<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[linux如何查杀指定用户进程]]></title>
      <url>%2Farticles%2Flinux-kill9-psef.html</url>
      <content type="text"><![CDATA[首先w查看登录用户 通过ps -ef | grep pts/0 查看pts/0上的用户 我们可以看到pid是17866 其余的ppid都是最终指向的都是这个。 -e 显示所有进程。-f 全格式。ps e 列出程序时，显示每个程序所使用的环境变量。ps f 用ASCII字符显示树状结构，表达程序间的相互关系 我们通过kill -9 强制关闭进程。一般情况下 请不要这样，因为是强制关闭。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[nginx重启，重载，测试，配置]]></title>
      <url>%2Farticles%2Fnginx-config.html</url>
      <content type="text"><![CDATA[nginx -s reload ：修改配置后重新加载生效nginx -s reopen ：重新打开日志文件nginx -t -c /path/to/nginx.conf 测试nginx配置文件是否正确 关闭nginx：nginx -s stop :快速停止nginx quit ：完整有序的停止nginx 其他的停止nginx 方式： ps -ef | grep nginx kill -QUIT 主进程号 ：从容停止Nginxkill -TERM 主进程号 ：快速停止Nginxpkill -9 nginx ：强制停止Nginx 启动nginx:nginx -c /path/to/nginx.conf 平滑重启nginx：kill -HUP 主进程号]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql2013错误]]></title>
      <url>%2Farticles%2Fmysql-2013%E9%94%99%E8%AF%AF.html</url>
      <content type="text"><![CDATA[mysql错误Lost connection to MySQL server at ‘reading initial communication packet’, system error: 0默认绑定的是本地,所以把bind-address = 127.0.0.1注释掉就好了。然后重启下服务器/etc/init.d/mysql restart 如果忘记密码可以添加skip-grant-tables忽略权限验证]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[写给前端工程师的DNS基础知识]]></title>
      <url>%2Farticles%2Fnetwrok-dns.html</url>
      <content type="text"><![CDATA[DNS在工作中，经常切换本地和服务器，添加各种解析。遇到DNS引起的一些问题。发现网上资料很混乱，用心整理写了下，希望对大家有帮助。 DNS（Domain Name System，域名系统），最初，由于ip长且难记，通过ip访问网站不方便。。所以后来通过发明了DNS服务器，这个时候我们访问网站输入网站域名，DNS服务器就解析我们的域名为ip。这样我们实际访问的就是对应的ip地址啦。 抽象点DNS就是 一个记录ip地址的超级分布式数据库。 根域和根域服务器首先我们要明白如何区分域，至于如何解析我们后面慢慢讲。 当我们输入www.sunhao.win访问网站。实际上是访问了不同的域。其中”.”是DNS 命称空间，用来分割不同域, www,sunhao,win分别代表不同的域。其实还有个域，跟在win后面，只是因为是域名系统默认的,所以这里不用写，这个就是根域。 意义上域名应该是这样。 www.sunhao.win.根域 根域记录了所有win域(这一个位置的叫顶级域),它和sunhao(二级域),共同构成顶级域名sunhao.win www(三级域)和sunhao.win叫二级域名www.sunhao.win 这里大家要明白sunhao.win和www.sunhao.win是两个不同的网址。 因为我们上网使用的UDP/TCP，UDP数据往往没有保障,但速度快,通常用于查询和响应，TCP由于多次验证，传输有保证，但速度慢，多用于主服务器和从服务器之间的传送。 因此我们DNS主要通过UDP。 当我们访问www.sunhao.win的时候,如果本地dns服务器没有记录，那么它就会向根服务器去请求地址。 也就是它会向根服务器请求win域的地址。然后通过win域继续向下请求。根域名服务器并不直接把待查询的域名直接解析出IP地址，而是告诉本地域名服务器下一步应当找哪一个顶级域名服务器进行查询。 所以根域名服务器很重要。假定所有的根域名服务器都瘫痪了，那么整个DNS系统就无法工作。 顶级域和顶级域服务器例如www.sunhao.win win所在的位置就是顶级域 域名只是逻辑概念，并不代表计算机所在的物理地点。据2006年12月统计，现在顶级域名TLD(Top Level Domain)已有265个，分为三大类： (1)国家顶级域名nTLD：采用ISO3166的规定。如：cn代表中国，us代表美国，uk代表英国，等等。国家域名又常记为ccTLD(cc表示国家代码contry-code)。 (2)通用顶级域名gTLD：最常见的通用顶级域名有7个，即：com(公司企业)，net(网络服务机构)，org(非营利组织)，int(国际组织)，gov(美国的政府部门)，mil(美国的军事部门)。(3)基础结构域名(infrastructure domain)：这种顶级域名只有一个，即arpa，用于反向域名解析，因此称为反向域名。 顶级域名服务器主要负责管理在该顶级域名服务器注册的二级域名。 权威DNS和权威域名服务器权威DNS服务器是经过上一级授权，对域名进行解析的服务器，同时它可以把解析授权转授给其他人。 例如，在互联网上,谁售出的域名,就把域名授权给谁，比如sunhao.win是阿里售出的，所以权威服务器是阿里的dns解析服务器。(为了保障安全和保障一般权威DNS服务器都是俩) dns9.hichina.comdns10.hichina.com 但是由于业务我从后台调整解析到yunjiasu。 123;; AUTHORITY SECTION:sunhao.win. 2992 IN NS n563.ns.yunjiasu.com.sunhao.win. 2992 IN NS n3101.ns.yunjiasu.com. 其中n563.ns.yunjiasu.com和n3101.ns.yunjiasu.com是sunhao.win的权威服务器。由顶级域名win授权ns.yunjiasu.com.进行管理的。 当访问sunhao.win通过顶级域名解析后，顶级域名win就给用户说,你要访问sunhao.win是吧，你得去n563.ns.yunjiasu.com看看,它那记录了ip地址,不行就去n3101.ns.yunjiasu.com.再不行，你就自己报错把。^_^. 通俗点说,就是爸爸给孩子十块钱(这里指域名)，这十块钱,孩子可以自己花，也可以转给别人。拥有了控制十块钱的所有权限。简单点说,就是一旦把域名授权给我，授权给我的那部分，我做主。 运营商DNS服务器和本地DNS服务器在实际上网中，我们不是直接连接根服务器，而是通过本地DNS服务器上网。 如果DNS设置不好，或者不对，会导致如我们qq能登陆，而页面无法浏览网页的症状、 在这，本地DNS主要指是指各地电信运营商提供的域名解析服务器。也就是我们在上网网卡里面你设置的DNS地址。当然也可以自己建设一个服务器。 当一个主机发出DNS查询请求时，这个查询请求报文就发送给本地域名服务器，本地服务器替我们进行DNS解析,我们得到的ip地址是由本地服务器返回的。 查询我们了解了个个服务器,理一下常规DNS系统如何运作的吧 1，用户—&gt;本地递归服务器— &gt; 根权威服务器— &gt; COM权威服务器— &gt; X(X代表任意地址).COM权威服务器— &gt; 本地递归服务器— &gt;用户 2，用户—&gt;本地递归服务器— &gt; 缓存 — &gt;用户 在这我们要明白两点。 一、递归查询:主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。 简单说 就是说我们请求的地址 必须返回一个准确的ip地址，没有就向别的地址查询，然后返回给我们一个准确的ip地址。我们的本地服务器就是递归服务器。 二、迭代查询:本地域名服务器向根域名服务器的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机。 这里由各级服务器进行的就是迭代查询，自身不返回ip，而是返回给下一级的DNS服务器地址。 实际一般本地DNS访问量巨大，会有一个前置的F5服务器，用于分发给后缀的服务器实现负载均衡。同时服务器会根据设置会缓存一段时间地址。所以有时候我们在服务器改完DNS，有时候会等一段时间，才能访问到新的地址。 解析记录域名解析记录A、CNAME、MX、NS、TXT、AAAA、SRV、显性URL、隐形URL含义 A记录：解析域名到指定ip CNAME记录（Canonical Name 别名指向）：解析域名到域名 MX记录：指向一个邮件服务器，用于电子邮件系统发邮件时根据收信人的地址后缀来定位邮件服务器。 NS记录：解析服务器记录。用来表明由哪台服务器对该域名进行解析，这里的NS记录只对子域名生效。优先级：NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。 TXT记录：为某个主机名或域名设置联系信息，如：admin IN TXT “管理员, 电话： 1000000000” AAAA记录(AAAA record)：是用来将域名解析到IPv6地址的DNS记录。用户可以将一个域名解析到IPv6地址上，也可以将子域名解析到IPv6地址上。 SRV记录：一般是为Microsoft的活动目录设置时的应用。 显性URL记录：访问域名时，会自动跳转到所指的另一个网络地址（URL），此时在浏览器地址栏中显示的是跳转的地址。 隐形URL记录：访问域名时，会自动跳转到所指的另一个网络地址（URL），此时在浏览器地址栏中显示的是原域名地址。 应答权威应答 由权威服务器区域直接返回的应答地址 非权威应答 由缓存或者其他服务器返回的地址 TTL值和缓存假如我们每次都发送一次DNS请求,那么服务器的压力会相当大，但是服务器的ip地址一般会经常变，所以实际我们都设置TTL把DNS缓存到本地。 什么是域名的TTL值？TTL(Time- To-Live)，简单的说它就是返回的记录在DNS服务器上保留的时间，就是TTL值。 DNS会将最终域名解析的结果缓存至本地。分为两种浏览器缓存和操作系统(OS)缓存。 在浏览器中访问的时候，会优先访问浏览器缓存，如果访问指定域名,没有命中返回,则访问OS缓存。最后再次访问dns服务器。 所以我们在调试的时候，更换了本地hosts仍然访问的是旧地址,那么就等一会吧。 我们可以看到chrome会自动缓存70s dns。 那么我们如果想在70s内清除缓存怎么办呢? 我们在chrome地址栏里面输入chrome，会自动索引出有关的基本地址。选择chrome-urls 往下拉选择chrome://net-internals 其中最右面 可以清除页面缓存 点Clear host cache，可以用于清除DNS缓存。 其实这个页面最好收藏下来，便于以后调试时及时刷新。 hosts在DNS系统之前，对应ip都是保存在hosts文件之中，现在系统仍然保留它。 实际通过浏览器访问，会先查询浏览器dns缓存，再查询hosts里面是否有记录 一般win系统Hosts文件就在C:\WINDOWS\system32\drivers\etc中 通过hosts我们可以把域名改成本地的地址，进行调试开发。 对于经常访问的网站，也可以直接设置到hosts里，加快访问速度。 sunhao.win解析过程分析最后我们看下用dig +trace 跟踪的全部解析过程 12345678910111213141516171819202122232425262728293031323334[root@sunhao ~]# dig +trace www.sunhao.win; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.37.rc1.el6 &lt;&lt;&gt;&gt; +trace www.sunhao.win;; global options: +cmd. 12674 IN NS e.root-servers.net.. 12674 IN NS i.root-servers.net.. 12674 IN NS h.root-servers.net.. 12674 IN NS k.root-servers.net.. 12674 IN NS d.root-servers.net.. 12674 IN NS l.root-servers.net.. 12674 IN NS a.root-servers.net.. 12674 IN NS c.root-servers.net.. 12674 IN NS m.root-servers.net.. 12674 IN NS g.root-servers.net.. 12674 IN NS b.root-servers.net.. 12674 IN NS f.root-servers.net.. 12674 IN NS j.root-servers.net.;; Received 492 bytes from 211.161.46.85#53(211.161.46.85) in 42 mswin. 172800 IN NS ns1.dns.nic.win.win. 172800 IN NS ns6.dns.nic.win.win. 172800 IN NS ns3.dns.nic.win.win. 172800 IN NS ns2.dns.nic.win.win. 172800 IN NS ns5.dns.nic.win.win. 172800 IN NS ns4.dns.nic.win.;; Received 412 bytes from 192.36.148.17#53(192.36.148.17) in 191 mssunhao.win. 3600 IN NS n563.ns.yunjiasu.com.sunhao.win. 3600 IN NS n3101.ns.yunjiasu.com.;; Received 86 bytes from 156.154.145.182#53(156.154.145.182) in 2415 mswww.sunhao.win. 300 IN A 162.159.211.33www.sunhao.win. 300 IN A 162.159.210.33;; Received 92 bytes from 220.181.111.112#53(220.181.111.112) in 6 ms .就是一开始说的根域。NS就是指定该域名由哪个DNS服务器来进行解析。 我们可以清晰的看到第一步先从13台dns服务器，然是顶级域win,最后权威域sunhao.win。查到地址在162.159.211.33和162.159.210.33上。最后的是A记录。不再是NS了哦。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[fg、bg、jobs、nohup、ctrl+z、ctrl+c、screen命令]]></title>
      <url>%2Farticles%2Flinux-bg-fg-jobs-screen.html</url>
      <content type="text"><![CDATA[一、&amp; 加在一个命令的最后，可以把这个命令放到后台执行，如 watch -n 10 sh test.sh &amp; #每10s在后台执行一次test.sh脚本 二、ctrl + z 可以将一个正在前台执行的命令放到后台，并且处于暂停状态。 三、jobs 查看当前有多少在后台运行的命令 jobs -l选项可显示所有任务的PID，jobs的状态可以是running, stopped, Terminated。但是如果任务被终止了（kill），shell从当前的shell环境已知的列表中删除任务的进程标识。 四、fg 将后台中的命令调至前台继续运行。如果后台中有多个命令，可以用fg %jobnumber（是命令编号，不是进程号）将选中的命令调出。 五、bg 将一个在后台暂停的命令，变成在后台继续执行。如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出。 六、kill 法子1：通过jobs命令查看job号（假设为num），然后执行kill %num 法子2：通过ps命令查看job的进程号（PID，假设为pid），然后执行kill pid 前台进程的终止：Ctrl+c 七、nohup 如果让程序始终在后台执行，即使关闭当前的终端也执行（之前的&amp;做不到），这时候需要nohup。该命令可以在你退出帐户/ 关闭终端之后继续运行相应的进程。关闭中断后，在另一个终端jobs已经无法看到后台跑得程序了，此时利用ps（进程查看命令） ps -aux | grep “test.sh” #a:显示所有程序 u:以用户为主的格式来显示 x:显示所有程序，不以终端机来区分 进程的终止： 后台进程的终止： 一、使用Screen创建一个Session screen -S sessionName 注：sessionName是要删除的session名字 二、结束一个Screen创建的session 1、首先使用screen -ls命令查看全部session列表 2、使用screen -S sessionName -X quit, 注：sessionName是要删除的session名字 三、恢复一个Screen的session 1、Screen -r sessionName]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[respberry树莓派 无线网络配置]]></title>
      <url>%2Farticles%2Frespberry-wpanetwork.html</url>
      <content type="text"><![CDATA[执行命令: sudo iwlist wlan0 scan , 看看能否手动扫描周围的ESSID. 无线配置修改配置文件: sudo vim /etc/network/interfaces, 如果需要自动IP, 增加如下: 12345# wifi (dhcp config) :auto wlan0allow-hotplug wlan0iface wlan0 inet dhcpwpa-conf /etc/wpa_supplicant/wpa_supplicant.conf 如果需要固定IP, 增加的内容如下: 123456auto wlan0iface wlan0 inet staticwpa-conf /etc/wpa_supplicant/wpa_supplicant.confaddress 192.168.1.12netmask 255.255.255.0gateway 192.168.1.1 编辑/etc/wpa_supplicant/wpa_supplicant.conf, 增加如下几行: 12345678network=&#123; ssid=&quot;ssid1&quot; psk=&quot;密码&quot;&#125;network=&#123; ssid=&quot;ssid2&quot; psk=&quot;密码&quot;&#125; 这里存的是明文密码, 如果需要存储加密后的密码, 执行命令wpa_passphrase ssid password, 替换上面的psk密码.wpa_supplicant.conf里面更多参数详情, 请参考man手册链接, 上面的配置能应付大多数路由器了. 重启wlan0 重启无线网卡: sudo ifdown wlan0 and then sudo ifup wlan0然后运行ifconfig wlan0 查看无线网卡是否获能够取到了IP.如果固定ip 最好重启 reboot 输入密码]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-source]]></title>
      <url>%2Farticles%2Flinux-source.html</url>
      <content type="text"><![CDATA[source: usage: source filename [arguments] source命令：source命令也称为“点命令”，也就是一个点符号（.）,是bash的内部命令。功能：使Shell读入指定的Shell程序文件并依次执行文件中的所有语句source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录。用法：source filename 或 . filenamesource命令(从 C Shell 而来)是bash shell的内置命令;点命令(.)，就是个点符号(从Bourne Shell而来)是source的另一名称。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[/bin,/sbin,/usr/bin,/usr/sbin区别]]></title>
      <url>%2Farticles%2Flinux-diff-sbin-bin.html</url>
      <content type="text"><![CDATA[/bin,/sbin,/usr/bin,/usr/sbin区别/ : this is root directory root 用户根目录 /bin : commandsin this dir are all system installed user commands 系统的一些指令 /sbin: commands in this dir are all system installedsuper user commands超级用户指令系统管理命令，这里存放的是系统管理员使用的管理程序 /usr/bin: usercommands for applications 后期安装的一些软件的运行脚本 /usr/sbin:super user commands for applications 超级用户的一些管理程序 /usr/X11R6/bin: X application user commands /usr/X11R6/sbin: X application super usercommands Linux中的某些重要的目录： •主目录：/root、/home/username •用户可执行文件：/bin、/usr/bin、/usr/local/bin •系统可执行文件：/sbin、/usr/sbin、/usr/local/sbin •其他挂载点：/media、/mnt •配置：/etc •临时文件：/tmp •内核和Bootloader：/boot •服务器数据：/var、/srv •系统信息：/proc、/sys •共享库：/lib、/usr/lib、/usr/local/lib 每个用户都拥有一个主目录。所有用户的个人文件（配置、数据甚至应用程序）都放在其中。 根的主目录为/root。大多数非根主目录包含在/home 树中，通常以用户命名。 重要的二进制位于 /bin（用户二进制）以及 /sbin（系统二进制）中。 不重要的二进制（如图形环境或Office 工具）安装在/usr/bin 和 /usr/sbin中。进行这种分隔是为了尽可能地缩小根分区。使用源代码编译的软件通常位于 /usr/local/bin 和/usr/local/sbin中。 传统上的常规做法是：系统级的组件放在/bin、/lib； 根用户才能访问的放在/sbin； 系统repository提供的应用程序放在/usr/bin、/usr/lib； 用户自己编译的放在/usr/local/XXX。 现在有一些变化，在大约两年前，大量Linux系统都将/bin、/lib弄成/usr/bin、/usr/lib的符号链接。 此外，不同系统还会有很多的细微区别，比如Redhat系喜欢把32位的库放在/lib、/usr/lib，64位的库放在/lib64、/usr/ lib64，而Debian系喜欢把平台相关的那层名字放在/lib、/usr/lib的子目录里，比如/usr/lib/x86_64-linux-gnu/ 。然后，各种配置文件的文件名、路径也会有区别，比如ssh服务器的配置文件可能叫/etc/ssh/sshd.conf，也可能叫/etc/ssh/sshd_config。。。 分成三块的最早的渊源，据说是这样的： Unix开发者的机器的硬盘不够了，新加了一块，挂在/usr上； 又TM不够了，再加一块，挂在/usr/local上； 不知怎么，就变成规范了。。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[反向代理 和 正向代理区别]]></title>
      <url>%2Farticles%2Fphp-proxy.html</url>
      <content type="text"><![CDATA[一个是代理客户端，为客户端收发请求，使真实客户端对服务器不可见。一个是代理服务器，为服务器收发请求，使真实服务器对客户端不可见。简单点说代理的目的本身都是为了隐藏自己真实的地址。 正向代理,是客户端用的,因为符合正常的网络请求，所以叫正向代理。而反向代理，是服务器用的，所以叫反向代理。 A同学在大众创业、万众创新的大时代背景下开启他的创业之路，目前他遇到的最大的一个问题就是启动资金，于是他决定去找马云爸爸借钱，可想而知，最后碰一鼻子灰回来了，情急之下，他想到一个办法，找关系开后门，经过一番消息打探，原来A同学的大学老师王老师是马云的同学，于是A同学找到王老师，托王老师帮忙去马云那借500万过来，当然最后事成了。不过马云并不知道这钱是A同学借的，马云是借给王老师的，最后由王老师转交给A同学。这里的王老师在这个过程中扮演了一个非常关键的角色，就是代理，也可以说是正向代理，王老师代替A同学办这件事，这个过程中，真正借钱的人是谁，马云是不知道的，这点非常关键。 我们常说的代理也就是只正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求，某些科学上网工具扮演的就是典型的正向代理角色。用浏览器访问 http://www.google.com 时，被残忍的block，于是你可以在国外搭建一台代理服务器，让代理帮我去请求google.com，代理把请求返回的相应结构再返回给我。 client &lt;==&gt; proxy &lt;==&gt;server 这里client知道server地址,但server不知道client地址 只是用proxy做了个请求. 大家都有过这样的经历，拨打10086客服电话，可能一个地区的10086客服有几个或者几十个，你永远都不需要关心在电话那头的是哪一个，叫什么，男的，还是女的，漂亮的还是帅气的，你都不关心，你关心的是你的问题能不能得到专业的解答，你只需要拨通了10086的总机号码，电话那头总会有人会回答你，只是有时慢有时快而已。那么这里的10086总机号码就是我们说的反向代理。客户不知道真正提供服务人的是谁。 反向代理隐藏了真实的服务端，当我们请求 www.baidu.com 的时候，就像拨打10086一样，背后可能有成千上万台服务器为我们服务，但具体是哪一台，你不知道，也不需要知道，你只需要知道反向代理服务器是谁就好了，www.baidu.com 就是我们的反向代理服务器，反向代理服务器会帮我们把请求转发到真实的服务器那里去。Nginx就是性能非常好的反向代理服务器，用来做负载均衡。 client &lt;==&gt; proxy &lt;==&gt; serverA or serverB 这里客户端只知道proxy 具体哪个服务器内容,是proxy分配的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Unicode 和 UTF-8 有何区别？]]></title>
      <url>%2Farticles%2Fsoft-unicode-utf8.html</url>
      <content type="text"><![CDATA[很久很久以前，有一群人，他们决定用8个可以开合的晶体管来组合成不同的状态，以表示世界上的万物。他们看到8个开关状态是好的，于是他们把这称为”字节“。再后来，他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出很多状态，状态开始变来变去。他们看到这样是好的，于是它们就这机器称为”计算机“。开始计算机只在美国用。八位的字节一共可以组合出256(2的8次方)种不同的状态。 他们把其中的编号从0开始的32种状态分别规定了特殊的用途，一但终端、打印机遇上约定好的这些字节被传过来时，就要做一些约定的动作。遇上0×10,终端就换行，遇上0×07, 终端就向人们嘟嘟叫，例好遇上0x1b,打印机就打印反白的字，或者终端就用彩色显示字母。他们看到这样很好，于是就把这些0×20以下的字节状态称为”控制码”。他们又把所有的空格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的文字了。大家看到这样，都感觉 很好，于是大家都把这个方案叫做 ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文文字。后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，他们的字母里有许多是ASCII里没有的，为了可以在计算机保存他们的文字，他们决定采用127号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横线、竖线、交叉等形状，一直把序号编到了最后一个状态255。从128 到255这一页的字符集被称”扩展字符集“。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可能没有想到还有第三世界国家的人们也希望可以用到计算机吧！等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有6000多个常用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些127号之后的奇异符号们直接取消掉,规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。中国人民看到这样很不错，于是就把这种汉字方案叫做 “GB2312“。GB2312 是对 ASCII 的中文扩展。但是中国的汉字太多了，我们很快就就发现有许多人的人名没有办法在这里打出来，特别是某些很会麻烦别人的国家领导人。于是我们不得不继续把GB2312 没有用到的码位找出来老实不客气地用上。后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里的内容。结果扩展之后的编码方案被称为 GBK 标准，GBK包括了GB2312 的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。 后来少数民族也要用电脑了，于是我们再扩展，又加了几千个新的少数民族的字，GBK扩成了 GB18030。从此之后，中华民族的文化就可以在计算机时代中传承了。 中国的程序员们看到这一系列汉字编码的标准是好的，于是通称他们叫做 “DBCS“（Double Byte Charecter Set双字节字符集）。在DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了。那时候凡是受过加持，会编程的计算机僧侣 们都要每天念下面这个咒语数百遍： “一个汉字算两个英文字符！一个汉字算两个英文字符……”因为当时各个国家都像中国这样搞出一套自己的编码标准，结果互相之间谁也不懂谁的编码，谁也不支持别人的编码，连大陆和台湾这样只相隔了150海里，使用着同一种语言的兄弟地区，也分别采用了不同的 DBCS编码方案——当时的中国人想让电脑显示汉字，就必须装上一个”汉字系统”，专门用来处理汉字的显示、输入的问题，但是那个台湾的愚昧封建人士写的算命程序就必须加装另一套支持 BIG5编码的什么”倚天汉字系统”才可以用，装错了字符系统，显示就会乱了套！这怎么办？而且世界民族之林中还有那些一时用不上电脑的穷苦人民，他们的文字又怎么办？ 真是计算机的巴比伦塔命题啊！正在这时，大天使加百列及时出现了——一个叫 ISO（国际标谁化组织）的国际组织决定着手解决这个问题。他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号 的编码！他们打算叫它”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “unicode“。unicode开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是 ISO就直接规定必须用两个字节，也就是16位来统一表示所有的字符，对于ASCII里的那些“半角”字符，unicode包持其原编码不变，只是将其长度由原来的8位扩展为16位，而其他文化和语言的字符则全部重新统一编码。由于”半角”英文符号只需要用到低8位，所以其高8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。这时候，从旧社会里走过来的程序员开始发现一个奇怪的现象：他们的strlen函数靠不住了，一个汉字不再是相当于两个字符了，而是一个！是的，从unicode开始，无论是半角的英文字母，还是全角的汉字，它们都是统一的”一个字符“！同时，也都是统一的”两个字节“，请注意”字符”和”字节”两个术语的不同，“字节”是一个8位的物理存贮单元，而“字符”则是一个文化相关的符号。在unicode中，一个字符就是两个字节。一个汉字算两个英文字符的时代已经快过去了。unicode同样也不完美，这里就有两个的问题，一个是，如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储空间来说是极大的浪费，文本文件的大小会因此大出二三倍，这是难以接受的。unicode在很长一段时间内无法推广，直到互联网的出现，为解决unicode如何在网络上传输的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，顾名思义，UTF-8就是每次8个位传输数据，而UTF-16就是每次16个位。UTF-8就是在互联网上使用最广的一种unicode的实现方式，这是为传输而设计的编码，并使编码无国界，这样就可以显示全世界上所有文化的字符了。UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度，当字符在ASCII码的范围时，就用一个字节表示，保留了ASCII字符一个字节的编码做为它的一部分，注意的是unicode一个中文字符占2个字节，而UTF-8一个中文字符占3个字节）。从unicode到uft-8并不是直接的对应，而是要过一些算法和规则来转换。Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）—————————————————————–0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx原文：unicode,ansi,utf-8,unicode big endian编码的区别 原文:https://wenku.baidu.com/view/cb9fe505cc17552707220865.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-crontab]]></title>
      <url>%2Farticles%2Flinux-crontab.html</url>
      <content type="text"><![CDATA[该词来源于希腊语 chronos(χρνο)，原意是时间。常，crontab储存的指令被守护进程激活， crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。 使用权限: root用户和crontab文件的所有者 语法: crontab [-e [UserName]|-l [UserName]|-r [UserName]|-v [UserName]|File ] 说明: crontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。 -u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。 参数: -e [UserName]: 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe) -r [UserName]: 删除目前的时程表 -l [UserName]: 列出目前的时程表 -v [UserName]:列出用户cron作业的状态 时程表的格式如下: f1 f2 f3 f4 f5 program 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程式。 当 f1 为 时表示每分钟都要执行 program，f2 为 时表示每小时都要执行程式，其余类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其余类推 当 f1 为 /n 时表示每 n 分钟个时间间隔执行一次，f2 为 /n 表示每 n 小时个时间间隔执行一次，其余类推 当 f1 为 a, b, c,… 时表示第 a, b, c,… 分钟要执行，f2 为 a, b, c,… 时表示第 a, b, c…个小时要执行，其余类推 使用者也可以将所有的设定先存放在档案 file 中，用 crontab file 的方式来设定时程表。 由于unix版本不一样，所以部分语法有差别，例如在hp unix aix 中设定间隔执行如果采用*/n 方式将出现语法错误，在这类unix中 ，间隔执行只能以列举方式。 使用方法 用VI编辑一个文件 cronfile，然后在这个文件中输入格式良好的时程表。编辑完成后，保存并退出。[2] 在命令行输入 $: crontab cronfile 这样就将cronfile文件提交给c r o n进程，同时，新创建cronfile的一个副本已经被放在/ v a r / s p o o l / c r o n目录中，文件名就是用户名。 例子: 每月每天每小时的第 0 分钟执行一次 /bin/ls : 0 /bin/ls 在 12 月内, 每天的早上 6 点到 12 点中，每隔 20 分钟执行一次 /usr/bin/backup : /20 6-12 12 * /usr/bin/backup 周一到周五每天下午 5:00 寄一封信给 alex_mail_name : 0 17 1-5 mail -s “hi” alex_mail_name &lt; /tmp/maildata 每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分….执行 echo “haha” 20 0-23/2 * echo “haha” 晚上11点到早上8点之间每两个小时，早上8点 0 23-7/2，8 * date 在hpunix,中，每20分钟执行一次，表示为：0,20,40 而不能采用*/n方式，否则出现语法错误 30 21 * /usr/local/apache/bin/apachectl restart上面的例子表示每晚的21:30重启apache。 45 4 1,10,22 /usr/local/apache/bin/apachectl restart上面的例子表示每月1、10、22日的4 : 45重启apache。 10 1 6,0 /usr/local/apache/bin/apachectl restart上面的例子表示每周六、周日的1 : 10重启apache。 0,30 18-23 * /usr/local/apache/bin/apachectl restart上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。 0 23 6 /usr/local/apache/bin/apachectl restart上面的例子表示每星期六的11 : 00 pm重启apache。 /1 /usr/local/apache/bin/apachectl restart每一小时重启apache 23-7/1 * /usr/local/apache/bin/apachectl restart晚上11点到早上7点之间，每隔一小时重启apache 0 11 4 * mon-wed /usr/local/apache/bin/apachectl restart每月的4号与每周一到周三的11点重启apache 0 4 1 jan * /usr/local/apache/bin/apachectl restart一月一号的4点重启apache 注意: 当程式在你所指定的时间执行后，系统会寄一封信给你，显示该程式执行的内容，若是你不希望收到这样的信，请在每一行空一格之后加上 &gt; /dev/null 2&gt;&amp;1 即可。 %在crontab中被认为是newline，要用\来escape才行。比如crontab执行行中，如果有”date +%Y%m%d”，必须替换为：”date +\%Y\%m\%d”创建crontab 在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑crontab文件。99 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$HOME目录下的.profile文件，在其中加入这样一行：EDITOR=vi; export EDITOR然后保存并退出。 不妨创建一个名为cron的文件，其中是用户名，为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数： $ crontab davecron 现在该文件已经提交给cron进程，同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名（即，dave）。 列出crontab文件 为了列出crontab文件，可以用： $crontab -l 编辑crontab文件 如果希望添加、删除或编辑crontab文件中的条目，而EDITOR环境变量又设置为vi，那么就可以用vi来编辑crontab文件，相应的命令为： $ crontab -e 可以像使用vi编辑其他任何文件那样修改crontab文件并退出。 删除crontab文件 为了删除crontab文件，可以用： $ crontab -r注释crontab文件如果不希望删除写好的crontab文件，在该crontab文件前添加#将该文件注释掉。恢复丢失的crontab文件如果不小心误删了crontab文件，假设你在自己的$HOME目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/，其中是用户名。如果由于权限问题无法完成拷贝，可以用： $ crontab 其中，是你在$HOME目录中副本的文件名。 crontab中的输出配置 crontab中经常配置运行脚本输出为：&gt;/dev/null 2&gt;&amp;1，来避免crontab运行中有内容输出。 shell命令的结果可以通过‘&gt; ’的形式来定义输出 /dev/null 代表空设备文件 代表重定向到哪里，例如：echo “123” &gt; /home/123.txt 1 表示stdout标准输出，系统默认值是1，所以”&gt;/dev/null”等同于”1&gt;/dev/null” 2 表示stderr标准错误 &amp; 表示等同于的意思，2&gt;&amp;1，表示2的输出重定向等同于1 那么重定向输出语句的含义： 1&gt;/dev/null 首先表示标准输出重定向到空设备文件，也就是不输出任何信息到终端，不显示任何信息。 2&gt;&amp;1 表示标准错误输出重定向等同于标准输出，因为之前标准输出已经重定向到了空设备文件，所以标准错误输出也重定向到空设备文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-iftop查看带宽-iptables]]></title>
      <url>%2Farticles%2Flinux-iftop-iptables.html</url>
      <content type="text"><![CDATA[iftop用于网络监控 if本身的意思就是interface的缩写 安装直接yum install iftop就可以 输入iftop即可登录 默认监控eth0 设置参数iftop -i eth1 -i参数就是选择网卡。这里选择eth1 然后使用iptables禁掉占用高的ip iptables -A OUTPUT -d ..*.157 -j REJECT 1、iftop界面相关说明界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。 中间的&lt;= =&gt;这两个左右箭头，表示的是流量的方向。 TX：发送流量 RX：接收流量 TOTAL：总流量 Cumm：运行iftop到目前时间的总流量 peak：流量峰值 rates：分别表示过去 2s 10s 40s 的平均流量 2、iftop相关参数常用的参数 -i设定监测的网卡，如：# iftop -i eth1 -B 以bytes为单位显示流量(默认是bits)，如：# iftop -B -n使host信息默认直接都显示IP，如：# iftop -n -N使端口信息默认直接都显示端口号，如: # iftop -N -F显示特定网段的进出流量，如# iftop -F 10.10.1.0/24或# iftop -F 10.10.1.0/255.255.255.0 -h（display this message），帮助，显示参数信息 -p使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息; -b使流量图形条默认就显示; -f这个暂时还不太会用，过滤计算包用的; -P使host信息及端口信息默认就都显示; -m设置界面最上边的刻度的最大值，刻度分五个大段显示，例：# iftop -m 100M 进入iftop画面后的一些操作命令(注意大小写) 按h切换是否显示帮助; 按n切换显示本机的IP或主机名; 按s切换是否显示本机的host信息; 按d切换是否显示远端目标主机的host信息; 按t切换显示格式为2行/1行/只显示发送流量/只显示接收流量; 按N切换显示端口号或端口服务名称; 按S切换是否显示本机的端口信息; 按D切换是否显示远端目标主机的端口信息; 按p切换是否显示端口信息; 按P切换暂停/继续显示; 按b切换是否显示平均流量图形条; 按B切换计算2秒或10秒或40秒内的平均流量; 按T切换是否显示每个连接的总流量; 按l打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息; 按L切换显示画面上边的刻度;刻度不同，流量图形条会有变化; 按j或按k可以向上或向下滚动屏幕显示的连接记录; 按1或2或3可以根据右侧显示的三列流量数据进行排序; 按&lt;根据左边的本机名或IP排序; 按&gt;根据远端目标主机的主机名或IP排序; 按o切换是否固定只显示当前的连接; 按f可以编辑过滤代码，这是翻译过来的说法，我还没用过这个！ 按!可以使用shell命令， 按q退出监控。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[架构师之路]]></title>
      <url>%2Farticles%2Fsoft-architect.html</url>
      <content type="text"><![CDATA[架构师之路(1)—面向过程和面向对象自学收集，如需观看，请访问原文。http://blog.csdn.net/phphot/article/details/4050193 1、引言机算机科学是一门应用科学，它的知识体系是典型的倒三角结构，所用的基础知识并不多，只 是随着应用领域和方向的不同，产生了很多的分支，所以说编程并不是一件很困难的事情，一个高中生经过特定的训练就可以做得到。但是，会编程和编好程绝对是 两码事，同样的程序员，有的人几年之后成为了架构师，有的人却还在不停地coding，只不过ctrl-c、ctrl-v用得更加纯熟了。在中国，编程人 员最终的归途无外乎两条：一是转向技术管理，它的终点是CTO；二是继续深入，它的终点是首席架构师，成为CEO的人毕竟是少数。如果你现在还是个普通的 程序员，希望继续在技术这条路上前进的话，我想你还是应该先补充一点软件工程的思想，学习一点有关设计模式的知识，只有具备这些能力，你才能从整体和宏观 层面来考虑问题、分析问题和解决问题。本人Coding了很多年，中间走了不少弯路，虽然最终没什么大成就，但总算有一些心得，很愿意把自己的一些经验拿 出来跟大家分享，这或许对你的发展有所帮助。 由程序员转为架构师，最绕不开的概念就算是面向对象(OO)了。记得在大学的时候，我们专业开了一门课叫《面向对象的编程》。那个时候，我们刚刚学 了一门C语言，开发环境用的还是DOS下的Turbo C，半点项目开发的经验都没有，纯粹的空对空。所以，一学期下来，我始终处于一种懵懂状态，既没领会面向过程和面向对象到底有什么区别，也没搞懂面向对象 能带来什么好处。 架构师之路(2)—详解面向过程2、面向过程(OP)和面向对象(OO)2.1 蛋炒饭和盖浇饭 有人这么形容OP和OO的不同：用面向过程的方法写出来的程序是一份蛋炒饭，而用面向对象写出来的程序是一份盖浇饭。所谓盖浇饭，北京叫盖饭，东北叫烩 饭，广东叫碟头饭，就是在一碗白米饭上面浇上一份盖菜，你喜欢什么菜，你就浇上什么菜。我觉得这个比喻还是比较贴切的。蛋炒饭制作的细节，我不太清楚，因为我没当过厨师，也不会做饭，但最后的一道工序肯定是把米饭和鸡蛋混在一起炒匀。盖浇饭呢，则是把米饭和盖菜分别做好，你如果要一份红烧肉盖饭呢，就给你浇一份红烧肉；如果要一份青椒土豆盖浇饭，就给浇一份青椒土豆丝。 蛋炒饭的好处就是入味均匀，吃起来香。如果恰巧你不爱吃鸡蛋，只爱吃青菜的话，那么唯一的办法就是全部倒掉，重新做一份青菜炒饭了。盖浇饭就没这么多麻烦，你只需要把上面的盖菜拨掉，更换一份盖菜就可以了。盖浇饭的缺点是入味不均，可能没有蛋炒饭那么香。到底是蛋炒饭好还是盖浇饭好呢？其实这类问题都很难回答，非要比个上下高低的话，就必须设定一个场景，否则只能说是各有所长。如果大家都不是美食家，没那么多讲究，那么从饭馆角度来讲的话，做盖浇饭显然比蛋炒饭更有优势，他可以组合出来任意多的组合，而且不会浪费。 2.2 软件工程 盖浇饭的好处就是“菜”“饭”分离，从而提高了制作盖浇饭的灵活性。饭不满意就换饭，菜不满意换菜。用软件工程的专业术语就是“可维护性”比较好，“饭” 和“菜”的耦合度比较低。蛋炒饭将“蛋”“饭”搅和在一起，想换“蛋”“饭”中任何一种都很困难，耦合度很高，以至于“可维护性”比较差。软件工程追求的 目标之一就是可维护性，可维护性主要表现在3个方面：可理解性、可测试性和可修改性。面向对象的好处之一就是显著的改善了软件系统的可维护性。 面向过程(OP)和面向对象(OO)是不是就是指编码的两种方式呢？不是！你拿到了一个用户需求，比如有人要找你编个软件，你是不是需要经过需求分析，然 后进行总体/详细设计，最后编码，才能最终写出软件，交付给用户。这个过程是符合人类基本行为方式的：先想做什么，再想如何去做，最后才是做事情。有的同 学说：“我没按照你说的步骤做啊，我是直接编码的”。其实，你一定会经历了这三个阶段，只不过你潜意识里没有分得那么清楚。对于拿到需求就编码的人，可能 编着编着，又得倒回去重新琢磨，还是免不了这些过程， 以OO为例，对应于软件开发的过程，OO衍生出3个概念：OOA、OOD和OOP。采用面向对象进行分析的方式称为OOA，采用面向对象进行设计的方式称 为OOD，采用面向对象进行编码的方式称为OOP。面向过程(OP)和面向对象(OO)本质的区别在于分析方式的不同，最终导致了编码方式的不同。 2.3 面向过程编程(OPP) 和面向对象编程(OOP)的关系 关于面向过程的编程(OPP)和面向对象的编程(OOP),给出这它们的定义的人很多，您可以从任何资料中找到很专业的解释，但以我的经验来看，讲的相对枯燥一点，不是很直观。除非您已经有了相当的积累，否则说起来还是比较费劲。 我是个老程序员出身，虽然现在的日常工作更多倾向了管理，但至今依然保持编码的习惯，这句话什么意思呢？我跟大家沟通应该没有问题。无论你是在重复 我走过的路，或者已经走在了我的前面，大家都会有那么一段相同的经历，都会在思想层面上有一种理解和默契，所以我还是会尽量按照大多数人的常规思维写下 去。 面向过程的编程(OPP)产生在前，面向对象的编程(OOP)产生在后，所以面向对象的编程(OOP)一定会继承前者的一些优点，并摒弃前者存在的 一些缺点，这是符合人类进步的自然规律。两者在各自的发展和演变过程中，一定会相互借鉴，相互融合，吸收对方的优点，从而出现某些方面的趋同性。但是，即 使两者有更多的相似点，也不会改变它们本质上的不同，因为它们的出发点不同，完全是两种截然不同的思维方式。关于两者的关系，我的观点是这样的：面向对象 编程(OOP)在局部上一定是面向过程(OP)的，面向过程的编程(OPP)在整体上应该借鉴面向对象(OO)的思想。这一段说的的确很空洞，而且也一定 会有引来争议，不过，我劝您还是在阅读了后面的内容之后，再来评判我观点的正确与否。 象C++、C#、Java等都是面向对象的语言，c,PHP(暂且这么说，因为php4以后就支持OO)都是面向过程的语言，那么是不是我用C++ 写的程序一定就是面向对象，用c写的程序一定就是面向过程呢？这种观点显然是没有真正吃透两者的区别。语言永远是一种工具，前辈们每创造出来的一种语言， 都是你用来实现想法的利器。我觉得好多人用C#,Java写出来的代码，要是仔细看看，那实际就是用面向对象(OO)的语言写的面向过程(OP)的程序。 所以，即使给关羽一根木棍，给你一杆青龙偃月刀，他照样可以打得你满头是包。你就是扛着个偃月刀，也成不了关羽，因为你缺乏关羽最本质的东西—绝世武功。同样的道理，如果你没有领会OO思想，怎么可能写得出真正的OO程序呢？ 那是不是面向过程就不好，也没有存在的必要了？我从来没有这样说过。事实上，面向过程的编程(OPP)已经存在了几十年了，现在依然有很多人在使 用。它的优点就是逻辑不复杂的情况下很容易理解，而且运行效率远高于面向对象（OO）编写的程序。所以，系统级的应用或准实时系统中，依然采用面向过程的 编程(OPP)。当然，很多编程高手以及大师级的人物，他们由于对于系统整体的掌控能力很强，也喜欢使用面向过程的编程(OPP)，比如像 Apache,QMail,PostFix,ICE等等这些比较经典的系统都是OPP的产物。象php这些脚本语言，主要用于web开发，对于一些业务逻 辑相对简单的系统，也常使用面向过程的编程(OPP)，这也是php无法跨入到企业级应用开发的原因之一，不过php5目前已经能够很好的支持OO了。 2.4 详解面向过程的编程(OPP) 在面向对象出现之前，我们采用的开发方法都是面向过程的编程(OPP)。面向过程的编程中最常用的一个分析方法是“功能分解”。我们会把用户需求先分解成 模块，然后把模块分解成大的功能，再把大的功能分解成小的功能，整个需求就是按照这样的方式，最终分解成一个一个的函数。这种解决问题的方式称为“自顶向 下”，原则是“先整体后局部”，“先大后小”，也有人喜欢使用“自下向上”的分析方式，先解决局部难点，逐步扩大开来，最后组合出来整个程序。其实，这两 种方式殊路同归，最终都能解决问题，但一般情况下采用“自顶向下”的方式还是较为常见，因为这种方式最容易看清问题的本质。 我举个例子来说明面向过程的编程方式: 用户需求：老板让我写个通用计算器。 最终用户就是老板，我作为程序员，任务就是写一个计算器程序。OK，很简单，以下就是用C语言完成的计算器： 假定程序的文件名为：main.c。 1234567891011121314151617181920212223242526272829303132int main(int argc, char *argv[])&#123; //变量初始化 int nNum1,nNum2; char cOpr; int nResult; nNum1 = nNum2 = 0; cOpr = 0; nResult = 0; //输入数据 printf("Please input the first number:/r/n"); scanf("%d",&amp;nNum1); printf("Please input the operator:/r/n"); scanf("%s",&amp;cOpr); printf("Please input the second number:/r/n"); scanf("%d",&amp;nNum2); //计算结果 if( cOpr == '+' )&#123; nResult = nNum1 + nNum2; &#125;else if( cOpr == '-' )&#123; nResult = nNum1 - nNum2; &#125;else&#123; printf("Unknown operator!"); return -1; &#125; //输出结果 printf("The result is %d!",nResult); return 0;&#125; 抛开细节不讲，我想大多数人差不多都会这么实现吧，很清晰，很简单，充分体现了“简单就是美”的原则，面向过程的编程就是这样有条理的按照顺序来逐步实现用户需求。 凡是做过程序的人都知道，用户需求从来都不会是稳定的，最多只能够做到“相对稳定”。用户可能会随时提出加个功能，减个功能的要求，也可能会要求改 动一下流程，程序员最烦的就是频繁地变动需求，尤其是程序已经写了大半了，但这种情况是永远无法避免的，也不能完全归罪到客户或者需求分析师。 以我们上面的代码为例，用户可能会提出类似的要求：首先，你程序中实现了“加法”和“减法”，我还想让它也能计算“乘法”、“除法”。其次，你现在的人机界面太简单了，我还想要个Windows计算器的界面或者Mac计算器的界面。 用户需求开始多了，我得琢磨琢磨该如何去写这段代码了。我今天加了“乘”“除”的运算，明天保不齐又得让我加个“平方”、“立方”的运算，这要是把 所有的运算都穷尽了，怎么也得写个千八百行代码吧。还有，用户要求界面能够更换，还得写一大堆界面生成的代码，又得来个千八百行。以后，这么多代码堆在一 起，怎么去维护，找个变量得半天，看懂了代码得半天，万一不小心改错了，还得调半天。另外，界面设计我也不擅长，得找个更专业的人来做，做完了之后再加进 来吧。这个过程也就是“软件危机”产生的过程。伴随着软件广泛地应用于各个领域，软件开发的规模变得越来越大，复杂度越来越高，而其用户的需求越来越不稳 定。 根据用户提出的两个需求，面向过程的编程该如何去应对呢？我想大家都很清楚怎么去改。Very easy，把“计算”和“界面”分开做成两个独立的函数，封装到不同的文件中。假定程序的文件名为：main.c。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include "interface.h"#include "calculate.h"int main(int argc, char *argv[])&#123; //变量初始化 int nNum1,nNum2; char cOpr; int nResult; nNum1 = nNum2 = 0; cOpr = 0; nResult = 0; //输入数据 if( getParameters(&amp;nNum1,&amp;nNum2,&amp;cOpr) == -1 ) return -1; //计算结果 if( calcMachine(nNum1,nNum2,cOpr,&amp;nResult) == -1 ) return -1; //输出结果 printf("The result is %d!",nResult); return 0;&#125;interface.h:int getParameters(int *nNum1,int * nNum2,char *cOpr);interface.c:int getParameters(int *nNum1,int * nNum2,char *cOpr)&#123; printf("Please input the first number:/r/n"); scanf("%d",nNum1); printf("Please input the operator:/r/n"); scanf("%s",cOpr); printf("Please input the second number:/r/n"); scanf("%d",nNum2); return 0;&#125;calculate.h:int calcMachine(int nNum1,int nNum2,char cOpr, int *nResult);calculate.c:int calcMachine(int nNum1,int nNum2,char cOpr,int *nResult)&#123; if( cOpr == '+' )&#123; *nResult = nNum1 + nNum2; &#125;else if( cOpr == '-' )&#123; *nResult = nNum1 - nNum2; &#125;else&#123; printf("Unknown operator!"); return -1; &#125;; return 0;&#125; “计算”和“界面”分开之后，添加新功能或者修改bug就方便多了，遇到与“计算”相关的需求就去修改calculate模块，遇到与“界面”相关的需求就去修改interface模块，因此，整个系统模块之间的“耦合度”就被放松了，可维护性有了一定程度的改善。 面向过程的编程(OPP)就是将用户需求进行“功能分解”。把用户需求先分解成模块(.h,.c)，再把模块(.h,.c)分解成大的功能(function)，然后把大的功能(function)分解成小的功能(function)，如此类推。 功能分解是一项很有技术含量的工作，它不仅需要分解者具有丰富的实战经验，而且需要科学的理论作为指导。如何分解，分解原则是什么，模块粒度多大合适？这些都是架构师的要考虑的问题，也是我们后面要着重讲的内容。 面向过程的编程(OPP)优点是程序顺序执行，流程清晰明了。它的缺点是主控程序承担了太多的任务，各个模块都需要主控程序进行控制和调度，主控和模块之间的承担的任务不均衡。有的人把面向过程定义为：算法 + 数据结构，我觉得也很准确。面向过程的编程中算法是核心，数据处于从属地位，数据随算法而流动。所以采用面向过程的方式进行编程，一般在动手之前，都要编写一份流程图或是数据流图。 架构师之路(3)—架构师的职责3 架构师的职责 近来看到CSDN上有个CTO俱乐部，里面聊得是不亦乐乎。我怀着无比崇敬的态度，拜读了一下牛人们的发言。里面有个哥们发起一个话题：“CTO, 你多久没有写程序了？”。有人回答：“不写代码的CTO,属于……这公司问题大了!”。看到这里，我就赶紧撤了，怕忍不住反驳几句，反而遭到牛人 们的群殴。试想，一个上点规模的IT公司，还得靠CTO来写程序的话，那是不是才叫问题大了呢。当然，我没有做过CTO，所以我有我的不同看法，而且还愿 意表达出来，无知者无畏。我情愿相信：我所理解的CTO跟这位CTO所理解的是两回事。所以我想，如果有人能把CTO的职责给标准化了，也许就不会有这么 多的争论了。 同样的道理，关于架构师的定义，大家也有着不同的理解。什么是架构师？架构师有哪些职责？我觉得有必要提前明确一下，要不然大家沟通起来也会产生类似问题，子说子理，卯说卯理，但是压根说得不是一码子事。 3.1 什么是架构师曾经有这么个段子：甲：我已经应聘到一家中型软件公司了，今天上班的时候，全公司的人都来欢迎我。乙：羡慕ing，都什么人来了？甲：CEO、COO、CTO、All of 程序员，还有会计、司机都来了。乙：哇，他们太重视你了，人才啊，这么多人迎接你！甲：没有啊，就一个人！乙：靠，#%￥$%… 很多的创业公司，一人身兼数职的情形还是很常见的。至少，我是经历过的，一个人包办了所有的开发过程，连测试我都做了，绝对的一条龙，但是经常踩钢丝、骑 独轮车总会有失足的时候，结果有一次，从我手里发出去的光盘母盘，含有病毒僵尸，以至于被迫收回已经推上市场的2万张光盘，从那之后，我的心脏就开始变得 无比坚强，现在就是整个后台服务都瘫痪了，我也只是微微一笑。其实，一个人身兼架构师和程序员，甚至多种角色，没什么不妥，后面还会讲这个话题，这种现象 不是中国特色，跟国外是完全接轨的。我曾经跟米国的一个工程师在msn中聊过类似的话题，发现他们的路子跟咱们没什么不同，在IT这个行业，我们跟世界的 差距只有1天，他们刚弄出来的新东西，我们这里第2天保准见得到。 架构师这个称呼不是拍脑袋想出来的，是有国际标准（ISO/IEC 42010）可查的。架构师是软件开发活动中的众多角色之一，它可能是一个人、一个小组，也可能是一个团队。微软对架构师有一个分类参考，我们参考一下， 他们把架构师分为4种：企业架构师EA(Enterprise Architect)、基础结构架构师IA(Infrastructure Architect)、特定技术架构TSA(Technology-Specific Architect)和解决方案架构师SA (Solution Architect)。微软的这个分类是按照架构师专注的领域不同而划分的。 EA的职责是决定整个公司的技术路线和技术发展方向。盖茨给自己的Title就是首席软件架构师，网易丁磊也喜欢这么称呼自己，实际上就是EA角色；IA 的工作就是提炼和优化技术方面积累和沉淀形成的基础性的、公共的、可复用的框架和组件，这些都是一个技术型公司传承下来的最宝贵的财富之一；特定技术架构 师TSA，他们主要从事类似安全架构、存储架构等专项技术的规划和设计工作；SA的工作则专于解决方案的规划和设计，“解决方案”这个词在中国已经到了严 重泛滥的程度，大忽悠们最喜欢把它挂在嘴边。所谓解决方案，就是把产品、技术或理论，不断地进行组合，来创造出满足用户需求的选择。售前工程师一般都是带 着它到客户那里去发挥的。 大公司会把各种类型的架构师分得很清楚，小公司一般就不那么讲究了，架构师多数是是IA+TSA+SA，一人包打天下，所以说大公司出专才，小公司出全才。 实际工作中，我们也经常会见到另一种比较简单的分类方式，把架构师分为软件架构师和系统架构师。软件架构师基本上是TSA+IA，这也是程序员最容易突 破，最可能走上的一条道路，比如Java架构师、DotNet架构师、LAPM架构师等等，我后面所讲的内容都是与软件架构师的相关的话题。系统架构师实 际上是SA+TSA，更着力于综合运用已有的产品和技术，来实现客户期望的需求。系统架构师要求通晓软、硬件两方面的知识，所以它的知识体系相对庞杂。关 于系统架构师的话题，我们可以稍后再作讨论。 3.2 架构师的职责架构师需要参与项目开发的全部过程，包括需求分析、架构设计、系统实现、集成、测试和部署各个阶段，负责在整个项目中对技术活动和技术说明进行指导和协调。架构师主要职责有4条： 1、确认需求 在项目开发过程中，架构师是在需求规格说明书完成后介入的，需求规格说明书必须得到架构师的认可。架构师需要和分析人员反复交流，以保证自己完整并准确地理解用户需求。 2、系统分解 依据用户需求，架构师将系统整体分解为更小的子系统和组件，从而形成不同的逻辑层或服务。随后，架构师会确定各层的接口，层与层相互之间的关系。架构师不仅要对整个系统分层，进行“纵向”分解，还要对同一逻辑层分块，进行“横向”分解。 软件架构师的功力基本体现于此，这是一项相对复杂的工作。 3、技术选型 架构师通过对系统的一系列的分解，最终形成了软件的整体架构。技术选择主要取决于软件架构。Web Server运行在Windows上还是Linux上？数据库采用MSSql、Oracle还是MySQL？需要不需要采用MVC或者spring等轻量级的框架？前端采用富客户端还是瘦客户端方式？类似的工作，都需要在这个阶段提出，并进行评估。架构师对产品和技术的选型仅仅限于评估，没有决定权，最终的决定权归项目经理。架构师提出的技术方案为项目经理提供了重要的参考信息，项目经理会从项目预算、人力资源、时间进度等实际情况进行权衡，最终进行确认。 4、制定技术规格说明 架构师在项目开发过程中，是技术权威。他需要协调所有的开发人员，与开发人员一直保持沟通，始终保证开发者依照它的架构意图去实现各项功能。 架构师与开发者沟通的最重要的形式是技术规格说明书，它可以是UML视图、Word文档，Visio文件等各种表现形式。通过架构师提供的技术规格说明书，保证开发者可以从不同角度去观察、理解各自承担的子系统或者模块。架构师不仅要保持与开发者的沟通，也需要与项目经理、需求分析员，甚至与最终用户保持沟通。所以，对于架构师来讲，不仅有技术方面的要求，还有人际交流方面的要求。 3.3 架构师的误区1、架构师就是项目经理 架构师不是项目经理。项目经理侧重于预算控制、时间进度控制、人员管理、与外部联系和协调等等工作，具备管理职能。一般小型项目中，常见项目经理兼架构师。 2、架构师负责需求分析 架构师不是需求分析员。需求分析人员的工作是收集需求和分析需求，并与最终用户、产品经理保持联系。架构师只对最终的需求审核和确认，提出需求不清和不完整的部分，他会跟需求分析员时刻保持联系。架构师是技术专家，不是业务专家。 3、架构师从来不写代码 这是一个尚存争论的问题。目前有两种观点：观点1：架构师不写代码，写代码纯体力活，架构师写代码大材小用。架构师把UML的各种视图交给开发人员，如果有不明确的地方，可以与架构师随时沟通。观点2：架构师本来自于程序员，只是比程序员站的层面更高，比程序员唯一多的是经验和知识，所以架构师也免不了写代码。 我个人觉得这两种说法是与架构师的出身和所处的环境有关。 架构师首先是一个技术角色，所以一定是来自于技术人员这个群体，比如系统架构师，多是来自于运维人员，可能本身代码写得并不多，或者说写不出来很漂亮的代 码。软件架构师多是来自于程序员，有着程序员的血统和情怀，所以在项目开发过程中，可能会写一些核心代码。我们的理想是架构师不用写代码，但事实上有时候 过于理想。架构师写不写代码，可能取决于公司的规模、文化、开发人员的素质等现实情况。另外，架构师也不是跟程序员界限分得那么清楚，按照能力也有高中低 之分，写不写代码不是区分两者的根本标准。 3.4 架构师的基本素质周星驰有个片子《喜剧之王》，剧中的尹天仇整天揣着本《演员的自我修养》，一个好演员不仅需要天赋，也需要一定的理论指导，无师自通的人毕竟是少 数。架构师的成长过程也是这样。从普通程序员到高级程序员，再到架构师，是一个经验积累和思想升华的过程。经验积累是一个方面，素质培养是另一个方面，两 者相辅相成，所以我觉得有必要把架构师的所要具备的素质罗列一下，作为程序员努力的方向。 1、沟通能力 为了提高效率，架构师必须赢得团队成员、项目经理、客户或用户认同，这就需要架构师具有较强的沟通能力。沟通能力是人类最普遍性的素质要求，技术人员好像 容易忽略，想成为架构师就不能忽略。千万不要抱着这样的观念：怀才跟怀孕似的，时间久了总会被人发现的。还是天桥上卖大力丸的哥们说得对：光说不练假把 式，光练不说傻把式。看看你周围的头头脑脑们，哪一个不是此中高手，我们千万不要鄙视，认为这是阿谀奉承、投机钻营，凡事都要看到积极的一面，“沟通”的 确是一种能力。我认为自己是一个略内向的人，因为我是农村出来的孩子，普通话都说不好，以前或多或少带有点自卑感，幻想着是金子总会发光，所以在职业生涯 中吃了不少亏。现在，我深深懂得了沟通的重要性，我会很主动地跟同事们，跟老大们不定时地沟通，感觉工作起来顺畅多了。 这一条我认为最为重要，所以排在首位。我甚至认为下面几条都可以忽略，唯一这一条得牢记，而且要常常提醒自己。 2、领导能力架构师能够推动整个团队的技术进展，能在压力下作出关键性的决策，并将其贯彻到底。架构师如何来保证这种执行力？这就需要架构师具有领导能力。 架构师的领导能力的取得跟项目经理不太一样。项目经理主要负责解决行政管理，这种能力与技术关系不大，他有人权和财权，再扯上一张“领导”的虎皮，采用“ 胡萝卜加大棒”的方式，基本上可以保证执行力。架构师在项目里面可能更多地使用非正式的领导力，也就是我们常说的影响力，里面包括个人魅力、技术能力、知 识传递等等。 3、抽象思维和分析能力 架构师必须具备抽象思维和分析的能力，这是你进行系统分析和系统分解的基本素质。只有具备这样的能力，架构师才能看清系统的整体，掌控全局，这也是架构师 大局观的形成基础。你如何具备这种能力呢？一是来自于经验，二是来自于学习。架构师不仅要具备在问题领域上的经验，也需要具备在软件工程领域内的经验。也 就是说，架构师必须能够准确得理解需求，然后用软件工程的思想，把需求转化和分解成可用计算机语言实现的程度。经验的积累是需要一个时间过程的，这个过程 谁也帮不了你，是需要你去经历的。但是，如果你有意识地去培养，不断吸取前人的经验的话，还是可以缩短这个周期的。这也是我写作此系列的始动力之一。 4、技术深度和广度 架构师最好精通1-2个技术，具备这种技术能力可以更加深入的理解有关架构的工作原理，也可以拉近和开发人员的距离，并形成团队中的影响力。 架构师的技术知识广度也很重要，需要了解尽可能多的技术，所谓见多识广，只有这样，才可能综合各种技术，选择更加适合项目的解决方案。有的人说，架构师技术广度的要求高于技术深度的要求，这是很有道理的。总而言之，一句话：架构师是项目团队中的技术权威。 面向过程和面向对象这两个基本概念，不仅架构师需要非常清楚，程序员、设计师也要非常清楚，这也是系统分析、设计和编码最基本的常识。我接触的程序 员，很多人只停留在一种“似是而非”的程度，这是不行的，想要继续前进，就得把基础夯实，所以我觉得很有必要先回回炉，补补课。 架构师之路(4)—详解面向对象3.5 详解面向对象的编程(OOP)3.5.1 什么是面向对象 刚接触编程的时候，多数人本能的反映可能是面向过程(OP)的，而不是面向对象(OO)的。这种现象其实是很正常的，改变思维方式是需要一个过程的，我大体归纳了一下其形成的原因： 1、直接原因 你还没有养成面向对象分析问题和解决问题的习惯。建立面向对象的思维方式需要一定时间的训练和揣摩才能形成，所以你可以在学习或具体项目中刻意地强化这种意识。一般情况下，经过一段时间之后，你会觉得这是自然而然的事情，只有心中OO，眼中自然OO了。 2、历史原因 我们从小接受的培训都是采用面向过程(OP)的方式分析问题和解决问题，尤其是数学，多数是强调按部就班的解决问题，计算机软件的发展一直就与数学是很有渊源，所以，顺理成章的，把面向过程(OP)的方式带入到软件开发也是很自然的事情。 什么是面向对象，或者谈谈你对面向对象的理解，这恐怕是软件开发人员，尤其是程序员和设计师应聘的时候，面试官常最挂在嘴边的问题吧。面向对象对应的英文 是Object-Oriented，把Object-Oriented翻译成“面向对象”，我一直觉得这个译法不太确切，因为多数人第一次看到“面向对象 ”这四个字，都很难从字面上理解它到底是什么意思。后来，我又查阅了一些有关的资料，发现港澳台的计算机书籍中是把它翻译成了“物件导向”，这个译法，我 感觉不错，于我心颇有些戚戚焉。“物件导向”比较准确地反映了面向对象认识和解决问题都是要围绕对象展开的。 所以，面向对象的思维方式认为：软件系统是一组交互的对象的集合。一组相关的对象组合为一个子系统，一组子系统继续组合为更复杂的子系统，直至组合成整个系统。 面向对象方式的出发点是尽可能模拟人类习惯的思维方式，将“问题域”中涉及的内容抽象为“对象”，使软件开发的方法与过程尽可能接近人类认识世界解决问题的方法与过程。 面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。面向对象是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。 面向过程认识和解决问题的思维，可以称为“流程论”，重点放在处理过程的步骤，流程是整个系统的核心。 面向对象认识和解决问题的思维，可以称为“组装论”，重心放在对象的抽象和提取上，然后将对象组装为整体。 所以OO和OP从思维方式来讲，出发点还是完全不同的。 3.5.2 OP PK OO 咱们用象棋对战的例子，来比较OP和OO的不同： 采用面向过程(OPP)的设计思路，首先分拆整个对战过程，分析双方对战的步骤，得到如下流程： 把上面每个步骤分别用函数进行实现，问题就解决了。 我们再来看看面向对象是如何来解决问题，整个象棋游戏可以抽象出3种对象：1、棋手，负责行棋，这两者行为一致。2、棋盘，负责绘制棋盘画面。3、裁判，负责判定诸如吃子、犯规和输赢。 三者之间的关系如下： 第一类对象棋手负责行棋，并告知第二类对象棋盘中棋子布局的变化，棋盘接收到了棋子布局的变化后，负责在绘制屏幕，同时利用第三类对象裁判来对棋局进行判定。从以上两种的实现方式可以看出几点： 1、可维护性 面向对象是以数据和功能来划分问题，而不是依据流程和步骤。同样是绘制棋盘的行为，在面向过程的设计中分散在了很多的步骤中，很可能出现在不同的绘制版本 中，只是不是很像一份“蛋炒饭”中的鸡蛋？在面向对象的设计中，绘图只可能在棋盘对象中出现，从而保证了绘图的统一，这就是把鸡蛋从“蛋炒饭”中分离出来 的效果。 2、可扩展性 假如我要加入悔棋的功能，如果要改动面向过程的设计，那么从行棋到显示再到判定这一连串的步骤都要改动，甚至步骤之间的循序都要进行大规模调整。如果是面 向对象的话，只用改动棋盘对象就行了，棋盘对象保存了双方的棋谱，简单回溯，减一就可以了，而显示和判定不涉及，同时整体对各个对象功能的调用顺序都没有 变化，改动只限定在了局部。 3.5.3 OO的深层思考 OO认为：软件系统是一组交互的对象的集合。 因为人类对现实世界是非常熟悉的，所以OO就是通过抽象的方式，把问题域映射到现实世界，尽量模拟现实世界的万事万物。通过这种方式，就可以运用现实世界中解决问题的方法与过程，来解决软件领域内的问题。有人说：OO眼里一切皆对象，这句话还是很有道理的。OO到底给软件开发带来了什么样的好处？OO的抽象的尺度是如何把握的呢？这都是问题。 架构师之路(5)—面向对象的设计原则1 OO的设计原则 采用面向对象的分析和设计思想，为我们分析和解决问题提供了一种全新的思维方式。我们在拿到需求之后(略去OOA，以后补全)，接下来的问题就是：如何对系统进行面向对象的设计呢？ 按照软件工程的理论，面向对象的设计要解决的核心问题就是可维护性和可复用性，尤其是可维护性，它是影响软件生命周期重要因素。通常情况下，软件的维护成本远远大于初期开发成本。 一个可维护性很差的软件设计，人们通常称之为“臭味”的，形成的原因主要有这么几个：过于僵硬、过于脆弱、复用率低或者黏度过高。相反，一个好的系统设计 应该是灵活的、可扩展的、可复用的、可插拔的。在20世纪80到90年代，很多业内专家不断探索面向对象的软件设计方法，陆续提出了一些设计原则。这些设 计原则能够显著地提高系统的可维护性和可复用性，成为了我们进行面向对象设计的指导原则： 1、单一职责原则SRP 每一个类应该专注于做一件事情。 2、“开-闭”原则OCP 每一个类应该是对扩展开放，对修改关闭。 3、 里氏代换原则LSP 避免造成派生类的方法非法或退化，一个基类的用户应当不需要知道这个派生类。 4、 依赖倒转原则DIP 用依赖于接口和抽象类来替代依赖容易变化的具体类。 5、 接口隔离原则ISP 应当为客户提供尽可能小的接口，而不是提供大的接口。 其中，“开-闭”原则是面向对象的可复用设计的基石，其他设计原则（里氏代换原则、依赖倒转原则、合成/聚合复用原则、迪米特法则、接口隔离原则）是实现“开-闭”原则的手段和工具。我会为大家一一进行讲解。 2 单一职责原则SRP(Single-Responsibility Principle)2.1 什么是单一职责 单一职责就是指一个类应该专注于做一件事。现实生活中也存在诸如此类的问题：“一个人可能身兼数职，甚至于这些职责彼此关系不大，那么他可能无法做好所有职责内的事情，所以，还是专人专管比较好。”我们在设计类的时候，就应该遵循这个单一职责原则。 记得有人比喻过软件开发、设计原则、设计模式之间的关系就是战争、战略和战术的关系，关于设计模式实际上是设计原则的具体应用，以后我们还会讲到这一点。另外，大家都很熟悉计算器的例子，很多的人都愿意以此为例，我们也以计算器编程为例说明单一职责原则： 在有些人眼里，计算器就是一件东西，是一个整体，所以它把这个需求进行了抽象，最终设计为一个Calculator类，代码如下： 1234567891011121314151617181920212223242526272829class Calculator&#123; public String calculate() &#123; Console.Write("Please input the first number:"); String strNum1 = Console.ReadLine(); Console.Write(Please input the operator:"); String strOpr= Console.ReadLine(); Console.Write("Please input the second number:"); String strNum2 = Console.ReadLine(); String strResult = ""; if (strOpr == "+")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) + Convert.ToDouble(strNum2)); &#125; else if (strOpr == "-")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) - Convert.ToDouble(strNum2)); &#125; else if (strOpr == "*")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) * Convert.ToDouble(strNum2)); &#125; else if (strOpr == "/")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) / Convert.ToDouble(strNum2)); &#125; Console.WriteLine("The result is " + strResult); &#125; &#125; 另外，还有一部分人认为：计算器是一个外壳和一个处理器的组合。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Appearance&#123; public int displayInput(String &amp;strNum1,String &amp;strOpr, String &amp;strNum2) &#123; Console.Write("Please input the first number:"); strNum1 = Console.ReadLine(); Console.Write(Please input the operator:"); strOpr= Console.ReadLine(); Console.Write("Please input the second number:"); strNum2 = Console.ReadLine(); return 0; &#125; public String displayOutput(String strResult) &#123; Console.WriteLine("The result is " + strResult); &#125;&#125; class Processor&#123; public String calculate(String strNum1,String strOpr, String strNum2)&#123; String strResult = ""; if (strOpr == "+")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) + Convert.ToDouble(strNum2)); &#125; else if (strOpr == "-")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) - Convert.ToDouble(strNum2)); &#125; else if (strOpr == "*")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) * Convert.ToDouble(strNum2)); &#125; else if (strOpr == "/")&#123;strResult = Convert.ToString(Convert.ToDouble(strNum1) / Convert.ToDouble(strNum2)); &#125; return strResult; &#125;&#125; 为什么这么做呢？因为外壳和处理器是两个职责，是两件事情，而且都是很容易发生需求变动的因素，所以把它们放到一个类中，违背了单一职责原则。 比如，用户可能对计算器提出以下要求： 第一，目前已经实现了“加法”、“减法”、“乘法”和“除法”，以后还可能出现“乘方”、“开方”等很多运算。 第二，现在人机界面太简单了，还可能做个Windows计算器风格的界面或者Mac计算器风格的界面。所以，把一个类Calculator 拆分为两个类Appearance和Processor，一个类做一件事情，这样更容易应对需求变化。如果界面需要修改，那么就去修改Appearance类；如果处理器需要修改，那么就去修改Processor类。 我们再举一个邮件的例子。我们平常收到的邮件内容，看起来是一封信，实际上内部有两部分组成：邮件头和邮件体。电子邮件的编码要求符合RFC822标准。第一种设计方式是这样：interface IEmail { public void setSender(String sender); public void setReceiver(String receiver); public void setContent(String content);} class Email implements IEmail { public void setSender(String sender) {// set sender; } public void setReceiver(String receiver) {// set receiver; } public void setContent(String content) {// set content; }} 这个设计是有问题的，因为邮件头和邮件体都有变化的可能性。1、邮件头的每一个域的编码，可能是BASE64，也可能是QP，而且域的数量也不固定。2、邮件体中封装的邮件内容可能是PlainText类型,也可能是HTML类型，甚至于流媒体。所谓第一种设计方式违背了单一职责原则，里面封装了两种可能引起变化的原因。我们依照单一职责原则，对其进行改进后，变为第二种设计方式： 123456789101112131415interface IEmail &#123; public void setSender(String sender); public void setReceiver(String receiver); public void setContent(IContent content);&#125;interface IContent &#123; public String getAsString();&#125;class Email implements IEmail &#123; public void setSender(String sender) &#123;// set sender; &#125; public void setReceiver(String receiver) &#123;// set receiver; &#125; public void setContent(IContent content) &#123;// set content; &#125;&#125; 有的资料把单一职责解释为：“仅有一个引起它变化的原因”。这个解释跟“专注于做一件事”是等价的。如果一个类同时做两件事情，那么这两件事情都有可能引起它的变化。同样的道理，如果仅有一个引起它变化的原因，那么这个类也就只能做一件事情。 2.2 单一职责原则的使用 单一职责原则的尺度如何掌握？我们怎么能知道该拆分还是不应该拆分呢？原则很简单：需求决定。如果你所需要的计算器，永远都没有外观和处理器变动的可能 性，那么就应该把它抽象为一个整体的计算器；如果你所需要的计算器，外壳和处理器都有可能发生变动，那么就必须把它拆离为外壳和处理器。单一职责 原则实际上是把相同的职责进行了聚合，避免把相同的职责分散到不同的类之中，这样就可以控制变化，把变化限制在一个地方，防止因为一个地方的变动，引起更 多地方的变动的“涟漪效应”，单一职责原则避免一个类承担过多的职责。单一职责原则不是说一个类就只有一个方法，而是具有单一功能。 我们在使用单一职责原则的时候，牢记以下几点：A、一个设计合理的类，应该仅有一个可以引起它变化的原因，即单一职责，如果有多个原因可以引起它的变化，就必须进行分离；B、在没有需求变化征兆的情况下，应用单一职责原则或其他原则是不明智的，因为这样会使系统变得很复杂，系统将会变成一堆细小的颗粒组成，纯属于没事找抽；C、在需求能够预计或实际发生变化时，就应该使用单一职责原则来重构代码，有经验的设计师、架构师对可能出现的需求变化很敏感，设计上就会具有一定的前瞻性。 架构师之路(6)—OOD的开闭原则2 开闭原则（Open-Closed Principle,OCP）2.1 什么是开闭原则 开闭原则是面向对象设计中“可复用设计”的基石，是面向对象设计中最重要的原则之一，其它很多的设计原则都是实现开闭原则的一种手段。 1988年，Bertrand Meyer在他的著作《Object Oriented Software Construction》中提出了开闭原则，它的原文是这样：“Software entities should be open for extension,but closed for modification”。翻译过来就是：“软件实体应当对扩展开放，对修改关闭”。这句话说得略微有点专业，我们把它讲得更通俗一点，也就是：软件系统中包含的各种组件，例如模块（Modules）、类（Classes）以及功能（Functions）等等，应该在不修改现有代码的基础上，引入新功能。开闭原则中“开”，是指对于组件功能的扩展是开放的，是允许对其进行功能扩展的；开闭原则中“闭”，是指对于原有代码的修改是封闭的，即不应该修改原有的代码。 2.2 如何实现开闭原则 实现开闭原则的关键就在于“抽象”。把系统的所有可能的行为抽象成一个抽象底层，这个抽象底层规定出所有的具体实现必须提供的方法的特征。作为系统设计的抽象层，要预见所有可能的扩展，从而使得在任何扩展情况下，系统的抽象底层不需修改；同时，由于可以从抽象底层导出一个或多个新的具体实现，可以改变系统的行为，因此系统设计对扩展是开放的。 我们在软件开发的过程中，一直都是提倡需求导向的。这就要求我们在设计的时候，要非常清楚地了解用户需求，判断需求中包含的可能的变化，从而明确在什么情况下使用开闭原则。 关于系统可变的部分，还有一个更具体的对可变性封装原则（Principle of Encapsulation of Variation, EVP），它从软件工程实现的角度对开闭原则进行了进一步的解释。EVP要求在做系统设计的时候，对系统所有可能发生变化的部分进行评估和分类，每一个可变的因素都单独进行封装。 我们在实际开发过程的设计开始阶段，就要罗列出来系统所有可能的行为，并把这些行为加入到抽象底层，根本就是不可能的，这么去做也是不经济的，费时费力。另外，在设计开始阶段，对所有的可变因素进行预计和封装也不太现实，也是很难做得到。所以，开闭原则描绘的愿景只是一种理想情况或是极端状态，现实世界中是很难被完全实现的。我们只能在某些组件，在某种程度上符合开闭原则的要求。 通过以上的分析，对于开闭原则，我们可以得出这样的结论：虽然我们不可能做到百分之百的封闭，但是在系统设计的时候，我们还是要尽量做到这一点。 对于软件系统的功能扩展，我们可以通过继承、重载或者委托等手段实现。以接口为例，它对修改就是是封闭的，而对具体的实现是开放的，我们可以根据实际的需要提供不同的实现，所以接口是符合开闭原则的。 2.3 开闭原则能够带来什么好处 如果一个软件系统符合开闭原则的，那么从软件工程的角度来看，它至少具有这样的好处：  可复用性好。 我们可以在软件完成以后，仍然可以对软件进行扩展，加入新的功能，非常灵活。因此，这个软件系统就可以通过不断地增加新的组件，来满足不断变化的需求。  可维护性好。 由于对于已有的软件系统的组件，特别是它的抽象底层不去修改，因此，我们不用担心软件系统中原有组件的稳定性，这就使变化中的软件系统有一定的稳定性和延续性。 2.4 开闭原则与其它原则的关系 开闭原则具有理想主义的色彩，它是面向对象设计的终极目标。因此，针对开闭原则的实现方法，一直都有面向对象设计的大师费尽心机，研究开闭原则的实现方式。后面要提到的里氏代换原则（LSP）、依赖倒转原则（DIP）、接口隔离原则（ISP）以及抽象类（Abstract Class）、接口(Interace)等等，都可以看作是开闭原则的实现方法。 架构师之路(7)—里氏代换原则4 里氏代换原则（Liskov Substitution Principle, LSP）4.1 什么是里氏代换原则 里氏代换原则是由麻省理工学院（MIT）计算机科学实验室的Liskov女士，在1987年的OOPSLA大会上发表的一篇文章《Data Abstraction and Hierarchy》里面提出来的，主要阐述了有关继承的一些原则，也就是什么时候应该使用继承，什么时候不应该使用继承，以及其中的蕴涵的原理。2002年，我们前面单一职责原则中提到的软件工程大师Robert C. Martin，出版了一本《Agile Software Development Principles Patterns and Practices》，在文中他把里氏代换原则最终简化为一句话：“Subtypes must be substitutable for their base types”。也就是，子类必须能够替换成它们的基类。 我们把里氏代换原则解释得更完整一些：在一个软件系统中，子类应该可以替换任何基类能够出现的地方，并且经过替换以后，代码还能正常工作。 4.2 第一个例子：正方形不是长方形 “正方形不是长方形”是一个理解里氏代换原则的最经典的例子。在数学领域里，正方形毫无疑问是长方形，它是一个长宽相等的长方形。所以，我们开发的一个与几何图形相关的软件系统中，让正方形继承自长方形是顺利成章的事情。现在，我们截取该系统的一个代码片段进行分析：长方形类Rectangle: 12345678class Rectangle &#123; double length; double width; public double getLength() &#123; return length; &#125; public void setLength(double height) &#123; this.length = length; &#125; public double getWidth() &#123; return width; &#125; public void setWidth(double width) &#123; this.width = width; &#125; &#125; 正方形类Square: 12345678910class Square extends Rectangle &#123; public void setWidth(double width) &#123; super.setLength(width); super.setWidth(width); &#125; public void setLength(double length) &#123; super.setLength(length); super.setWidth(length); &#125; &#125; 由于正方形的度和宽度必须相等，所以在方法setLength和setWidth中，对长度和宽度赋值相同。类TestRectangle是我们的软件系统中的一个组件，它有一个resize方法要用到基类Rectangle，resize方法的功能是模拟长方形宽度逐步增长的效果: 测试类TestRectangle： 1234567class TestRectangle &#123; public void resize(Rectangle objRect) &#123; while(objRect.getWidth() &lt;= objRect.getLength() ) &#123; objRect.setWidth( objRect.getWidth () + 1 ); &#125; &#125;&#125; 我们运行一下这段代码就会发现，假如我们把一个普通长方形作为参数传入resize方法，就会看到长方形宽度逐渐增长的效果，当宽度大于长度,代码就会停止，这种行为的结果符合我们的预期；假如我们再把一个正方形作为参数传入resize方法后，就会看到正方形的宽度和长度都在不断增长，代码会一直运行下去，直至系统产生溢出错误。所以，普通的长方形是适合这段代码的，正方形不适合。 我们得出结论：在resize方法中，Rectangle类型的参数是不能被Square类型的参数所代替，如果进行了替换就得不到预期结果。因此，Square类和Rectangle类之间的继承关系违反了里氏代换原则，它们之间的继承关系不成立，正方形不是长方形。 #### 4.3 第二个例子：鸵鸟不是鸟 “鸵鸟非鸟”也是一个理解里氏代换原则的经典的例子。“鸵鸟非鸟”的另一个版本是“企鹅非鸟”，这两种说法本质上没有区别，前提条件都是这种鸟不会飞。生物学中对于鸟类的定义：“恒温动物，卵生，全身披有羽毛，身体呈流线形，有角质的喙，眼在头的两侧。前肢退化成翼，后肢有鳞状外皮，有四趾”。所以，从生物学角度来看，鸵鸟肯定是一种鸟。我们设计一个与鸟有关的系统，鸵鸟类顺理成章地由鸟类派生，鸟类所有的特性和行为都被鸵鸟类继承。大多数的鸟类在人们的印象中都是会飞的，所以，我们给鸟类设计了一个名字为fly的方法，还给出了与飞行相关的一些属性,比如飞行速度（velocity）。 鸟类Bird: 1234567class Bird &#123;double velocity;public fly() &#123; //I am flying; &#125;;public setVelocity(double velocity) &#123; this.velocity = velocity; &#125;;public getVelocity() &#123; return this.velocity; &#125;;&#125; 鸵鸟不会飞怎么办？我们就让它扇扇翅膀表示一下吧，在fly方法里什么都不做。至于它的飞行速度，不会飞就只能设定为0了，于是我们就有了鸵鸟类的设计。鸵鸟类Ostrich: 12345class Ostrich extends Bird &#123; public fly() &#123; //I do nothing; &#125;; public setVelocity(double velocity) &#123; this.velocity = 0; &#125;;public getVelocity() &#123; return 0; &#125;;&#125; 好了，所有的类都设计完成，我们把类Bird提供给了其它的代码（消费者）使用。现在，消费者使用Bird类完成这样一个需求：计算鸟飞越黄河所需的时间。 对于Bird类的消费者而言，它只看到了Bird类中有fly和getVelocity两个方法，至于里面的实现细节，它不关心，而且也无需关心，于是给出了实现代码：测试类TestBird: 12345678910class TestBird &#123;public calcFlyTime(Bird bird) &#123;try&#123; double riverWidth = 3000; System.out.println(riverWidth / bird.getVelocity());&#125;catch(Exception err)&#123; System.out.println("An error occured!");&#125;&#125;;&#125; 如果我们拿一种飞鸟来测试这段代码，没有问题，结果正确，符合我们的预期，系统输出了飞鸟飞越黄河的所需要的时间；如果我们再拿鸵鸟来测试这段代码，结果代码发生了系统除零的异常，明显不符合我们的预期。 对于TestBird类而言，它只是Bird类的一个消费者，它在使用Bird类的时候，只需要根据Bird类提供的方法进行相应的使用，根本不会关心鸵鸟会不会飞这样的问题，而且也无须知道。它就是要按照“所需时间 = 黄河的宽度 / 鸟的飞行速度”的规则来计算鸟飞越黄河所需要的时间。 我们得出结论：在calcFlyTime方法中，Bird类型的参数是不能被Ostrich类型的参数所代替，如果进行了替换就得不到预期结果。因此，Ostrich类和Bird类之间的继承关系违反了里氏代换原则，它们之间的继承关系不成立，鸵鸟不是鸟。 4.4 鸵鸟到底是不是鸟? “鸵鸟到底是不是鸟”，鸵鸟是鸟也不是鸟，这个结论似乎就是个悖论。产生这种混乱有两方面的原因：原因一：对类的继承关系的定义没有搞清楚。 面向对象的设计关注的是对象的行为，它是使用“行为”来对对象进行分类的，只有行为一致的对象才能抽象出一个类来。我经常说类的继承关系就是一种“Is-A”关系，实际上指的是行为上的“Is-A”关系，可以把它描述为“Act-As”。关于类的继承的细节，我们可以单独再讲。 我们再来看“正方形不是长方形”这个例子，正方形在设置长度和宽度这两个行为上，与长方形显然是不同的。长方形的行为：设置长方形的长度的时候，它的宽度保持不变，设置宽度的时候，长度保持不变。正方形的行为：设置正方形的长度的时候，宽度随之改变；设置宽度的时候，长度随之改变。所以，如果我们把这种行为加到基类长方形的时候，就导致了正方形无法继承这种行为。我们“强行”把正方形从长方形继承过来，就造成无法达到预期的结果。 “鸵鸟非鸟”基本上也是同样的道理。我们一讲到鸟，就认为它能飞，有的鸟确实能飞，但不是所有的鸟都能飞。问题就是出在这里。如果以“飞”的行为作为衡量“鸟”的标准的话，鸵鸟显然不是鸟；如果按照生物学的划分标准：有翅膀、有羽毛等特性作为衡量“鸟”的标准的话，鸵鸟理所当然就是鸟了。鸵鸟没有“飞”的行为，我们强行给它加上了这个行为，所以在面对“飞越黄河”的需求时，代码就会出现运行期故障。 原因二：设计要依赖于用户要求和具体环境。 继承关系要求子类要具有基类全部的行为。这里的行为是指落在需求范围内的行为。图中鸟类具有4个对外的行为，其中2个行为分别落在A和B系统需求中： 系统需求和对象关系示意图 A需求期望鸟类提供与飞翔有关的行为，即使鸵鸟跟普通的鸟在外观上就是100%的相像，但在A需求范围内，鸵鸟在飞翔这一点上跟其它普通的鸟是不一致的，它没有这个能力，所以，鸵鸟类无法从鸟类派生，鸵鸟不是鸟。 B需求期望鸟类提供与羽毛有关的行为，那么鸵鸟在这一点上跟其它普通的鸟一致的。虽然它不会飞，但是这一点不在B需求范围内，所以，它具备了鸟类全部的行为特征，鸵鸟类就能够从鸟类派生，鸵鸟就是鸟。 所有派生类的行为功能必须和使用者对其基类的期望保持一致，如果派生类达不到这一点，那么必然违反里氏替换原则。在实际的开发过程中，不正确的派生关系是非常有害的。伴随着软件开发规模的扩大，参与的开发人员也越来越多，每个人都在使用别人提供的组件，也会为别人提供组件。最终，所有人的开发的组件经过层层包装和不断组合，被集成为一个完整的系统。每个开发人员在使用别人的组件时，只需知道组件的对外裸露的接口，那就是它全部行为的集合，至于内部到底是怎么实现的，无法知道，也无须知道。所以，对于使用者而言，它只能通过接口实现自己的预期，如果组件接口提供的行为与使用者的预期不符，错误便产生了。里氏代换原则就是在设计时避免出现派生类与基类不一致的行为。 4.5 如何正确地运用里氏代换原则里氏代换原则目的就是要保证继承关系的正确性。我们在实际的项目中，是不是对于每一个继承关系都得费这么大劲去斟酌？不需要，大多数情况下按照“Is-A”去设计继承关系是没有问题的，只有极少的情况下，需要你仔细处理一下，这类情况对于有点开发经验的人，一般都会觉察到，是有规律可循的。最典型的就是使用者的代码中必须包含依据子类类型执行相应的动作的代码：动物类Animal： 12345678910111213public class Animal&#123; String name; public Animal(String name) &#123; this.name = name; &#125; public void printName()&#123; try&#123; System.out.println("I am a " + name + "!"); &#125;catch(Exception err)&#123; System.out.println("An error occured!"); &#125;&#125;&#125; 猫类Cat： 123456789101112public class Cat extends Animal&#123; public Cat(String name)&#123; super(name); &#125; public void Mew()&#123; try&#123; System.out.println("Mew~~~ "); &#125;catch(Exception err)&#123; System.out.println("An error occured!"); &#125; &#125;&#125; 狗类Dog： 123456789101112public class Dog extends Animal &#123; public Dog(String name) &#123; super(name); &#125; public void Bark()&#123; try&#123; System.out.println("Bark~~~ "); &#125;catch(Exception err)&#123; System.out.println("An error occured!"); &#125;&#125;&#125; 测试类：TestAnimal 123456789101112131415public class TestAnimal &#123;public void TestLSP(Animal animal)&#123; if (animal instanceof Cat )&#123;Cat cat = (Cat)animal;cat.printName();cat.Mew(); &#125; if (animal instanceof Dog )&#123; Dog dog = (Dog)animal; dog.printName(); dog.Bark(); &#125; &#125;&#125; 象这种代码是明显不符合里氏代换原则的，它给使用者使用造成很大的麻烦，甚至无法使用，对于以后的维护和扩展带来巨大的隐患。实现开闭原则的关键步骤是抽象化，基类与子类之间的继承关系就是一种抽象化的体现。因此，里氏代换原则是实现抽象化的一种规范。违反里氏代换原则意味着违反了开闭原则，反之未必。里氏代换原则是使代码符合开闭原则的一个重要保证。 我们常见这样的代码，至少我以前的Java和PHP项目中就出现过。比如有一个网页，要实现对于客户资料的查看、增加、修改、删除功能，一般Server端对应的处理类中都有这么一段： 123456789101112if(action.Equals(“add”))&#123; //do add action&#125;else if(action.Equals(“view”))&#123; //do view action&#125;else if(action.Equals(“delete”))&#123; //do delete action&#125;else if(action.Equals(“modify”))&#123; //do modify action&#125; 大家都很熟悉吧，其实这是违背里氏代换原则的，结果就是可维护性和可扩展性会变差。有人说：我这么用，效果好像不错，干嘛讲究那么多呢，实现需求是第一位的。另外，这种写法看起来很很直观的，有利于维护。其实，每个人所处的环境不同，对具体问题的理解不同，难免局限在自己的领域内思考问题。对于这个说法，我觉得应该这么解释：作为一个设计原则，是人们经过很多的项目实践，最终提炼出来的指导性的内容。如果对于你的项目来讲，显著增加了工作量和复杂度，那我觉得适度的违反并不为过。做任何事情都是个度的问题，过犹不及都不好。在大中型的项目中，是一定要讲究软件工程的思想，讲究规范和流程的，否则人员协作和后期维护将会是非常困难的。对于小型的项目可能相应的要简化很多，可能取决于时间、资源、商业等各种因素，但是多从软件工程的角度去思考问题，对于系统的健壮性、可维护性等性能指标的提高是非常有益的。像生命周期只有一个月的系统，你还去考虑一大堆原则，除非脑袋被驴踢了。 实现开闭原则的关键步骤是抽象化，基类与子类之间的继承关系就是一种抽象化的体现。因此，里氏代换原则是实现抽象化的一种规范。违反里氏代换原则意味着违反了开闭原则，反之未必。里氏代换原则是使代码符合开闭原则的一个重要保证。 通过里氏代换原则给我们带来了什么样的启示？ 类的继承原则：如果一个继承类的对象可能会在基类出现的地方出现运行错误，则该子类不应该从该基类继承，或者说，应该重新设计它们之间的关系。 动作正确性保证：符合里氏代换原则的类扩展不会给已有的系统引入新的错误。 架构师之路(39)—IoC框架1 IoC理论的背景 我们都知道在面向对象的应用中，软件系统都是由N个对象组成的，它们通过彼此的合作，最终实现业务逻辑。 图1：耦合在一起的对象 如果我们打开机械式手表的后盖，就会看到与上面类似的情形，各个齿轮分别带动时针、分针和秒针顺时针旋转，从而在表盘上产生正确的时间。上图画的就是这样 的一个齿轮组，它拥有多个独立的齿轮，这些齿轮相互啮合在一起，协同工作，来共同完成某项任务。我们可以看到，在齿轮组中，如果有一个齿轮出了问题，就可 能会影响到整个齿轮组的运转。 齿轮组中各个齿轮之间的啮合关系,与软件系统中对象与对象之间的耦合关系，非常类似。对象之间的耦合关系是必要的，是协同工作的基础，当然也是无法避免 的，否则无法保证系统整体的正常运转。目前，很多工业级的应用越来越庞大，对象之间的依赖关系也越来越复杂，就会出现对象之间的多重依赖性关系，因此，架 构师和设计师对系统进行分析和设计将面临很大的挑战。对象之间耦合度过高的系统，必然会出现牵一发而动全身的情形。 图2：对象之间复杂的依赖关系 耦合关系不仅会出现在对象与对象之间，也会出现在软件系统的各模块之间，以及软件系统和硬件系统之间。如何降低系统之间、模块之间和对象之间的耦合度，是软件工程永远追求的目标之一。 所以有人就提出来IOC理论，用来实现对象之间的“解耦”，目前已被广泛应用于很多项目中。 2 什么是控制反转(IoC) IoC是Inversion of Control的缩写，多数书籍翻译成“控制反转”，还有些书籍翻译成为“控制反向”或者“控制倒置”，这些都大同小异，我个人觉得这个翻译有待商榷，容易引起歧义，是不是翻译为 “控制转移”会更好一些。 1996年，Michael Mattson在一篇有关探讨面向对象框架的文章中，首先提出了IoC 这个概念。对于面向对象设计及编程的基本思想，前面我们已经讲了很多了，不再赘述，读者可以参考我前面的文章，简单来说就是把复杂系统分解成相互合作的对 象，这些对象类的内部实现是透明的，从而降低了解决问题的复杂度，而且可以灵活地被重用和扩展。IoC理论提出的观点大体是这样的：借助于“第三方”实现 具有依赖关系的对象之间的解耦，如下图： 图3：IoC解耦示意图 大家看到了吧，由于引进了中间的“第三方”，也就是IoC容器，使得A、B、C、D这4个对象没有了耦合关系，齿轮之间的传动全部依靠“第三方”了，所有 对象的控制权全部上缴给“第三方”，这就是“控制反转”说法的由来，意思就是各个对象的控制权都被转移给“第三方”了。 从另一个角度来看，作为“第三方”的IoC容器成了整个系统的关键核心，它起到了一种类似“粘合剂”的作用，把系统中的所有对象粘合在一起发挥作用，如果没有这个“粘合剂”，对象与对象之间会彼此失去联系，这就是所谓的Ioc容器被称为“粘合剂”的原因。 我们再把上图中间的Ioc容器拿掉后，整个系统变为这样的情形： 图4：拿掉IoC容器后的系统 拿掉IoC容器后，我们看到的就是系统开发所需要完成的全部内容，这时候，A、B、C、D这4个对象之间已经没有了耦合关系，彼此毫不影响，所以当你在实 现Class A的时候，根本不用再考虑B、C和D了，系统对象之间的依赖已经降低到了最低程度。至于IoC容器，你可以到开源组织的网站上找一找，里面有很多比较成熟 而且Free的，使用起来非常简便。如果真能实现控制反转，对于系统开发而言，这将是一件多么美好的事情！ 3 什么是依赖注入(DI) 我们先看一些生活中的例子，帮助你理解依赖注入(DI)： 3.1 主机和内置硬盘 我们平时所用的电脑，它的硬盘安装在主机里面，从电脑的外部，我们是看不见硬盘的。所以，我们通常认为，电脑的所有部件是融为一体的。 图5：主机和内置硬盘 对于一体机而言，一旦出现了问题，我们可能无法准确地判断到底是什么零部件出现了问题，有可能是CPU坏了，也有可能是主板烧了，还有可能是内存松动了。 还有的时候，比如，电脑硬盘出现了问题，可能导致整台电脑都无法使用。从这个例子，我们可以看到部件之间“紧密耦合”的产生的问题：无法准确的定位和诊断 故障所在。这种情形，在软件工程的理论中，称之为可理解性和可测试性差。 如果你想修理电脑的硬盘，那么在修理过程中就必须小心翼翼，不要把其它的部件再搞坏了，比如不慎把内存给碰松动了，硬盘固然是修好了，但整台电脑仍然无法使用。这种情形，在软件工程的理论中，称之为可修改性差。可理解性、可测试性、可修改性组成了系统的可维护性，一体机的可维护性就表现得比较差。 3.2 主机和USB设备 大家对USB接口和设备应该都很熟悉。自从有了USB接口，给我们使用电脑带来了很大的方便，现在有很多的外部设备都支持USB接口。 图6：主机和USB设备 从软件工程角度，我们分析一下USB带来的好处：1、USB设备作为主机的外部设备，在插入主机之前，与主机没有任何的关系，两者都可独立进行测试，无论两者中的任何一方出现什么的问题，都不会影响另一方的运行，所以可维护性比较好。2、同一个USB设备可以插接到不同的支持USB的任何主机，也就是USB设备可以被重复利用，所以可复用性比较好。3、支持热插拔，只要是支持USB接口的设备都可以接入，所以可扩展性比较好，非常灵活。 3.3 依赖注入 2004年，Martin Fowler从另一个角度来思考这个问题，提出了“哪些方面的控制被反转了？”这样一个问题，并给出了答案：“依赖对象的获得被反转”。于是，他给“控制 反转”取了一个他认为更合适的名字叫做“依赖注入（Dependency Injection）”。他的这个答案，实际上点明了实现IoC理论的解决方法。所谓依赖注入，就是由IoC容器在运行期间，动态地将某种依赖关系注入到 对象之中。 依赖注入(DI)和控制反转(IoC)是从不同的角度的描述的同一件事情，都是指通过引入第三方，即IoC容器，实现软件系统中对象之间的解耦。 控制反转能够带给系统开发的好处，与USB机制带来的好处基本类似，而且依赖注入的实现跟USB机制也完全一样。USB机制是现实中依赖注入的很好的案例。我们用一个实际的例子，分析一下USB机制： 任务：主机通过USB接口读取一个文件。思路：首先，必须制定一个USB接口标准，主机对USB设备的访问严格按照USB接口标准，USB设备提供的功能也必须符合USB接口标准。 当主机需要获取一个文件的时候，它直接去读取USB接口，根本不会关心USB接口上连接的是什么设备。如果我给主机连接上一个U盘，那么主机就从U盘上读取文件；如果我给主机连接上一个外接硬盘，那么主机就从外接硬盘上读取文件。选取何种外部设备的权力由我说了算，也就是控制权归我。至此,依赖注入的思路已经非常清楚：当主机需要读取文件的时候，我就把它所要依赖的外部设备，挑出来一个，帮他挂接上。这个过程就是一个被依赖的对象在系统运行时被注入另外一个对象内部的过程。在这个过程中，我就起到了IoC容器的作用。 我们再把依赖注入应用到软件工程中： Class A依赖于Class B,当Class A需要用到Class B的时候，IoC容器就会立刻创建一个Class B送给Class A使用。IoC容器就是一个类制造工厂，你需要什么，直接来拿，直接用就可以了，而不需要去关心你所用的东西是如何制成的，也不用关心最后是怎么被销毁 的，这一切全由IoC容器包办。 4 实现IoC容器 后记：之所以突然跳跃到39，是因为有的同学基础比较好，已经没有必要阅读有关面向对象、设 计模式以及软件工程的基本理论，那么可以从这里开始阅读。基础需要继续补全的同学，可以从4继续看，我会定期在两个方向进行更新。框架理论，是架构师知识 体系中非常重要的部分，我会逐步结合实例，把常见的一些框架方面的知识与大家共享。 里氏替换原则1234567891011121314151617181920212223242526272829303132333435&lt;?php//例子1class Bird&#123; protect function fly()&#123; &#125;&#125;//翠鸟class KingFisher extends Bird&#123;&#125;//鸵鸟class Ostrich extends Bird&#123; //鸵鸟不会飞啊&#125;//例子2class A&#123; protect function add($a, $b)&#123; return $a + $b; &#125;&#125;//重载class B extends A&#123; protected function add($a, $b)&#123; return $a + $b + 100; &#125;&#125;?&gt; 里氏替换原则是对类继承的一种约束。对里氏替换原则有两种理解： 不能随便去继承不合适的，有多余方法或者属性的类。（例子1） 子类可以扩展父类的功能，但不能改变父类原有的功能。（例子2） 看了第二个例子，有人会说那岂不是和重载矛盾了。初看是有点，但仔细理解，并不矛盾，我们可以这样处理矛盾： //例子2 12345678910111213class A&#123; protect function add($a, $b)&#123; return $a + $b; &#125;&#125;//重载class B extends A&#123; protected function add($a, $b, $c)&#123; return isset($c) ? $a + $b + 100 : $a + $b; &#125;&#125; 里氏替换原则包含一下几个隐藏含义： 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松。 当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php-disign-pattern设计模式]]></title>
      <url>%2Farticles%2Fphp-disign-pattern.html</url>
      <content type="text"><![CDATA[单一职责:1避免职责分散，2避免职责过于集中。关键词 整体 部分。原子 接口隔离:意思是不应该强迫实现一些不会使用的接口 关键词 原子 开放-封闭原则:一个模块扩展是开放的，核心是封闭的。 这里的关键是 抽象，因为抽象具有稳定性 替换原则:子类必须能够替换成他们的基类]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-shell-/bin/bash^M错误]]></title>
      <url>%2Farticles%2Flinux-shell-bin-bashM.html</url>
      <content type="text"><![CDATA[1bash: ./du2.sh: /bin/bash^M: bad interpreter: No such file or directory 在win平台下输入/bin/bash的脚本,运行报错。 因为win下默认编辑器的回车是crlf。改成lf就好了 while read 可以读取文件的每一行.read -p 可以读取指令。 123456789#!/bin/bashcat 2 | while read linedo echo &quot;$line&quot;doneread -p &quot;niaiwome?&quot; nameecho &quot;$name&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-while-do-case与js和python,php对比]]></title>
      <url>%2Farticles%2Flinux-while-do.html</url>
      <content type="text"><![CDATA[case … esac 与其他语言中的 switch … case 语句类似，是一种多分枝选择结构。 1234while commanddo Statement(s) to be executed if command is truedone 1234567891011121314151617case 值 in模式1) command1 command2 command3 ;;模式2） command1 command2 command3 ;;*) command1 command2 command3 ;;esac js的switch 1234567891011switch(n)&#123;case 1: 执行代码块 1 break;case 2: 执行代码块 2 break;default: n 与 case 1 和 case 2 不同时执行的代码&#125; php的switch 12345678910111213switch (expression)&#123;case label1: code to be executed if expression = label1; break; case label2: code to be executed if expression = label2; break;default: code to be executed if expression is different from both label1 and label2;&#125; python的switchpython本身没有switch语句，解决方法有以下3种: 123456789101112131415A.使用dictionaryvalues = &#123; value1: do_some_stuff1, value2: do_some_stuff2, ... valueN: do_some_stuffN, &#125;values.get(var, do_default_stuff)()B.使用lambdaresult = &#123; 'a': lambda x: x * 5, 'b': lambda x: x + 7, 'c': lambda x: x - 2&#125;[value](x)C.使用引用类]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql-mysql5.7-[Err]1067-Invaliddefaultvaluefor]]></title>
      <url>%2Farticles%2Fmysql-mysql5-7-Err-1067-Invaliddefaultvaluefor.html</url>
      <content type="text"><![CDATA[升级到mysql5.7后，还原数据出现[Err]1067-Invaliddefaultvaluefor，更改mysqld组的sql_mode.5.7在/etc/mysql/mysql.conf.d/mysqld.cnf [mysqld] # # * Basic Settings # user = mysql pid-file = /var/run/mysqld/mysqld.pid socket = /var/run/mysqld/mysqld.sock port = 3306 basedir = /usr datadir = /var/lib/mysql tmpdir = /tmp lc-messages-dir = /usr/share/mysql skip-external-locking sql_mode = ALLOW_INVALID_DATES 设置完后，查询下，如果是ALLOW_INVALID_DATES说明改成功。否则检查下。123456mysql&gt; select @@sql_mode; +----------------------------------------------------------------+ | @@sql_mode | +----------------------------------------------------------------+ | STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION | +----------------------------------------------------------------+]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php-php7-fpm默认监听的scok]]></title>
      <url>%2Farticles%2Fphp-php7-listen.html</url>
      <content type="text"><![CDATA[php7-fpm默认监听的sock。和以前不一样 。以前是监听9000端口。 1234567891011121314151617server &#123; listen 80; server_name ityhc.com www.ityhc.com; root /var/www/html/ityhc; index index.html index.htm index.php; location ~ \.php?.*$ &#123; root /var/www/html/ityhc; fastcgi_index index.php; fastcgi_pass unix:/run/php/php7.0-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php-interfaces-and-traits]]></title>
      <url>%2Farticles%2Fphp-interfaces-and-traits.html</url>
      <content type="text"><![CDATA[interfaces和traits,超强组合译者注:老歪，写的文章特别详细，一句话会说好几遍，语义我删减了点。但尽可能保持原意。如果你还没有用php的interfaces, 会错过面向对象的强大特性. 在PHP 5.4中Interfaces和traits配合十分强大.Interfaces不在类中，类必须实现interface里约定的方法. 假设我们有个User的类. Users有个地址，我们把地址通过应用邮件包传给PackageShipper（托运人） : 12345678910111213141516171819202122232425class Address &#123; // ... setters and getters for address fields ...&#125;class User &#123; protected $address; public function setAddress(Address $address) &#123; $this-&gt;address = $address; &#125; public function getAddress() &#123; return $this-&gt;address; &#125; // ... other user logic ...&#125;class PackageShipper &#123; public function shipTo(User $user) &#123; $address = $user-&gt;getAddress(); // ... do shipping code using $address ... &#125;&#125; 我们的应用愉快的传递包, 直到有一天我们有个需求， Companies(公司) 也需要传递包. 我们创建一个公司类来处理: 12345678910111213class Company &#123; protected $address; public function setAddress(Address $address) &#123; $this-&gt;address = $address; &#125; public function getAddress() &#123; return $this-&gt;address; &#125; // ... other company logic ...&#125; 现在我们遇到一个问题. PackageShipper只知道处理Users. 我们需要PackageShipper类处理任何地址. 我们可以创建基类(就是基本的类) ,Users 和 Companies 集成它,PackageShipper允许任何来至继承 base 的类. 这么做不令人满意. 从含义上讲, Users 和 Companies 是两个不同实体, 他们没有太多的共性用于base继承. 除了地址其他没有一样的了. 还有一些类或许已经继承了别的类, 因为php是单继承的，我们没办法再继承了. 所以, 我们可以用 interface定义一个PackageShipper处理的 Users 和 Companies公共部分 . 然后, Users 和 Companies继承interface, PackageShipper只需要处理继承接口的对象. 12345678910111213141516171819202122232425262728293031323334353637383940inteface Addressable &#123; public function setAddress(Address $address); public function getAddress();&#125;class User implements Addressable &#123; protected $address; public function setAddress(Address $address) &#123; $this-&gt;address = $address; &#125; public function getAddress() &#123; return $this-&gt;address; &#125; // ... other user logic ...&#125;class Company implements Addressable &#123; protected $address; public function setAddress(Address $address) &#123; $this-&gt;address = $address; &#125; public function getAddress() &#123; return $this-&gt;address; &#125; // ... other company logic ...&#125;class PackageShipper &#123; public function shipTo(Addressable $entity) &#123; $address = $entity-&gt;getAddress(); // ... do shipping code using $address ... &#125;&#125; 一个类可以继承多个不同interfaces, 不同基类可以继承同样的interface. 但是这还是有一个问题. Company和User 用同样代码继承Addressable . 这样太浪费了;只要还有接口约束, 继承来至接口类没必要都一样. 但是, 它们都继承了接口, 我们要复制代码. 如果还要第三个Addressable,同样继承interface, 将会带来更多的重复. 如果你使用PHP 5.3 版本以下, 没办法解决的. 但是如果使用PHP 5.4, 有种新的方式可以解决这种问题: traits. trait类似于类，因为它们都实现方法和属性。不同的是，类可以实例化，但是trait不能。相反，trait可以添加到类定义，给该类的所有定义的方法和属性定义在trait中 traits就像一个宏一样:在类中使用traits和traits中的代码复制到类是一样的。 用traits,我们可以清除重复的代码 ，保持Addressable接口的定义: 12345678910111213141516171819202122trait AddressAccessor &#123; protected $address; public function setAddress(Address $address) &#123; $this-&gt;address = $address; &#125; public function getAddress() &#123; return $this-&gt;address; &#125;&#125;class User implements Addressable &#123; use AddressAccessor; // ... other user logic ...&#125;class Company implements Addressable &#123; use AddressAccessor; // ... other company logic ... 现在，任何类可以通过AddressAccessor trait继承Addressable接口 . 重复的代码都可以移除. trait本身不继承Addressable. 这就是为什么只有classes 可以继承 interfaces. 注意trait的优先级别要小于类里面的。 Interfaces保证 PHP执行正确的代码. 和traits结合, 定义了一个快速开发的强大工具, 减少重复的代码,更易读,更好维护. 下面是应用的最终代码 12345678910111213141516171819202122232425262728293031323334353637383940class Address &#123; // ... setters and getters for address fields ...&#125;inteface Addressable &#123; public function setAddress(Address $address); public function getAddress();&#125;trait AddressAccessor &#123; protected $address; public function setAddress(Address $address) &#123; $this-&gt;address = $address; &#125; public function getAddress() &#123; return $this-&gt;address; &#125;&#125;class User implements Addressable &#123; use AddressAccessor; // ... other user logic ...&#125;class Company implements Addressable &#123; use AddressAccessor; // ... other company logic ...&#125;class PackageShipper &#123; public function shipTo(Addressable $entity) &#123; $address = $entity-&gt;getAddress(); // ... do shipping code using $address ... &#125;&#125; 简单点说，接口用于限制，traits减少重复代码。 原文:http://blog.everymansoftware.com/2012/09/interfaces-and-traits-powerful-combo.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-fifo]]></title>
      <url>%2Farticles%2Flinux-fifo.html</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-mknod]]></title>
      <url>%2Farticles%2Flinux-mknod.html</url>
      <content type="text"><![CDATA[12345678#将其中的1,3这样的数字记录下来，这表示主设备号和次设备号（一般来说主设备号用来区分设备的种类；次设备号则是为了作唯一性区分，标明不同属性——注意，在unix系统中是把设备也当作文件来对待的），在redhat 9下，ls加不加-L参数都无所谓，但是在Solaris下则一定要加上才可以显示[root@localhost test1]# ls -lL /dev/null crw-rw-rw- 1 root root 1, 3 8月 18 21:56 /dev/null[root@localhost test1]# mknod /dev/hda3 b 3 7 #创建一个区块[root@localhost test1]# ls -al /dev/hda3 #查看brw-r--r-- 1 root root 3, 7 8月 21 11:01 /dev/hda3 mknod命令用于创建Linux中的字符设备文件和块设备文件。 首先要明白什么是设备文件，简单的我们说 操作系统与外部设备（入磁盘驱动器，打印机，modern，终端 等等）都是通过设备文件来进行通信 的，在Unix/Linux系统与外部设备通讯之前，这个设备必须首先要有一个设备文件，设备文件均放在/dev目录下。一般情况下在安装系统的时候系统自动创建了很多已检测到的设备的设备文件，但有时候我们也需要自己手动创建，命令行生成设备文件的方式有 insf，mksf，mknod等等 根据mknod命令的使用参数来看【mknod Name { b | c } Major Minor 】，使用mknod之前，至少要明白以下几点：设备文件类型：分为块设备和字符设备。ls -l /dev 结果显示第一个字段有b 和 c*，这里即标识了块设备和字符设备。字符设备文件—-字符设备文件传送数据给设备的时候，一次传送一个字符，终端，打印机，绘图仪，modern等设备都经过字符设备文件传送数据块设备—系统通过块设备文件存取一个设备的时候，先从内存中的buffer中读或写数据，而不是直接传送数据到物理磁盘，这种方式能有效的提高磁盘和CD-ROMS的I/O性能。磁盘和CD-ROMS即可以使用字符设备文件也可使用块设备文件。 来看看mknod 命令，如果该设备文件你想放在一个特定的文件夹下当然就先创建文件夹mknod 设备文件名[/dev/xyz] b/c 主号 次号 Linux对设备管理是以文件管理的形式进行的，各种设备都以文件的形式存放在/dev目录 下，称为设备文件。应用程序可以打开、关闭和读写这些设备文件，完成对设备的操作，就像操作普通的数据文件一样。为了管理这些设备，系统为设备编了号，每 个设备号又分为主设备号和次设备号。主设备号用来区分不同种类的设备，而次设备号用来区分同一类型的多个设备。 Linux为所有的设备文件都提供了统一的操作函数接口，此函数结构使用数据结构struct file_operations。这个数据结构中包括许多操作函数的指针，如open()、close()、read()和write()等，但由于外设 的种类较多，操作方式各不相同。Struct file_operations结构体中的成员为一系列的接口函数，如用于读/写的read/write函数和用于控制的ioctl等。打开一个文件就是 调用这个文件file_operations中的open操作。不同类型的文件有不同的file_operations成员函数，如普通的磁盘数据文件， 接口函数完成磁盘数据块读写操作；而对于各种设备文件，则最终调用各自驱动程序中的I/O函数进行具体设备的操作。这样，应用程序根本不必考虑操作的是设 备还是普通文件，可一律当作文件处理，具有非常清晰统一的I/O接口。所以file_operations是文件层次的I/O接口。 linux中可以通过mknod命令创建一个设备，具体的使用方法如下 mknod 的标准形式为: mknod DEVNAME {b | c} MAJOR MINOR 1、DEVNAME是要创建的设备文件名，如果想将设备文件放在一个特定的文件夹下，就需要先用mkdir在dev目录下新建一个目录； 2、 b和c 分别表示块设备和字符设备： b表示系统从块设备中读取数据的时候，直接从内存的buffer中读取数据，而不经过磁盘； c表示字符设备文件与设备传送数据的时候是以字符的形式传送，一次传送一个字符，比如打印机、终端都是以字符的形式传送数据； 3、MAJOR和MINOR分别表示主设备号和次设备号： 为了管理设备，系统为每个设备分配一个编号，一个设备号由主设备号和次设备号组成。主设备号标示某一种类的设备，次设备号用来区分同一类型的设备。linux操作系统中为设备文件编号分配了32位无符号整数，其中前12位是主设备号，后20位为次设备号，所以在向系统申请设备文件时主设备号不好超过4095，次设备号不好超过2^20 -1。 用法：mknod [选项]… 名称 类型 [主设备号 次设备号]创建指定类型和名称的特殊文件。 长选项必须使用的参数对于短选项时也是必需使用的。 -m, –mode=模式 设置权限模式(类似chmod)，而不是rwxrwxrwx 减umask -Z, –context=CTX 将对应名称文件的SELinux 安全环境设置为CTX –help 显示此帮助信息并退出 –version 显示版本信息并退出 当类型为”p”时可不指定主设备号和次设备号，否则它们是必须指定的。如果主设备号和次设备号以”0x”或”0X”开头，它们会被视作十六进制数来解析；如果以”0”开头，则被视作八进制数；其余情况下被视作十进制数。可用的类型包括： b 创建(有缓冲的)区块特殊文件 c, u 创建(没有缓冲的)字符特殊文件,虚拟设备 p 创建先进先出(FIFO)特殊文件 注意：您的shell 内含自己的mknod 程序版本，它会覆盖这里所提及的相应版本。请查阅您的shell 文档获知它所支持的选项。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[html5-prefech加速prerender预渲染]]></title>
      <url>%2Farticles%2Fhtml5-prefetch.html</url>
      <content type="text"><![CDATA[DNS Prefetching 现代浏览器当遇到DNS解析时已经十分聪明——用户在跟随某个链接之前，浏览器先尝试解析域名再将其进行缓存。 &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//fonts.googleapis.com&quot;&gt; &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//google-analytics.com&quot;&gt; &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//www.google- analytics.com&quot;&gt; &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//platform.twitter.com&quot;&gt; Link Prefetching Link Prefetching特性允许开发者在页面加载的时候预先加载他们希望指定的页面或元素。代码如下： &lt;link rel=&quot;prefetch&quot; href=&quot;http://daker.me/2013/05/hello-world.html&quot; /&gt; &lt;link rel=&quot;prefetch&quot; href=&quot;http://daker.me/assets/images/avatar.png&quot; /&gt; 你也能够使用prerendering特性令你的网站速度更快，浏览器能够在后台获取并渲染整个页面，用户点击相应链接时再为用户展示该页面。代码如下： &lt;link rel=&quot;prerender&quot; href=&quot;http://daker.me/2013/05/hello-world.html&quot; /&gt; Download属性 凭借HTML5的Download属性，开发者可以不必到特定页面下载文件，而是直接进行下载。这一操作不必依赖服务器端代码便能够执行。代码如下： &lt;a href=&quot;download_pdf.php?id=15&quot; download=&quot;myfile.pdf&quot;&gt;Download PDF&lt;/a&gt; Regular Expressions 一旦用户输入一个有效的email或URL地址，pattern属性可以令你直接使用regular expressions而无需检查JS或服务器端代码。代码如下： &lt;input type=&quot;email&quot; pattern=&quot;[^ @]*@[^ @]*&quot; value=&quot;&quot;&gt; Datalist元素 若使用jQuery插件执行自动填充输入操作，则用户每敲击一次键盘都要访问服务器端代码以及数据库。但有了Datalist元素，开发者不必再使用jQuery插件便可完成该操作。代码如下： &lt;form action=&quot;form.php&quot; method=&quot;post&quot;&gt; &lt;input list=&quot;cars&quot; name=&quot;cars&quot; &gt; &lt;datalist id=&quot;cars&quot;&gt; &lt;option value=&quot;Volvo&quot;&gt; &lt;option value=&quot;BMW&quot;&gt; &lt;option value=&quot;Bugatti&quot;&gt; &lt;option value=&quot;Cadillac&quot;&gt; &lt;option value=&quot;Chevrolet&quot;&gt; &lt;option value=&quot;Chrysler&quot;&gt; &lt;/datalist&gt; &lt;input type=&quot;submit&quot; /&gt; &lt;/form&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux-kill]]></title>
      <url>%2Farticles%2Flinux-kill.html</url>
      <content type="text"><![CDATA[一些快捷键ctrl+a 行首 ctrl+e 行尾 ctrl+u 删除 ctrl+l 清除屏幕 ctrl+z 加入到后台 ctrl+r 历史记录 linux 把top放入后台 ctrl+z或者top&amp; 放入后台&amp;还有含义 就是 1 2 输出 如果要关闭 先ps 看到pid号后 kill -9 pid号 错误输出2&gt;&gt; 2&gt;&amp;1 是将标准出错重定向到标准输出，这里的标准输出已经重定向到了out.file文件，即将标准出错也输出到out.file文件中。最后一个&amp; ， 是让该命令在后台执行。 ； 多命令 ls /etc/ | grep [^b].* |wc $a=1 $取值运算set -u 未声明变量会提示unset 删除变量 export x 设置全局变量 locate 定位locale 位置 locale -a 显示支持的所有 df -h 磁盘信息]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux点命令执行linux.命令]]></title>
      <url>%2Farticles%2Flinux-shell-dot.html</url>
      <content type="text"><![CDATA[.: . filename [arguments] . 文件名 [参数] Execute commands from a file in the current shell. 在当前的shell脚本中加载一个文件执行里面的命令. Read and execute commands from FILENAME in the current shell. The 在当前的shell脚本中加载一个文件读取和执行里面的命令. entries in $PATH are used to find the directory containing FILENAME. $PATH环境变量用于查找文件目录 If any ARGUMENTS are supplied, they become the positional parameters when FILENAME is executed. 如果有形参，文件在被执行的时候实参就会传过去。 ps:(parameter=形参(formal parameter)， argument=实参(actual parameter)。) Exit Status: 退出状态: Returns the status of the last command executed in FILENAME; fails if FILENAME cannot be read. 返回文件最后执行的命令的状态；如果无法读取文件返回失败。 12echo &apos;ls -a&apos;&gt;&gt;myLS. myLS]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[vmware-nonet]]></title>
      <url>%2Farticles%2Fvmware-nonet.html</url>
      <content type="text"><![CDATA[很多小伙伴，在配置完虚拟机后，发现无法正常上网，这是为什么呢？ 导致这个原因大部分是因为，我们的电脑有多个网卡，而我们设置的桥接方式是自动配置的，无法正确识别，主网卡。 这个时候我们可以通过 虚拟网络编辑器 编辑网桥 指定网卡就可以。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git fork和clone区别，fetch与pull区别]]></title>
      <url>%2Farticles%2Fgit-fork-clone-fetch-pull.html</url>
      <content type="text"><![CDATA[fork：github中，克隆别人仓库的项目到自己的仓库clone：克隆github或者其他远程 git服务器仓库的项目到自己的 本地]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[apache配置]]></title>
      <url>%2Farticles%2Fapache-config.html</url>
      <content type="text"><![CDATA[优雅重启1/usr/local/apache2/bin/apachectl graceful vhost配置路径/usr/local/apache2/etc/extra httpd配置路径/usr/local/apache2/etc]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php函数参数类和接口]]></title>
      <url>%2Farticles%2Fphp-class-type-declaration.html</url>
      <content type="text"><![CDATA[参数为类的实例123456789101112131415&lt;?phpclass C &#123;&#125;class D extends C &#123;&#125;// This doesn't extend C.class E &#123;&#125;function f(C $c) &#123; echo get_class($c)."\n";&#125;f(new C);f(new D);f(new E);?&gt; 输出为 1234567891011&lt;?phpCDFatal error: Uncaught TypeError: Argument 1 passed to f() must be an instance of C, instance of E given, called in - on line 14 and defined in -:8Stack trace:#0 -(14): f(Object(E))#1 &#123;main&#125; thrown in - on line 8?&gt; 参数为接口的实现 1234567891011121314&lt;?phpinterface I &#123; public function f(); &#125;class C implements I &#123; public function f() &#123;&#125; &#125;// This doesn't implement I.class E &#123;&#125;function f(I $i) &#123; echo get_class($i)."\n";&#125;f(new C);f(new E);?&gt; 输出为 1234&lt;?phpCPHP Catchable fatal error: Argument 1 passed to f() must implement interface I, instance of E given, called in /code/main.php on line 13 and defined in /code/main.php on line 8?&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[webpack热拔插教程hmr]]></title>
      <url>%2Farticles%2Fwebpack-hmr-tutorial.html</url>
      <content type="text"><![CDATA[http://andrewhfarmer.com/webpack-hmr-tutorial/Struggling to set up HMR with Webpack? Are you finding the Webpack documentation to be lacking - particularly in the HMR section? Does it seem like they’ve left out some important parts? If so, read on! We’ll fill in the gaps together. By the way, HMR stands for ‘Hot Module Replacement’, sometimes called ‘hot module swapping’. It’s a Webpack feature that updates your JavaScript in-place without a browser refresh - whenever you make code changes. I love it because it enables a very fast developer workflow.HMR MythsFirst let’s get a couple myths about HMR out of the way.Myth: HMR is only for ReactNot true - it usually just takes 3 lines of code to enable HMR in arbitrary JavaScript. This Tutorial doesn’t even mention React - I’ll cover HMR in React in a subsequent post. Myth: HMR is only for ‘advanced’ usersNot true. Without good documentation, HMR is difficult for beginners and advanced users alike. With the right information (this article), HMR can be enabled with very minor changes to config/code. Myth: HMR is the same as ‘live reload’Not true. Live reload is when the browser automatically refreshes the page whenever you make a code change. HMR is faster because it updates code in-place without refreshing. 2 Steps to HMR SuccessThere are 2 steps to enabling HMR: config changes and code changes. Config / Project SetupThere are 3 ways to configure your project for HMR. I go into each way in detail in Part 1. Pick the way that’s right for you and either use the provided github repository, or follow the directions to adapt your existing code base. JavaScript / HMR APITo get HMR to work you have to add a little bit of extra code to your JavaScript. In the simplest case this is just 3 lines of code. I’ll show you everything you need to add for your use-case in Part 2. Part 1: Configuring Your ProjectThere are exactly 3 ways that you can configure your HMR project. Let’s go through each one. I’ll help you pick which one to use in the next section. webpack-dev-server CLIRun the webpack-dev-server on the command-line. With this approach you don’t need to change your webpack.config.js file, so it’s the simplest. webpack-dev-server APIRun WebpackDevServer from a node.js script. Requires some additions to your webpack.config.js. webpack-hot-middleware w/ expresswebpack-hot-middleware is used for running a webpack dev server with HMR inside an express server. The Non-WayIf you are used to running the webpack CLI or the Webpack API (without express or webpack-dev-server), then you’ll have to change how you do things a little bit. HMR requires a server to work. To find out why, read my understanding HMR post. But how do I choose?Follow this simple guide to pick one of the 3 ways above. If you are using a task runner like grunt or gulp you’ll want to use the webpack-dev-server API. You can run the server from one of your gulp/grunt tasks. If you use your own node scripts to run webpack, you’ll also want to use the webpack-dev-server API. If you use express to host your site: use webpack-hot-middleware. It will be integrated with your express server, so you won’t have to run another server for your bundled JS. If none of the above apply to you or you just want the simplest possible setup: use the webpack-dev-server CLI. It requires no configuration. Okay, I picked one, but how do I start?Glad you asked! Below is a separate ‘Configuring X’ section for each of the 3 approaches. Scroll forward to the approach you decided to use, follow the directions, and then scroll down to Part 2. Configuring webpack-dev-server CLIRead this section if you’ve decided to use the webpack-dev-server CLI. Otherwise, scroll to the next section. If you are starting a new project, use my webpack HMR with webpack-dev-server CLI starter project (wow that’s a mouthful). It has a README and lots of comments to explain what’s going on. If you are working with an existing project: just make sure you have a valid webpack.config.js and run webpack-dev-server. Here’s an example command: webpack-dev-server –content-base=www –inline –watch –hotYou may want to modify the above command for your use-case based on the CLI Docs. That’s it! When you use the webpack-dev-server CLI it does all the configuration for you. Gotcha: When using this approach, make sure your webpack.config.js does NOT contain any references to webpack-dev-server or HotModuleReplacementPlugin. You’ll get errors if you do. Configuring WebpackDevServer APIRead this section if you’ve decided to use the WebpackDevServer API. Otherwise, scroll to the next section. If you are starting a new project, use my webpack HMR with WebpackDevServer API starter project. It has a README and lots of comments to explain what’s going on. If you are working with an existing project, you’ll have to make 3 changes: Change #1: Add entry points to your webpack.config.js. Here’s an example. You need webpack/hot/dev-server and webpack-dev-server/client as shown, but index.js should be the name of your usual entry point. entry: [ ‘./index.js’, ‘webpack/hot/dev-server’, ‘webpack-dev-server/client?http://localhost:8080/‘,],Change #2: Add the HotModuleReplacementPlugin to your your webpack.config.js, like this: plugins: [ new webpack.HotModuleReplacementPlugin(),]For a complete example, see the starter project webpack.config.js. Change #3: Run WebpackDevServer with the hot: true option. For an example, see the starter project server.js. Configuring webpack-hot-middleware &amp; expressRead this section if you’ve decided to use express and webpack-hot-middleware. Otherwise, scroll on to Part 2. If you are starting a new project, use my webpack HMR with webpack-hot-middleware &amp; express starter project. It has a README and lots of comments to explain what’s going on. If you are working with an existing express project, you’ll need to do 3 things: Change #1: Install webpack-hot-middleware and webpack-dev-middleware. I’m assuming you already have webpack and express. npm install –save-dev webpack-hot-middleware webpack-dev-middlewareChange #2: Adjust your webpack.config.js to look similar to this. The important bits are the entry and plugins section. You’ll want all the plugins I have listed: var path = require(‘path’);var webpack = require(‘webpack’); var config = { context: path.join(dirname, ‘js’), entry: [ ‘webpack-hot-middleware/client?path=/webpack_hmr&amp;timeout=20000’, ‘./index.js’, ], output: { path: path.join(__dirname, ‘www’), filename: ‘bundle.js’, publicPath: ‘/assets/‘, }, plugins: [ new webpack.optimize.OccurenceOrderPlugin(), new webpack.HotModuleReplacementPlugin(), new webpack.NoErrorsPlugin() ]};module.exports = config;Change #3: Add the middleware to your express server. Add these requires: var webpackDevMiddleware = require(“webpack-dev-middleware”);var webpackHotMiddleware = require(“webpack-hot-middleware”);And these middleware .use statements: app.use(webpackDevMiddleware(compiler, { hot: true, filename: ‘bundle.js’, publicPath: ‘/assets/‘, stats: { colors: true, }, historyApiFallback: true,})); app.use(webpackHotMiddleware(compiler, { log: console.log, path: ‘/__webpack_hmr’, heartbeat: 10 * 1000,}));Part 2: Code ChangesYour Webpack project should now be configured for HMR. But if you fire up a browser at this point and make a code change, it won’t work. Either you won’t see the update, or you’ll get a full browser refresh. Why isn’t it working yet? Webpack doesn’t know when it is acceptable to reload a particular JS file. To let Webpack know which files can be updated, we’ll use the HMR JavaScript API a.k.a. the module.hot API. If you used any of my github starter projects, they are already using the module.hot API and you will see changes reflected immediately.The Simple WayTo start, find your entry point (often called index.js or main.js) and add the following to the end: if (module.hot) { module.hot.accept();}This tells Webpack that this file and all of its dependencies can be replaced. Now make a code change that you could see the effect of onscreen. You SHOULD have seen an update! For many projects, that’s all there is to it. The Catch: Side EffectsIf any of your files produce side effects when they run, for instance if they add elements to the DOM, then you’ll need to use module.hot.dispose to dispose of those side effects. Why? If you don’t, when Webpack reloads the module, all the side effects will be repeated. Here’s an example, box-creator.js: var sideEffectNode = document.createElement(‘div’);sideEffectNode.textContent = ‘Side Effect’;document.body.appendChild(sideEffectNode); // Remove the most recently-added so that when the code runs again and// adds a new , we don’t end up with duplicate divs.if (module.hot) { module.hot.dispose(function() { sideEffectNode.parentNode.removeChild(sideEffectNode); });}This is a file that simply adds a to the DOM whenever it is loaded. It uses module.hot.dispose to remove the when it is unloaded by the Webpack HMR Runtime. ConclusionThat’s all you need to know to get HMR working. If you want to dig deeper to solidify your understanding, read my article on understanding HMR. Coming soon: next I’ll post about how to apply HMR to your React project. Sign up for my list to be notified when that comes out!]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[laravel学习零散知识点]]></title>
      <url>%2Farticles%2Flaravel-study.html</url>
      <content type="text"><![CDATA[&lt;?php$firstname = “Bill”;$lastname = “Gates”;$age = “60”; $result = compact(“firstname”, “lastname”, “age”); print_r($result);?&gt;compact 紧凑的 动人的; 雄辩的，有口才的; 有说明力的; 富于表情的，逼真的;eloquent英文发音：[‘lærəvel] 作者 Taylor Otwell In Narnia, Cair Paravel is the name of the castle where the kings and queens of Narnia live. Laravel rhymes with Paravel. I thought the name had a classy and sophisticated ring to it.— Taylor Otwell — Laravel这个名字来自于纳尼亚传奇中的Cair Paravel城堡。Laravel 和Paravel 的发音相似，Taylor认为Laravel这个名字韵味深长而又优雅，所以命名为Laravel。Cair Paravel 中的Paravel发音为[‘pærəvel] 推断Laravel发音取[‘lærəvel] 123456789101112131415161718192021222324252627&#123;!! !!&#125; 相当于 &lt;?php echo $value; ?&gt;&#123;&#123; &#125;&#125; 相当于 &lt;?php echo htmlspecialchars($value); ?&gt;csrf_field()csrf_field 函数生成一个包含 CSRF 令牌值的 HTML 隐藏域，例如，使用Blade语法示例如下：&#123;!! csrf_field() !!&#125;&#123;&#123;&#123;&#125;&#125;&#125; 完全转换html@if()@else ss@endif@foreach()@endforeach@for@endfor@while@endwhilecsrf_token()csrf_token 函数获取当前 CSRF 令牌的值：$token = csrf_token(); php artisan make:controller myControllerphp artisan route:list laravel collect laravel 请求 query get has existshas 和exists 的区别 has 判断 是否存在此参数 其此参数不为空检索 only去除 Request::except(‘name’,’age’) 去除url Request::url() 全部 fullUrl() 请求历史 flash flashExcept flashOnly old请求文件 Request::file(‘’profile)-&gt;getSize()getClientOriginalNamegetClientOriginalExtensionsession 教程http://blog.csdn.net/ghost_hell/article/details/53177072Hash::make() laravelyield 用于定义个内容的片段 里面没有内容 只是内容的片段section 用于定义给定片段的内容 定义了内容 可以多次继承覆盖 服务容器 都是依靠构造函数或者某些情况下通过 setter 方法将类依赖注入到类]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git文件状态]]></title>
      <url>%2Farticles%2Fgit-filestatus.html</url>
      <content type="text"><![CDATA[灰色箭头不参与git快照。 默认git有4种状态 untracked 未跟踪 unmodified 未修改 modified 修改 staged 暂存区 其中我们工作区中只有 未修改 和修改。初始化，和commit后 所有为跟踪的文件都是 未修改的。运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来：git diff –cached 查看已经暂存起来的变化：git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交 如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 “Changes not staged for commit” 部分（也就是未暂存清单）看到： 123456789$ rm grit.gemspec$ git statusOn branch masterChanges not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) deleted: grit.gemspec no changes added to commit (use “git add” and/or “git commit -a”)然后再运行 git rm 记录此次移除文件的操作： 123456789$ git rm grit.gemspecrm &apos;grit.gemspec&apos;$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) deleted: grit.gemspec 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆 .a 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 –cached 选项即可： $ git rm --cached readme.txt 后面可以列出文件或者目录的名字，也可以使用 glob 模式。比方说： $ git rm log/\*.log 注意到星号 * 之前的反斜杠 \，因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开（译注：实际上不加反斜杠也可以运行，只不过按照 shell 扩展的话，仅仅删除指定目录下的文件而不会递归匹配。上面的例子本来就指定了目录，所以效果等同，但下面的例子就会用递归方式匹配，所以必须加反斜杠。）。此命令删除所有 log/ 目录下扩展名为 .log 的文件。类似的比如： $ git rm \*~ 会递归删除当前目录及其子目录中所有 ~ 结尾的文件。 图形化显示分支 git log –pretty=format:”%h %s” –graph 123456789101112选项 说明-p 按补丁格式显示每个更新之间的差异。--word-diff 按 word diff 格式显示差异。--stat 显示每次更新的文件修改统计信息。--shortstat 只显示 --stat 中最后的行数修改添加移除统计。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--graph 显示 ASCII 图形表示的分支合并历史。--pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。--oneline `--pretty=oneline --abbrev-commit` 的简化用法。 提交时忘了暂存某些修改，可以先补上暂存操作，然后再运行 –amend 提交：123$ git commit -m &apos;initial commit&apos;$ git add forgotten_file$ git commit --amend 取消对文件的修改$ git checkout – benchmarks.rb 添加远程仓库git remote add [shortname] [url] 从远程仓库抓取数据$ git fetch [remote-name] 默认情况下 git clone 命令本质上就是自动创建了本地的 master 分支用于跟踪远程仓库中的 master 分支（假设远程仓库确实有 master 分支）。所以一般我们运行 git pull，目的都是要从原始克隆的远端仓库中抓取数据后，合并到工作目录中的当前分支。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[window命令mklink 创建符号链接 硬链接 目录联结]]></title>
      <url>%2Farticles%2Fwindow-mklink.html</url>
      <content type="text"><![CDATA[最近研究mklink 发现国内很多文档认识有错误 或者不充分，在此补充下。 符号链接 用的比较多 也就是我们的快捷方式 硬链接 用的很少 可以防止误删，省空间等、 目录联结 一般用于共享目录链接的本质是创建一个指向原文件的路径 我们的文件其实是存在磁盘空间中， 文件名指向磁盘空间，最后访问文件名 访问到它所指向的空间。 符号链接mklink /d 和快捷方式几乎。但与其不同的是快捷方式是.link后缀的文件。 删除原文件，这种链接就无效了 硬链接(hard link)mklink /h 指向到原文件空间中所在地址。只能用于文件，其实就是又新建了个文件名，指向共同的磁盘空间。所以删除其中一个文件名，不影响另一个。 与copy不同的是，copy实际是创建了两个不同的磁盘空间。 目录联接(junction)mklink /j所谓联结就是相当于一个中间件。充当中介 只能用于目录。而且它用的相对路径，所以复制到别的文件夹是无效的。 这个用来做目录共享。 比如说 我想让b电脑访问 a电脑的目录aa但是我就想让他访问一会。所以我可以创建个目录联结。然后共享这个目录。 等b访问完，直接就可以删掉这个目录。 总的来说链接的本质是为了管理方便，充分利用磁盘空间，避免冗余。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[window命令 端口占用、查杀进制]]></title>
      <url>%2Farticles%2Fwindow-tasklist-taskkill-netstat.html</url>
      <content type="text"><![CDATA[cmd关闭php的一个示例 首先用php -S 开启一个服务 另开一个窗口，查询占用了8081端口的进程：netstat -ano|findstr 8081，找到pid为12552 tasklist|findstr 12552 。发现就是我们的php服务 taskkill /f /t /im php.exe/f 强制/t 关闭子进程/im 文件名taskkill /f /PID 12552/PID 删除指定pid]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据结构-集合论，集合,数组 大O 第一篇]]></title>
      <url>%2Farticles%2Fdata-structure-set.html</url>
      <content type="text"><![CDATA[集合论: 集合论或集论是研究集合（由一堆抽象物件构成的整体）的数学理论,包含了集合、元素和成员关系等最基本的数学概念。集合（简称集）是数学中一个基本概念，它是集合论的研究对象.集合就是“一堆东西”。集合里的“东西”，叫作元素。集合A和B的并集，符号为A ∪ B集合A和B的交集，符号为A ∩ B集合U和A的相对差集，符号为U \ A集合A和B的对称差，符号为A △ B或A⊕B 编程中的数组 是集合中的一种表现形式。 数组是在程序设计中，为了处理方便， 把具有相同类型的若干变量按有序的形式组织起来的一种形式。这些按序排列的同类数据元素的集合称为数组。其中具有相同类型的若干变量按有序的形式组织起来的一种形式 就是我们说的成员关系。 ①[x，y] ：中括号表示包括边界数字，即表示大于等于x小于等于y②(x，y)：小括号是不包括边界，即表示大于x小于y所以我们的数组 用[]来声明。而()已经被函数占用，所以不考虑。大O 其实是omega的缩写 在数学上表示首个不可数的序数 序数是在基数的基础上再增加一层意思。例如： 基数：一、二、三、四、五、六、七、八、九、十。 序数：第一、第二、第三、第四、第五、第六、第七、第八、第九、第十。基数： 在数学上，基数（cardinal number）是集合论中刻画任意集合大小的一个概念。两个能够建立元素间一一对应的集合称为互相对等集合。例如3个人的集合和3匹马的集合可以建立一一对应，是两个对等的集合。序数： 集合论基本概念之一，是日常使用的第一、第二等表示次序的数的推广。序数概念是建立在良序集概念之上的，而良序集又是偏序集、全序集的特殊情形。 数学的一个基本的分支学科，研究对象是一般集合。集合论在数学中占有一个独特的地位，它的基本概念已渗透到数学的所有领域。[1] 集合论或集论是研究集合（由一堆抽象物件构成的整体）的数学理论，包含了集合、元素和成员关系等最基本的数学概念。在大多数现代数学的公式化中，集合论提供了要如何描述数学物件的语言。集合论和逻辑与一阶逻辑共同构成了数学的公理化基础，以未定义的“集合”与“集合成员”等术语来形式化地建构数学物件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python-列表list,元组tuple,字典dict,集合set]]></title>
      <url>%2Farticles%2Fpython-list-tuple-dict-set.html</url>
      <content type="text"><![CDATA[数序: 全称是数字序列，就是指数字按照一定规律所排出来的顺序。序数: 表顺序的数,像第1、第2、第3。 序列的两个特点：1.索引操作符，从序列中抓取一个特定项目2.和切片操作符，获取序列的一个切片，即一部分序列 Python一些内置函数1、cmp(A, B)：比较可为list、tuple等的A、B，A&gt;B为1，A=B为0，小于为-12、len(obj)： 计算元素个数。3、max(obj)：返回元素最大值。4、min(obj)：返回元素最小值。5、reversed(obj): 对元素进行翻转6、enumerate(obj): 遍历list的元素，返回序号及其对应的元素 for x，y in list：7、zip():打包成tuple（元组），然后返回由这些tuples组成的list（列表） 列表、元组和字符串都是序列，字符串是字符的序列，列表和元祖是任意类型的序列 列表list，用中括号“[ ]”表示 1.任意对象的有序集合列表是一组任意类型的值，按照一定顺序组合而成的2.通过偏移读取组成列表的值叫做元素(Elements)。每一个元素被标识一个索引，第一个索引是0，序列的功能都能实现3.可变长度，异构以及任意嵌套列表中的元素可以是任意类型，甚至是列表类型，也就是说列表可以嵌套4.可变的序列支持索引、切片、合并、删除等等操作，它们都是在原处进行修改列表5.对象引用数组列表可以当成普通的数组，每当用到引用时，Python总是会将这个引用指向一个对象，所以程序只需处理对象的操作。当把一个对象赋给一个数据结构元素或变量名时，Python总是会存储对象的引用，而不是对象的一个拷贝 #!/usr/bin/env python #coding:utf-8 ‘’’FuncName: study_list.pyDesc: list 内建函数Date: 2016-03-17 14:00Author: johnny‘’’ L.append(var) # 追加元素，加在最后 L.insert(index,var) # 在index的位置追加元素，位置就是索引 L.pop(var) # 从list中删除最后一个元素，并返回该元素 L.remove(var) # 删除第一次出现的该元素 L.count(var) # 该元素在列表中出现的个数 L.index(var) # 该元素的位置（索引号）,无则抛异常 L.extend(list) # 追加list，即合并list到L上，两个列表合并 L.sort() # 排序 L.reverse() # 原地翻转列表，从前到后变成从后向前 l = [1,2,3,4,[‘hello’,’johnny’],’blog.csdn.net/z_johnny’] # 创建list l[1:5:2] # list的切片，切一部分，范围为索引[1，5)，即1、2、3、4不包括5，隔2取1个值 l[1:5:2] == [2, 4] l[1] # list的索引，左1索引为0，右1索引为-1，l[1] == 2 l[4][1] # 列表支持嵌套，l[4][1] == ‘johnny’ list的官方内置函数可用dir(list)与help(list) 命令进行查看 元祖tuple，用小括号“( )”表示 1.任意对象的有序集合与列表相同2.通过偏移存取与列表相同3.属于不可变序列类型类似于字符串，但元组是不可变的，不支持在列表中任何原处修改操作，不支持任何方法调用4.固定长度、异构、任意嵌套固定长度即元组不可变，在不被拷贝的情况下长度固定，其他同列表5.对象引用的数组与列表相似，元祖是对象引用的数组 和list相比1.比列表操作速度快2.对数据“写保护“3.可用于字符串格式化中4.可作为字典的key #!/usr/bin/env python #coding:utf-8 ‘’’FuncName: study_tuple.pyDesc: tuple 内建函数Date: 2016-03-17 14:00Author: johnny‘’’ t.count(var) # 该元素在元组中出现的个数 t.index(var) # 该元素的位置（索引号）,无则抛异常 t = (1,2,3,4,[‘hello’,’johnny’],’blog.csdn.net/z_johnny’) # 创建tuple tu = (5,) # 只含有一个元素的元祖，必须加逗号“,” t[1:5:2] # tuple的切片，切一部分，范围为索引[1，5)，即1、2、3、4不包括5，隔2取1个值 t[1:5:2]== (2, 4) t[1] # tuple的索引，左1索引为0，右1索引为-1，t[1] == 2 t[4][1] # 同列表一样支持嵌套，t[4][1] == ‘johnny’ tuple的官方内置函数可用dir(tuple)与help(tuple) 命令进行查看 字典dict，用大括号“{key，value}”表示 1.通过键而不是偏移量来读取字典就是一个关联数组，是一个通过关键字索引的对象的集合，使用键-值（key-value）进行存储，查找速度快2.任意对象的无序集合字典中的项没有特定顺序，以“键”为象征3.可变长、异构、任意嵌套同列表，嵌套可以包含列表和其他的字典等4.属于可变映射类型因为是无序，故不能进行序列操作，但可以在远处修改，通过键映射到值。字典是唯一内置的映射类型（键映射到值的对象）5.对象引用表字典存储的是对象引用，不是拷贝，和列表一样。字典的key是不能变的，list不能作为key，字符串、元祖、整数等都可以 和list比较，dict有以下几个特点：1.查找和插入的速度极快，不会随着key的增加而增加2.需要占用大量的内存，内存浪费多而list相反：1.查找和插入的时间随着元素的增加而增加2.占用空间小，浪费内存很少所以，dict是用空间来换取时间的一种方法 #!usr/bin/env python #coding:utf-8 ‘’’FuncName: study_dict.pyDesc: dict 内建函数Date: 2016-03-17 14:00Author: johnny‘’’ d = {‘Name’: ‘Johnny’, ‘Address’:’blog.csdn.net/z_johnny’} # 创建dictd[‘Name’] # 找出key为Name的值 d[‘Name’] == ‘Johnny’d[‘Name’] = hello # 更新key为Name的值 Name对应的值从Johnny改为hellodel d[‘Address’] # 删除key为Name的值和该key d = {‘Name’: ‘Johnny’}d.clear() # 删除字典d中的所有元素 d = {}d.pop(‘Name’) # 删除字典d中key为’Name’的值和该键d.copy() # 返回字典d的浅复制副本d.fromkeys(S[,v]) # 创建一个新的字典，设置键为seq 和值为valued.get(key, default=None) # 返回该键key的值，若没有该键，则返回Noned.has_key(key) # 如果在字典d中存在键key，则返回true，否则返回 falsed.items() # 返回字典的（键，值）元组对的列表d.keys() # 返回字典的键的列表d.values() # 返回字典d的值列表d.setdefault(key, default=None)# 类似get() # 但会设定d[key]=default 如果key不在字典d中 d.update(d2) # 将字典d2的键值对增加到字典d中d.iteritems() # （键，值）项的一个迭代器d.iterkeys() # 字典d中键的一个迭代器d.itervalues() # 字典d中值的一个迭代器d.popitem() # 删除元组返回键、值，若字典d为空会报key错d.viewitems() # 像对象一样提供字典d中项的一个视图d.viewkeys() # 像对象一样提供字典d中key的一个视图d.viewvalues() # 像对象一样提供字典d中value的一个视图 dict的官方内置函数可用dir(dict)与help(dict) 命令进行查看 集合set，用小括号“( )”表示 1.是一组key的集合，但不存储value，并且key不能重复创建一个set，需要提供一个list作为输入集合,s = set([1,2,3]),注意，传入的参数 [1, 2, 3] 是一个list，而显示的 set([1, 2, 3]) 只是告诉你这个set内部有1，2，3这3个元素，显示的[ ]不表示这是一个list2.重复元素在set中自动被过滤set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作 还有一种集合是forzenset( )，是冻结的集合，它是不可变的，存在哈希值，好处是它可以作为字典的key，也可以作为其它集合的元素。缺点是一旦创建便不能更改，没有add，remove方法 和dict对比1.set和dict的唯一区别仅在于没有存储对应的value2.set的原理和dict一样，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素” #!usr/bin/env python #coding:utf-8 ‘’’FuncName: study_set.pyDesc: set 内建函数Date: 2016-03-17 14:00Author: johnny‘’’ s = set([1,2,3]) # 创建一个数值set，有1，2，3三个元素s == set([1, 2, 3])se = set(‘Hello’) # 创建一个唯一字符的集合s == set([‘H’, ‘e’, ‘l’, ‘o’])a = s | se # s 和 se 的并集 set([1, 2, 3, ‘e’, ‘H’, ‘l’, ‘o’])b = s &amp; se # s 和 se 的交集 set([]) 没有相同项为空c = s – se # 求差集（项在s中，但不在se中） set([1, 2, 3])d = s ^ se # 对称差集（项在s或se中，但不会同时出现在二者中） # set([1, 2, 3, &apos;e&apos;, &apos;H&apos;, &apos;l&apos;, &apos;o&apos;]) s.issubset(t) # 如果s是t的子集,则返回True,否则返回Falses.issuperset(t) # 如果t是s的超集,则返回True,否则返回Falses.union(t) # 返回一个新集合,该集合是s和t的并集s.intersection(t) # 返回一个新集合,该集合是s和t的交集s.difference(t) # 返回一个新集合,该集合是 s 的成员,但不是 t 的成员s.symmetric_difference(t) # 返回一个新集合,该集合是s或t的成员,但不是s和t共有的成员s.copy() # 返回一个新集合,它是集合s的浅复制s.update(t) # 用t中的元素修改s，即s现在包含s或t的成员s.intersection_update(t) # s中的成员是共同属于s和t中的元素s.difference_update(t) # s中的成员是属于s但不包含在t中的元素s.symmetric_difference_update(t) # s中的成员更新为那些包含在s或t中， # 但不是s和t共有的元素 s.add(obj) # 在集合s中添加对象objs.remove(obj) # 从集合s中删除对象obj，如果obj不是集合s中的元素 # （obj not in s），将引发KeyError s.discard(obj) # 如果obj是集合s中的元素，从集合s中删除对象objs.pop() # 删除集合是中的任意一个对象，并返回它s.clear() # 删除集合s中的所有元素 set的官方内置函数可用dir(set)与help(set) 命令进行查看]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[名词 吞吐量 带宽 QPS TPS DDOS流量 并发用户数]]></title>
      <url>%2Farticles%2Fsafe-noun.html</url>
      <content type="text"><![CDATA[Throughput：吞吐量。防火墙吞吐量是指在没有帧丢失的情况下，设备能够接收并转发的最大数据速率。[1]Max net bitrate: 带宽。指链路上每秒所能传送的比特数，它取决于链路时钟速率和信道编码在计算机网络中又称为线速。可以说以太网的带宽是10Mbps。两者需要区分链路上的可用带宽（带宽）与实际链路中每秒所能传送的比特数（吞吐量）。通常更倾向于用“吞吐量”一词来表示一个系统的测试性能。这样，因为实现受各种低效率因素的影响，所以由一段带宽为10Mbps的链路连接的一对节点可能只达到2Mbps的吞吐量。 QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 TPS是 TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器 做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息来估计得分。客户机使 用加权协函数平均方法来计算客户机的得分，测试软件就是利用客户机的这些信息使用加权协函数平均方法来计算服务器端的整体TPS得分。 DDOS流量该防御值主要针对DNS服务器进行DDOS攻击所产生的流量。这种攻击方式，是指借助于客户/服务器技术，将多个计算机联合起来作为攻击平台，对一个或多个目标发动DDOS攻击，从而成倍地提高拒绝服务攻击的威力。 响应时间(RT)响应时间是指系统对请求作出响应的时间。对于一个游戏软件来说，响应时间小于100毫秒应该是不错的，响应时间在1秒左右可能属于勉强可以接受，如果响应时间达到3秒就完全难以接受了。而对于编译系统来说，完整编译一个较大规模软件的源代码可能需要几十分钟甚至更长时间，但这些响应时间对于用户来说都是可以接受的。 吞吐量(Throughput)吞吐量是指系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。 对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。 并发用户数 并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。一网站系统为例，假设用户只有注册后才能使用，但注册用户并不是每时每刻都在使用该网站，因此具体一个时刻只有部分注册用户同时在线，在线用户就在浏览网站时会花很多时间阅读网站上的信息，因而具体一个时刻只有部分在线用户同时向系统发出请求。这样，对于网站系统我们会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数。由于注册用户可能长时间不登陆网站，使用注册用户数作为性能指标会造成很大的误差。而在线用户数和同事发请求用户数都可以作为性能指标。相比而言，以在线用户作为性能指标更直观些，而以同时发请求用户数作为性能指标更准确些。 从以上概念来看吞吐量和响应时间是衡量系统性能的重要指标，QPS虽然和吞吐量的计量单位不同，但应该是成正比的，任何一个指标都可以含量服务器的并行处理能力。当然Throughput更关心数据量，QPS更关心处理笔数。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[position:absolute-top,right,bottom,left为0使用]]></title>
      <url>%2Farticles%2Fcss-top-right-bootom-left-zero.html</url>
      <content type="text"><![CDATA[绝对定位一直用起来非常方便，直接脱离文本流。偶然发现它还有个超强的功能。竟然可以撑开盒子宽高。 对外默认情况下，看代码；盒子如果设置 宽高后 设置绝对定位,bottom为0会自动抵底部。123456789101112131415161718192021222324252627282930313233343536&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; .wai&#123; position:relative; top: 300px; left: 300px; width: 233px; height: 370px; background-color: yellow; &#125; .nei&#123; position: absolute; /*top: 0px;*/ /*left: 0px; right: 0px;*/ bottom: 0px; width: 100px; height: 100px; background-color: rgba(200,200,200,0.7); &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="wai"&gt; &lt;div class="nei"&gt; &lt;!-- &lt;div class="nei-item1"&gt;1&lt;/div&gt; &lt;div class="nei-item2"&gt;2&lt;/div&gt; --&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 当我们同时设置bottom和top，nei盒子会自动抵触顶部。说明top优先级要比bottom高。当我们这个时候把nei盒子的高度去掉，这个时候神奇的事情发生了。nei的高度被撑开。同理width不设置，然后设置left,right为零，nei的宽度也会被撑开. 为了确认宽高是来源于最邻近的定位点，而不是父级，我们在wai内在加个盒子wai2并设置宽高。1.nei盒子的宽高完全由上级定位节点，而不是父级确定。2.nei盒子完全覆盖掉wai2的位置。12345678910111213141516171819202122232425262728293031323334353637383940&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; .wai&#123; position:relative; top: 300px; left: 300px; width: 233px; height: 370px; background-color: yellow; &#125; .wai2&#123; width: 100px; height: 100px; background-color: yellow; &#125; .nei&#123; position: absolute; top: 0px; left: 0px; right: 0px; bottom: 0px; background-color: red; &lt;!--background-color: rgba(200,200,200,0.7);--&gt; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="wai"&gt; &lt;div class="wai2"&gt; &lt;div class="nei"&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 对内假如nei盒子的内部有其余盒子呢，比如我们在内部加两个盒子 不设置宽度。只设置高度。宽度可以继承。而且nei盒子的宽高 还是wai盒子的宽高。但是nei盒子的内部盒子的高度已经溢出。 当nei盒子的内部盒子设置百分比时候，是相对于父级。同理height也是相对父级。可以设置都是50% 50%看下 总结来说。利用这个特性，我们内部无需再设置宽度。可直接继承。这样的好处可以实现响应式的变化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用iptables应对SYN攻击,CC攻击,ACK攻击[转]]]></title>
      <url>%2Farticles%2Fsafe-iptables.html</url>
      <content type="text"><![CDATA[三次握手的过程及相关概念TCP/IP协议使用三次握手来建立连接，过程如下：1、第一次握手，客户端发送数据包syn到服务器，并进入SYN_SEND状态，等待回复2、第二次握手，服务器发送数据报syn/ack，给客户机，并进入SYN_RECV状态，等待回复3、第三次握手，客户端发送数据包ACK给客户机，发送完成后，客户端和服务器进入ESTABLISHED状态，链接建立完成 三次握手协议中，服务器维护一个等待队列，收到一个syn包就在队列中建立一个条目，并分配一定的资源。对应的每一个条目表示已经收到一个syn请 求，并已经回复syn/ack，服务器上对应的连接已经进入SYN_RECV状态，等待客户端响应，收到客户端的响应包以后，该连接进入 ESTABLISHED状态，队列中对应的条目被删除。backlog参数：设定等待队列的最大数目。对应内核参数：net.ipv4.tcp_max_syn_backlog = 1024syn-ack重传次数：服务器发送syn/ack包，如果没有收到客户端的相应，就会重传syn/ack，超过一定时间之后会进行第二次重传，超过设定 次数以后将该条目从队列中删除。每次重传的间隔时间并不确定。对应的内核参数：net.ipv4.tcp_synack_retries = 5syn重传次数：概念和syn/ack重传次数类似，对应的内核参数：net.ipv4.tcp_syn_retries = 5等待存活时间：指等待队列的条目存活时间，即从服务器收到syn包到确认这个包无效的最长时间，该时间是所有重传包请求的最长等待时间什么是SYN 攻击 syn攻击属于DDOS攻击中的一种，利用TCP/IP的缺陷进行网络攻击，可以使用很小的资源取得十分显著的效果。其基本原理如下：服务器收到客户端的syn包，之后进入SYN_RECV状态，服务器的等待队列中增加一个条目，服务器未收到客户端的确认包，进行重传，一直到超时之后， 该条目从未链接队列中删除。客户端不断地发送syn包，而不响应来自服务器的syn/ack，等待队列的条目迅速增长，最后服务器的等待队列达到最大数 目，之后就不能再接受新的连接，一直到链接超时才从队列中删除对应的条目。配合ip地址欺骗技术，该方法可以取得十分良好的效果，基本上在攻击期间，服务 器将不能给正常的用户提供服务。这个攻击办法利用了TCP/IP协议的缺陷，攻击的目标不止于服务器，任何网络设备，只要开启了网络服务器，都可能会受到 这种攻击，导致处理器资源被大量占用，内存被用完，大量队列等待处理，针对网络设备的攻击往往会导致整个网络瘫痪。 如何减小SYN攻击的影响 1、修改等待数：1# sysctl -w net.ipv4.tcp_max_syn_backlog=2048 2、启用syncookies：1#sysctl -w net.ipv4.tcp_syncookies=1 启用syncookies可以大幅减小syn攻击带来的影响，但是却引入了新的安全缺陷 syncookie基本原理是：仔细处理连接的初始序列号而不是随机选择一个序列号。一旦server接收到SYN报文，将关键信息仔细编码并作为 state存储在SYN队列中。这种经过编码的信息是用一个秘钥进行加密hash，形成SYN-ACK报文中的序列号并发送给client。在合法握手的 第三个报文中，即从client返回给server的ACK报文中，在acknowledgment number字段中包含该序列号(加1). 这样，open双向连接所必须的所有信息又返回给server，而server在三次握手完成之前不必维护state。syn-cookies解决了 SYN的基本问题，但是随之带来一个新的问题，就是服务器需要对收到的ACK报文进行计算，提高了三次握手需要的系统资源。一种新的攻击方式随之而来，即 ACK攻击，发送大量的ACK数据报，导致服务器忙于计算最终导致服务器停止相应。Linux上的实际应用中，只有等待数被占满的时候才会启用 syncookies的方式（syncookies摘自网文） 3、修改重试次数1#sysctl -w net.ipv4.tcp_syn_retries = 0 重传次数设置为0，只要收不到客户端的响应，立即丢弃该连接，默认设置为5次4、使用iptables限制单个地址的并发连接数量：1#iptables -t filter -A INPUT -p tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK SYN -m connlimit --connlimit-above 10 --connlimit-mask 32 -j REJECT 5、使用iptables限制单个c类子网的并发链接数量：1#iptables -t filter -A INPUT -p tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK SYN -m connlimit --connlimit-above 10 --connlimit-mask 24 -j REJECT 6、限制单位时间内的连接数：123#iptables -t filter -A INPUT -p tcp --dport 80 -m --state --state NEW -m recent --set --name access --resource#iptables -t filter -A INPUT -p tcp --dport 80 -m --state --state NEW -m recent --update --seconds 60 --hitcount 30 --name access -j DROP 或者使用如下两条策略123#iptables -t filter -A INPUT -p tcp --dport 80 -m --state --syn -m recent --set#iptables -t filter -A INPUT -p tcp --dport 80 -m --state --syn -m recent --update --seconds 60 --hitcount 30 -j DROP 7、为了取得更好的效果，需要修改/etc/modprobe.conf options ipt_recent ip_list_tot=1000 ip_pkt_list_tot=60 记录10000个地址，每个地址60个包 # ip_list_tot最大为8100,超过这个数值会导致iptables错误8、限制单个地址最大连接数：1#iptables -I INPUT -p tcp --dport 80 -m connlimit --connlimit-above 50 -j DROP 应对 ACK攻击 ACK 攻击是针对syn-cookies而发产生的，通过发送大量的ACK数据报，使目标服务器忙于计算，达到拒绝服务的目的，使用iptables对发起 ACK攻击的地址进行限制1#iptables -I INPUT -p tcp --dport 80 -m connlimit --connlimit-above 50 -j DROP 限制并发连接数不大于501#iptables -t filter -A INPUT -p tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK ACK -m connlimit --connlimit-above 10 --connlimit-mask 32 -j REJECT 限制并发ACK不大于50 1#iptables -t filter -A INPUT -p tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK ACK -m recent --set --name drop 1#iptables -t filter -A INPUT -p tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK ACK -m recent --update --seconds 60 --hitcount 30 -j DROP 一分钟内大于30次的连接全部丢弃应对CC攻击 普通的CC攻击特点是所有的连接都是正常的完整的连接，这样的连接一般的防火墙是很难预防的。但是既然是网络攻击必然也具有网络攻击的共同特点，也 就是每一个攻击源都会发起尽量多的连接，因此我们仍然可以使用限制单个地址并发链接数量的办法来实现对CC攻击的抵御。具体命令同上 webcc，想必之下似乎更加难以预防，但是由于所有的访问都是由相同的一个或几个网站中转而来，这些访问请求的http_reffer都会带有这 些中转站的地址。我们只要在web服务器上设置http_reffer过滤即可大幅减小webcc攻击的影响，具体的设置这里就略过不表了 附：如何为RHEL5增加connlimit模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189#wget ftp://ftp.netfilter.org/pub/patch-o-matic-ng/snapshot/patch-o-matic-ng-20080214.tar.bz2#wget ftp://ftp.netfilter.org/pub/iptables/iptables-1.4.0.tar.bz2#bunzip2 iptables-1.4.0.tar.bz2 #tar xvf iptables-1.4.0.tar # bunzip2 patch-o-matic-ng-20080214.tar.bz2 # tar xf patch-o-matic-ng-20080214.tar #cd patch-o-matic-ng-20080214下载connlimit模块# export KERNEL_DIR=/usr/src/kernels/2.6.18-8.el5-i686/ # export IPTABLES_DIR=/root/iptables-1.4.0# ./runme --downloadSuccessfully downloaded external patch geoipSuccessfully downloaded external patch conditionSuccessfully downloaded external patch IPMARKSuccessfully downloaded external patch ROUTESuccessfully downloaded external patch connlimitSuccessfully downloaded external patch ipp2pSuccessfully downloaded external patch time./patchlets/ipv4options exists and is not external./patchlets/TARPIT exists and is not externalFailed to get http://www.intra2net.com/de/produkte/opensource/ipt_account//index, skipping..Successfully downloaded external patch pknockLoading patchlet definitions........................ doneExcellent! Source trees are ready for compilation.把connlimit应用到内核# ./runme connlimitLoading patchlet definitions........................ doneWelcome to Patch-o-matic ($Revision: 6736 $)!Kernel:2.6.18, /usr/src/kernels/2.6.18-8.el5-i686/Iptables: 1.4.0, /root/iptables-1.4.0/Each patch is a new feature: many have minimal impact, some do not.Almost every one has bugs, so don&apos;t apply what you don&apos;t need!-------------------------------------------------------Already applied: Testing connlimit... not appliedThe connlimit patch:Author: Gerd Knorr &lt;kraxel@bytesex.org&gt;Status: ItWorksForMe[tm]This adds an iptables match which allows you to restrict thenumber of parallel TCP connections to a server per client IP address(or address block).Examples:# allow 2 telnet connections per client hostiptables -p tcp --syn --dport 23 -m connlimit --connlimit-above 2 -j REJECT# you can also match the other way around:iptables -p tcp --syn --dport 23 -m connlimit ! --connlimit-above 2 -j ACCEPT# limit the nr of parallel http requests to 16 per class C sized# network (24 bit netmask)iptables -p tcp --syn --dport 80 -m connlimit --connlimit-above 16 \--connlimit-mask 24 -j REJECT-----------------------------------------------------------------Do you want to apply this patch [N/y/t/f/a/r/b/w/q/?] yExcellent! Source trees are ready for compilation.内核编译# make oldconfigscripts/kconfig/conf -o arch/i386/Kconfig** Linux Kernel Configuration*** Code maturity level options*Prompt for development and/or incomplete code/drivers (EXPERIMENTAL) [Y/n/?] y** General setup………………………………………………………………………………………………………………………………………………………..ARP tables support (IP_NF_ARPTABLES) [M/n/?] mARP packet filtering (IP_NF_ARPFILTER) [M/n/?] mARP payload mangling (IP_NF_ARP_MANGLE) [M/n/?] mConnections/IP limit match support (IP_NF_MATCH_CONNLIMIT) [N/m/?] (NEW) m提示加入了connlimit的选项，问使用哪一种模式，编译进内核还是模块，输入“m”，编译为模块CRC16 functions (CRC16) [M/n/y/?] mCRC32 functions (CRC32) [Y/?] yCRC32c (Castagnoli, et al) Cyclic Redundancy-Check (LIBCRC32C) [Y/?] y## configuration written to .config#编译模块# make modules_preparescripts/kconfig/conf -s arch/i386/KconfigCHKinclude/linux/version.hCHKinclude/linux/utsrelease.hHOSTCCscripts/genksyms/genksyms.oHOSTCCscripts/genksyms/lex.oHOSTCCscripts/genksyms/parse.oHOSTLDscripts/genksyms/genksymsCCscripts/mod/empty.oMKELFscripts/mod/elfconfig.hHOSTCCscripts/mod/file2alias.oHOSTCCscripts/mod/modpost.oHOSTCCscripts/mod/sumversion.oHOSTLDscripts/mod/modpost[root@localhost 2.6.18-8.el5-i686]# mv net/ipv4/netfilter/Makefile net/ipv4/netfilter/Makefile.bak备份原来的文件# make M=net/ipv4/netfilter/LDnet/ipv4/netfilter/built-in.oCC [M]net/ipv4/netfilter/ipt_connlimit.oBuilding modules, stage 2.MODPOSTCCnet/ipv4/netfilter/ipt_connlimit.mod.oLD [M]net/ipv4/netfilter/ipt_connlimit.ko#cp net/ipv4/netfilter/ipt_connlimit.ko /lib/modules/2.6.18-8.el5/kernel/net/ipv4/netfilter/# chmod 744 /lib/modules/2.6.18-8.el5/kernel/net/ipv4/netfilter/ipt_connlimit.ko # depmod -a[root@localhost 2.6.18-8.el5-i686]# modprobe ipt_connlimit# lsmod |grep connip_conntrack_netbios_ns69770 ipt_connlimit76806 ip_conntrack531533 ip_conntrack_netbios_ns,xt_state,ipt_connlimitnfnetlink107131 ip_conntrackx_tables173498 ipt_recent,xt_state,ipt_REJECT,ipt_connlimit,ip_tables,ip6t_REJECT,xt_tcpudp,ip6_tables 好了，模块安装完毕。可以使用connlimit策略了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[服务器网站被CC攻击的解决方法]]></title>
      <url>%2Farticles%2Fsafe-cc.html</url>
      <content type="text"><![CDATA[作为站长或者公司的网站的网管，什么最可怕？显然是网站受到的DDoS攻击。大家都有这样的经历，就是在访问某一公司网站或者论坛时，如果这个网站或者论坛流量比较大，访问的人比较多，打开页面的速度会比较慢，对不?!一般来说，访问的人越多，网站或论坛的页面越多，数据库就越大，被访问的频率也越高，占用的系统资源也就相当可观。 首先，什么事CC攻击？ 攻击者借助代理服务器生成指向受害主机的合法请求，实现DDOS,和伪装就叫：CC(ChallengeCollapsar)。CC主要是用来攻击页面的。大家都有这样的经历，就是在访问论坛时，如果这个论坛比较大，访问的人比较多，打开页面的速度会比较慢，访问的人越多，论坛的页面越多，数据库就越大，被访问的频率也越高，占用的系统资源也就相当可观。一个静态页面不需要服务器多少资源，甚至可以说直接从内存中读出来发给你就可以了，但是论坛就不一样了，我看一个帖子，系统需要到数据库中判断我是否有读帖子的权限，如果有，就读出帖子里面的内容，显示出来——这里至少访问了2次数据库，如果数据库的数据容量有200MB大小，系统很可能就要在这200MB大小的数据空间搜索一遍，这需要多少的CPU资源和时间？如果我是查找一个关键字，那么时间更加可观，因为前面的搜索可以限定在一个很小的范围内，比如用户权限只查用户表，帖子内容只查帖子表，而且查到就可以马上停止查询，而搜索肯定会对所有的数据进行一次判断，消耗的时间是相当的大。CC就是充分利用了这个特点，模拟多个用户（多少线程就是多少用户）不停的进行访问（访问那些需要大量数据操作，就是需要大量CPU时间的页面）.这一点用一个一般的性能测试软件就可以做到大量模拟用户并发。 CC攻击是DDoS(分布式拒绝服务)的一种，相比其它的DDoS攻击CC似乎更有技术含量一些。这种攻击你见不到虚假IP，见不到特别大的异常流量，但造成服务器无法进行正常连接，一条ADSL的普通用户足以挂掉一台高性能的Web服务器。由此可见其危害性，称其为”Web杀手”毫不为过。最让站长们忧虑的是这种攻击技术含量不是很高，利用工具和一些IP代理，一个初、中级的电脑水平的用户就能够实施DDoS攻击。 那么怎样保证这些网站服务器的安全呢？防护CC攻击大家有必要了解CC攻击的原理及如果发现CC攻击和对CC攻击的防范措施。 一、CC攻击的原理：CC攻击的原理就是攻击者控制某些主机不停地发大量数据包给对方服务器造成服务器资源耗尽，一直到宕机崩溃。CC主要是用来攻击页面的，每个人都有这样的体验：当一个网页访问的人数特别多的时候，打开网页就慢了，CC就是模拟多个用户(多少线程就是多少用户)不停地进行访问那些需要大量数据操作(就是需要大量CPU时间)的页面，造成服务器资源的浪费，CPU长时间处于100%，永远都有处理不完的连接直至就网络拥塞，正常的访问被中止。 二、CC攻击的种类：CC攻击的种类有三种，直接攻击，代理攻击，僵尸网络攻击。 直接攻击主要针对有重要缺陷的WEB应用程序，一般说来是程序写的有问题的时候才会出现这种情况，比较少见。 僵尸网络攻击有点类似于DDOS攻击了，从WEB应用程序层面上已经无法防御。 代理攻击：CC攻击者一般会操作一批代理服务器，比方说100个代理，然后每个代理同时发出10个请求，这样WEB服务器同时收到1000个并发请求的，并且在发出请求后，立刻断掉与代理的连接，避免代理返回的数据将本身的带宽堵死，而不能发动再次请求，这时WEB服务器会将响应这些请求的进程进行队列，数据库服务器也同样如此，这样一来，正常请求将会被排在很后被处理，就象本来你去食堂吃饭时，一般只有不到十个人在排队，今天前面却插了一千个人，那么轮到你的机会就很小很小了，这时就出现页面打开极其缓慢或者白屏。 三、攻击症状CC攻击有一定的隐蔽性，那如何确定服务器正在遭受或者曾经遭受CC攻击呢?我们可以通过以下三个方法来确定。 (1).命令行法一般遭受CC攻击时，Web服务器会出现80端口对外关闭的现象，因为这个端口已经被大量的垃圾数据堵塞了正常的连接被中止了。我们可以通过在命令行下输入命令netstat-an来查看，如果看到类似如下有大量显示雷同的连接记录基本就可以被CC攻击了：12345678910111213……TCP 192.168.1.3:80 192.168.1.6:2205 SYN_RECEIVED 4TCP 192.168.1.3:80 192.168.1.6: 2205 SYN_RECEIVED 4TCP 192.168.1.3:80 192.168.1.6: 2205 SYN_RECEIVED 4TCP 192.168.1.3:80 192.168.1.6: 2205 SYN_RECEIVED 4TCP 192.168.1.3:80 192.168.1.6: 2205 SYN_RECEIVED 4…… 其中”192.168.1.6”就是被用来代理攻击的主机的IP，”SYN_RECEIVED”是TCP连接状态标志，意思是”正在处于连接的初始同步状态”，表明无法建立握手应答处于等待状态。这就是攻击的特征，一般情况下这样的记录一般都会有很多条，表示来自不同的代理IP的攻击。 (2).批处理法上述方法需要手工输入命令且如果Web服务器IP连接太多看起来比较费劲，我们可以建立一个批处理文件，通过该脚本代码确定是否存在CC攻击。打开记事本键入如下代码保存为CC.bat：123456789@echoofftime /t &gt;&gt;log.lognetstat -n -p tcp |find &quot;:80&quot;&gt;&gt;Log.lognotepad log.logexit 上面的脚本的含义是筛选出当前所有的到80端口的连接。当我们感觉服务器异常是就可以双击运行该批处理文件，然后在打开的log.log文件中查看所有的连接。如果同一个IP有比较多的到服务器的连接，那就基本可以确定该IP正在对服务器进行CC攻击。 (3).查看系统日志上面的两种方法有个弊端，只可以查看当前的CC攻击，对于确定Web服务器之前是否遭受CC攻击就无能为力了，此时我们可以通过Web日志来查，因为Web日志忠实地记录了所有IP访问Web资源的情况。通过查看日志我们可以Web服务器之前是否遭受CC攻击，并确定攻击者的IP然后采取进一步的措施。 Web日志一般在C:\WINDOWS\system32\LogFiles\HTTPERR目录下，该目录下用类似httperr1.log的日志文件，这个文件就是记录Web访问错误的记录。管理员可以依据日志时间属性选择相应的日志打开进行分析是否Web被CC攻击了。默认情况下，Web日志记录的项并不是很多，我们可以通过IIS进行设置，让Web日志记录更多的项以便进行安全分析。其操作步骤是： “开始→管理工具”打开”Internet信息服务器”，展开左侧的项定位到到相应的Web站点，然后右键点击选择”属性”打开站点属性窗口，在”网站”选项卡下点击”属性”按钮，在”日志记录属性”窗口的”高级”选项卡下可以勾选相应的”扩展属性”，以便让Web日志进行记录。比如其中的”发送的字节数”、”接收的字节数”、”所用时间”这三项默认是没有选中的，但在记录判断CC攻击中是非常有用的，可以勾选。另外，如果你对安全的要求比较高，可以在”常规”选项卡下对”新日志计划”进行设置，让其”每小时”或者”每一天”进行记录。为了便于日后进行分析时好确定时间可以勾选”文件命名和创建使用当地时间”。 四、CC攻击防御策略确定Web服务器正在或者曾经遭受CC攻击，那如何进行有效的防范呢? (1).取消域名绑定一般cc攻击都是针对网站的域名进行攻击，比如我们的网站域名是”www.star-net.cn”，那么攻击者就在攻击工具中设定攻击对象为该域名然后实施攻击。 对于这样的攻击我们的措施是在IIS上取消这个域名的绑定，让CC攻击失去目标。具体操作步骤是：打开”IIS管理器”定位到具体站点右键”属性”打开该站点的属性面板，点击IP地址右侧的”高级”按钮，选择该域名项进行编辑，将”主机头值”删除或者改为其它的值(域名)。 经过模拟测试，取消域名绑定后Web服务器的CPU马上恢复正常状态，通过IP进行访问连接一切正常。但是不足之处也很明显，取消或者更改域名对于别人的访问带来了不变，另外，对于针对IP的CC攻击它是无效的，就算更换域名攻击者发现之后，他也会对新域名实施攻击。 (2).域名欺骗解析如果发现针对域名的CC攻击，我们可以把被攻击的域名解析到127.0.0.1这个地址上。我们知道127.0.0.1是本地回环IP是用来进行网络测试的，如果把被攻击的域名解析到这个IP上，就可以实现攻击者自己攻击自己的目的，这样他再多的肉鸡或者代理也会宕机，让其自作自受。 另外，当我们的Web服务器遭受CC攻击时把被攻击的域名解析到国家有权威的政府网站或者是网警的网站，让其网警来收拾他们。 现在一般的Web站点都是利用类似”新网”这样的服务商提供的动态域名解析服务，大家可以登录进去之后进行设置。 (3).更改Web端口一般情况下Web服务器通过80端口对外提供服务，因此攻击者实施攻击就以默认的80端口进行攻击，所以，我们可以修改Web端口达到防CC攻击的目的。运行IIS管理器，定位到相应站点，打开站点”属性”面板，在”网站标识”下有个TCP端口默认为80，我们修改为其他的端口就可以了。 (4).IIS屏蔽IP我们通过命令或在查看日志发现了CC攻击的源IP，就可以在IIS中设置屏蔽该IP对Web站点的访问，从而达到防范IIS攻击的目的。在相应站点的”属性”面板中，点击”目录安全性”选项卡，点击”IP地址和域名现在”下的”编辑”按钮打开设置对话框。在此窗口中我们可以设置”授权访问”也就是”白名单”，也可以设置”拒绝访问”即”黑名单”。比如我们可以将攻击者的IP添加到”拒绝访问”列表中，就屏蔽了该IP对于Web的访问。 五、CC攻击的防范手段防止CC攻击，不一定非要用高防服务器。比如，用防CC攻击软件就可以有效的防止CC攻击。推荐一些CC的防范手段： 1、优化代码尽可能使用缓存来存储重复的查询内容，减少重复的数据查询资源开销。减少复杂框架的调用，减少不必要的数据请求和处理逻辑。程序执行中，及时释放资源，比如及时关闭mysql连接，及时关闭memcache连接等，减少空连接消耗。 2、限制手段对一些负载较高的程序增加前置条件判断，可行的判断方法如下： 必须具有网站签发的session信息才可以使用（可简单阻止程序发起的集中请求）；必须具有正确的referer（可有效防止嵌入式代码的攻击）；禁止一些客户端类型的请求（比如一些典型的不良蜘蛛特征）；同一session多少秒内只能执行一次。 3、完善日志尽可能完整保留访问日志。日志分析程序，能够尽快判断出异常访问，比如单一ip密集访问；比如特定url同比请求激增。 六、针对CC攻击的商业解决方案很多的网站管理者是等到网站遭到攻击了，受到损失了，才去寻求解决的方案，在将来的互联网飞速发展的时代，一定要有安全隐患意识，不要等到损失大了，再去想办法来补救，这样为时已晚。然而当网站受到攻击时，大多数人想到的是—–快点找硬防，基本上都步了一个误区，就是认为网站或者服务器被攻击，购买硬件防火墙，什么事都万事大吉了，实际上这样的想法是极端错误的。多年的统计数据表明，想彻底解CC攻击是几乎不可能的，就好比治疗感冒一样，我们可以治疗，也可以预防，但却无法根治，但我们若采取积极有效的防御方法，则可在很大程度上降低或减缓生病的机率，防治DDOS攻击也是如此。 实际上比较理想解决方案应该是”软件+硬件”的解决方案。此方案对于资金较为充足的企业网站来说，这个方案适合他们；硬件在DDOS防护上有优势，软件CC防护上有优势；相对于一些对于ICP内容网站、论坛社区BBS、电子商务eBusiness、音乐网站Music、电影网站File等网站服务器越来越普及，但由于种种原因往往会遭受竞争对手或打击报复者的恶意DDOS攻击，持续的攻击会导致大量用户流失，严重的甚至因人气全失而被迫关闭服务器，为了最大程度的保护运营者的利益，冰盾科技结合多年抗DDOS的实践经验给出了最少的安全投资可获得最大安全回报的抗DDOS解决方案。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[study clojure]]></title>
      <url>%2Farticles%2Fstudy-clojure.html</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Compass中文手册]]></title>
      <url>%2Farticles%2Fcompass.html</url>
      <content type="text"><![CDATA[开始compass目前已经不再维护，但有些东西仍值得学习。 Version: 1.0.1 开始使用CompassCompass 是一款使用Sass语言 编写的开源的css设计框架，使用起来强大和简单. 如果你对Sass不熟悉, 可以去sass-lang.com学习如何使用. 安装Compass请按照Compass 安装指南按步骤安装Compass和Sass。 如果需要验证版本，可以运行以下命令: 1$ compass version 监视和编译你的项目（ps：watch参数就是，监控你的项目是否则有文件改动，一旦有改动，就自动转成css。） 当开发项目时, 你可以运行compass监视器 ，自动修改你的css文件到最新状态。 12$ cd /path/to/project$ compass watch 当在生产环境中编译你的css文件的时, 通过 –production 编译器将默认对终端(就是我们用的浏览器)优化输出(其实就是精简): 1$ compass compile --production 使用Compass不用命令行你可以不用compass命令行. 在一些情况下, 对于一些不是明确支持Compasssass编译器和框架，这样更容易集成.12345678910$ gem install compass-core$ cat &lt;&lt;- EOF &gt; _project-setup.scss\$project-path: absolute-path(join-file-segments(".."));@import "compass/configuration";\$compass-options: (http_path: "/");@include compass-configuration(\$compass-options);EOFAdd to the top of each sass file: @import "project-setup";Compile using the Sass command line:$ sass -r compass-core --update sass:css 详情请读: Compass’s Sass-based配置选项. 更多配置命令所有compass命令的文档可以通过运行下面的代码发现:1$ compass help 可以设置一个可选参数，指定具体的一个命令:1$ compass help &lt;command&gt; 就是指定的命令参数 (例如. compile) 教程教程Compass 教程这个教程还在改进, 如果这里还有什么教程没有涉及到，请看 Compass 联络表， 那里有很多compass大神帮你解决。 Compass入门如果你对Compass不熟悉, 你最好看看 最佳练习, 配置参照, 变量配置, 还有 命令行手册. 贡献点?如果你使用Compass中有些建议和想法, 可以看下贡献 和 创建插件. 应用集成应用集成Ruby on RailsRails 3.1（一款构建在 Ruby 语言之上的一款web框架） 添加compass到你的依赖中: 1gem 'compass' 也可以去 gist(一款代码分享平台)看看 Rails 3 1compass init rails /path/to/myrailsproject Rails 2.3 1rake rails:template LOCATION=http://compass-style.org/rails/installer SinatraSinatra （基于ruby的微型web框架）123456789101112131415161718require 'compass'require 'sinatra'require 'haml'configure do set :haml, &#123;:format =&gt; :html5&#125; set :scss, &#123;:style =&gt; :compact, :debug_info =&gt; false&#125; Compass.add_project_configuration(File.join(settings.root, 'config', 'compass.rb'))endget '/stylesheets/:name.css' do content_type 'text/css', :charset =&gt; 'utf-8' scss :"stylesheets/#&#123;params[:name]&#125;", Compass.sass_engine_optionsendget '/' do haml :indexend 假设你保存配置文件到 config/compass.rb. 如果你保存样式表到 “views/stylesheets/” 目录，而不是 “views/”, 记得按你设置好的配置更新 sass_dir . 看看 sample compass-sinatra project 实时运行! Sinatra Bootstrap - 一个 支持Haml, Sass, Compass, jQuery 等 的Sinatra项目. nanocnanoc 是一个用 Ruby 实现的静态网页产生工具 最小集成: 只需要拖他进去 最简单的途径集成compass到nanoc. 更改 config.rb 指向到你所使用的样式表. 你需要单独运行一个窗口用Compass watch命令监控编译nanoc程序. 实力项目，如: unthinkingly. 标准集成 Nanoc文件规范的首要要点, 像这样加载 Compass 配置文件:1234567require 'compass'Compass.add_project_configuration 'compass.rb'# when using Compass &gt; 0.10sass_options = Compass.sass_engine_options# when using Compass &gt; 0.10Compass.configuration.parse 'compass.rb' when using Compass &lt; 0.10sass_options = Compass.config.to_sass_engine_options when using Compass &lt; 0.10 创建并配置一个 compass.rb 文件到你站点的根目录 .示例配置:1234567891011http_path = "/"project_path = File.expand_path(File.join(File.dirname(__FILE__), '..'))css_dir = "output/stylesheets"sass_dir = "content/stylesheets"images_dir = "assets/images"javascripts_dir = "assets/javascripts"fonts_dir = "assets/fonts"http_javascripts_dir = "javascripts"http_stylesheets_dir = "stylesheets"http_images_dir = "images"http_fonts_dir = "fonts" 根据您的目录结构和配置，您可能需要更改一些目录的路径。1234567Sass 和 Compass过滤样式表, 从Compass按照配置好的sass引擎，调用sass进行过滤, 如下: compile '/stylesheets/*' do filter :sass, sass_options.merge(:syntax =&gt; item[:extension].to_sym) end nanoc projects using the formal approach 站点 最佳方法按下面的方法可以使你的项目更以维护和创建. 使用一个Base样式表文件 创建一个_base.scss partial(部分) 用来初始化样式表中共同的变量和集成一些你经常使用的工具。 _base.scss12345678$blueprint-grid-columns : 24;$blueprint-grid-width : 30px;$blueprint-grid-margin : 10px;$font-color :333;@import "compass/reset";@import "compass/utilities";@import "blueprint"; // etc._base.scss 同时也是储存你自定义 mixins(混合)的好地方, 所以它可以供任何样式表用。 你可以在其他样式表中包含它: application.scss 12345@import &quot;base&quot;;#wrapper &#123; @include container;&#125; // etc.如果你想覆盖掉base.scss,可以在@import-ing之前，定义一些compass/framework 常量. 请参见可配置的变量里具体的例子. 请注意，您可以参考 base.scss的，因为它是局部的,所以名字没有前置下划线和扩展名。(译者注:这里意思就是partial是公共部分，不属于私有，所以起名字的时候不要加或者扩展名) 编写自定义Mixins Mixins让你通过一条命令就可以把多个样式表插入选择器. 这样可以使你的源码避免重复，提升可维护性. 使用mixins让你的样式表源码像自己注释的文档 – 这样更易读，例如 @include round-corners(6px,f00) 要比列出多条语句强很多。 自由标记样式表 从一个站点的页面中提取出我们所关注的css样式. 这样看似更易于维护. 然而, 事实上, 由于CSS功能上的限制抽象成符合DRY原则的可维护的代码. 不过sass它能让我们能够创建完全抽象和重用的代码，允许我们把所有的样式移入到样式表里。 读这篇博客关于这个问题的更多信息 一旦你有整洁的标记，使用mixin和继承的样式表。整洁清晰的抽象，您应该能够阅读网页的样式表,甚至没有在Web浏览器中加载该页,就想象出页面会是什么样子。 如果你发现语义化的选择器使得你的css表臃肿，是时候到重构的时间了，例如，此样式表将产生不必要的膨胀: 1234567891011@mixin three-column &#123; .container &#123; @include container; &#125; .header, .footer &#123; @include column(24); &#125; .sidebar &#123; @include column(6); &#125; article &#123; @include column(10); &#125; .rightbar &#123; @include column(8); &#125;&#125;body#article,body#snippet,body#blog-post &#123; @include three-column; &#125; 相反的，问问自己，“这些页面非样式的实质共同点是什么？”在这种情况下，他们的所有内容页面，最好把这些页面的body类单独编辑。(译者注，上面的sass样式表，编写完很臃肿冗余的。这把所有页面的内容都合并在了一起。产生太多没必要的语句。所以为了省代码，不如单独写更易于维护) 嵌套选择器不要太多层。 从零开始进行样式处理或以应用程序的一些常见的基点，要比应付不想要的风格到您的新设计的容易多。这样，在标记书中使用一些选择器，最好使用一些基本嵌套样式。然后使用重构模式的出现，减少膨胀。 重要的是过长嵌套的选择器会导致一个小渲染的性能损失，可以减缓您的Web页面。没有必要完全模仿你的css文档结构。嵌套只有足够深的选择器是唯一的部分。例如，不要使用table thead tr th，当一个简单th选择器时就足够了。这可能意味着你必须把你的风格分成若干选择器，让文档级联工作。 促进促进Compass发展感谢您有兴趣在促进compass发展。我们因你而变，如果这里有难以懂的地方，请让我们知道。如果你发现文档中的错误，可以按步骤告知我们 Step 1: 去github上注册个账号. Step 2: 用你的账户Fork Compass. 简单改进感谢gihub让我们的迭代更加加单. 克隆镜像到本地，commit你的项目。 编辑文档compass文档存在两个地方. 一个在compass-style.org directory但大部分Sass中的注释生成文档文件本身。一个在github。 修复BugsStep 3: 如果发现bug请及时bug，以便我们更新 Step 4: 如果你不知道如如何提交。点 the code Step 5: 修复bug推送进度. 请务必提到的bug ID在您的提交消息，像这样: 123Fixed the display of the fizzlebuzz in IE6.Closes GH-123. Step 6: 尽可能在多个浏览器上测试 Step 7: 确保测试通过. 完善测试 可以提交代码了 更改样式表如果你有什么好想法，别害羞发给我哈。 许多特征的想法很好，非常适合compass核心库。在这些情况下，你可以创建一个罗盘的扩展。有时这是因为compass的哲学概念不合。有时这只是因为我们认为这个想法需要时间考验。。Step 3: 如果你不知道如如何提交 Step 4: 点添加特性. Step 5: 写测试发给我们. Step 6: 编写文档实例给我们 结束 更改ruby如果你是对Ruby的规划工作方面的事情，假设你知道怎么读的代码，并使用标准Ruby工具，例如rake, gem, bundler, test/unit, cucumber, rspec,等。如果您有任何问题，请询问。问题随着解决。 补丁提交如果你有多个功能要提交，请创建一个主分支，然后合并，迭代更新。 创建一个主分支:$ git checkout -b new_branch_name… 可以commit一下 …$ git push origin new_branch_name你可以看到url的改变:1http://github.com/your_user_name/compass/commits/new_branch_name 如果你有单提交的补丁，保存到master分支。但请记住，这些变更可能被刻意地挑选出来。一旦你的变更GitHub上，确保你针对选择上游分支开发，选择包含您的更改适当的分支并发送一个pull请求。。大部分的描述应该在commit信息中–因此，没有必要写一大堆在请求消息。 Pull 请求实例简单说Pull请求就是从fork到merge的整个过程 像compass页面的pull request由管理问题托管。代码审查由compass的核心团队成员维护: 更新被拒绝 – 更新不符合compass规范. 如果你的修改更好, 至少等到他已经到期，或者用户认可。更新被拒绝, 除非 – 有时,有丢失的部分，或其他的变化需要作出的更改。建议指出要解决的问题更新统一 – 更新合并到compass, 小的改动由提交者合并后提交。 项目结构1234567891011121314151617181920212223242526272829303132compass/ core/ - compass配置和样式核心文件. frameworks/ - 该目录框架自动加载。 compass/ - compass框架 stylesheets/ - compass库 templates/ - compass模板和模式 test/ - 单元测试 lib/ compass-core.rb - compass-core ruby 库 compass/ core/ sass_extensions/ - 增强 Sass functions/ - Sass函数 monkey_patches/ - sass 更改 configuration/ - 支持的项目配置 cli/ - compass命令行 bin/ compass - CLI 可执行文件 devbin/ - 安装包后的脚本文件 test/ - 单元测试 features/ - compass测试 lib/ compass.rb - compass-core ruby 库 compass/ app_integration/ - 集成app框架 commands/ - UI 不支持命令 configuration/ - 一些特殊的命令 exec/ - UI 命令 installers/ - 安装模板支持 compass-style.org/ - 文档源码 output/ - 生成文档 import-once/ - 引入Compass 一般哲学(其实就是规范)1.用户可以指定选择器。compass永远不会强制用户使用一个样式的类名。 2.Compass 不需要javascript 3.compass核心与设计无关。这就是为什么compass没有栅格系统，因为栅格系统和设计有关。 4.compass并不特别，compass能做的，扩展也能做。5.Sass非常棒 – compass使Sass更容易，并证明如何使用Sass充分发挥其潜力。.6.浏览器的兼容很头疼。需要共同解决。7.默认情况下，compass支持尽可能多的浏览器，渐进增强，向后兼容。 8.compass是一个Sass的试验场。watcher和 color function的例子转移到sass。 样式约定1.框架所有的样式都是(私有)部分. 它们由一个下划线开始. 否则, Sass 将直接在用户的css目录创建样式表2.Compass不引入额外样式. 也有例外如 resets 和 集成的基类。3.Mixins 提供两个级别的默认设置. 第一是一个全局默认，可以重写一次. 第二个默认mixin如果包含进来，可以重写.4.Mixin 参数名称的公共API部分,确保易懂，不要简短.5.创建一个新的文件夹放样式表, 用一个和文件夹名一样的样式表导入所有的样式表 .6.尽量避免通过选择器作为参数。 常见问题 &amp;杂项信息设置Git 请按照以下这些指示来设置您的电子邮件地址和属性的信息。. 下载git repo:1git clone git@github.com:your_username/compass.git 链接远程 repo:12cd compassgit remote add chriseppstein git://github.com/chriseppstein/compass.git 获取最近更新:1git fetch chriseppstein 在开发中使用compass使用本地脚本可以放在 /path/to/compass/bin/compass 。 你可以添加 /path/to/compass/bin 到$PATH(环境变量), 或者选择其他目录.创建安装gem:编辑 VERSION 改变 version像这样: 1.0.0.something-unique-to-me.012gem build compass.gemspecgem install compass-0.10.6.something-uniq-to-me.0.gem – 如果安装gems到你的系统, 你可能需要用 sudo . 如果你不明白什么意思，就加上它(sudo意思就是superuser do 的缩写)捆绑环境, 你可以像这样用gem安装compass:``linuxgem ‘compass’, :path =&gt; “/Users/myusername/some/path/to/compass”12345ruby将自动执行捆绑命令配置ruby目录 . ruby的加载路径可以这么设置```linuxexport RUBYLIB=/Users/myusername/some/path/to/compass/lib 运行测试 你必须安装Ruby到你的系统. 配置完git, 切换到root目录通过git checkout到compass分支1cd compass 捆绑安装Ruby gem.1gem install bundler 用sudo安装gems, 配置依赖:1bundle install --binstubs devbin 核心库和样式测试:1bundle exec rake test features 运行性能测试1./devbin/cucumber 如果样式测试失败, 捕获输出的测试项目在1test/fixtures/stylesheets/&lt;project&gt;/saved/ 编写样式测试Compass已经对每个样式表测试, 直接可以导入任何其他依赖关系和重构，不会影响到输出. 在某种程度上，在不同的浏览器测试是一项巨大工程。如果你有想法，请让我们知道如何做到这一点在test/fixtures/stylesheets目录, 有许多的compass项目. 测试添加更新文件,修改错误保证他们都通过. 安全起见，它可能错过一些问题。如果您添加一个新的样式表到compass，请确保添加一个新样式表，增加新的样式规则。 重新选择或重新定位. 我们该怎么办?根据任何数目的原因，包括但不限于星星多少，您的更改不会简单合并到compass。例如，我们会考虑master的稳定，而不是改变的地方，或者我们可以把所有同类更改合并在一起，形成一个单一的提交在时间，或者我们可能希望改变你已经提交，它被安置到顶部但没有改变。在这些情况下，有两种方法你有两种选择: 1.如果您有一些变化的一个分支，尚未接受，但其他分支上的变化被接受，那么您应该运行以下命令（确保fetch最新）:12git checkout branch_name; git rebase chriseppstein/master(假设的变化应用到主分支) 2.如果你所有在分支的改变被接受或你不想再保留:1git checkout master; git branch -D branch_name; git push origin :branch_name 创建Compass扩展Compass扩展Compass,其核心，是在Sass基础上建立的框架。它是提供创建，安装和可重复使用的样式表的工具，它提供从全面布局小部件框架设计，甚至整页的设计。Sass让HTML页面的语义明确的和设计细节省力。本文档描述了compass扩展的工具集，这样您就可以建立你自己的compass的扩展。 基础布局 my_extension||- stylesheets (sass加载路径)| || |- my_extension (not technically required, but it’s good to scope imports by the name of the extension)| | || | |- _module_one.sass (this file would be imported using @import my_extension/module_one.sass)| | |- _module_two.sass (this file would be imported using @import my_extension/module_two.sass)| | |- …| || |- _my_extension.sass (This file will import the entire extension using @import my_extension.sass)||- templates (this is where templates/patterns go)| || |- project (this should be provided if you’d like people to be able to base their project on the extension)| | || | |- manifest.rb (this file should declare the contents of the template)| | |- screen.sass (this would be the main stylesheet, importing from your extension and demonstrating its use)| | |- print.sass (this file would set up basic print styles)| | |- ie.sass (if you want, you can provide custom styles for IE)| || |- some_pattern| || |- manifest.rb| |- some.sass (some sass is probably in order, always import from the extension library as much as possible)| |- some_script.js (yes, you can provide javascript code)| |- some_image.png (and images)| |- some_content.html.haml (and even html and haml)| |- some_other_file.txt (and other arbitrary files)||- lib (optional ruby code) | |- my_extension.rb (this code can register your framework if you deviate from conventions and require sass extensions, etc.) |- compass-my_extension.rb (This file is automatically required by compass if it is present. Avoiding the need to pass -r to the compass command line tool.) | |- my_extension | |- sass_extensions.rb (this is the standard location to place sass functions)Names in bold are part of the extension naming convention. Generating an Extension If you want a leg up to get started working on your extension, you can use compass to generate an extension with the following command: compass create my_extension –using compass/extensionThis will create a few basic files and folders to get you started. If you prefer to use the scss syntax for your extension run the following command instead: compass create my_extension –using compass/extension -x scssAdvanced Layout Options Library File Location The extension library file referenced above as my_extension/lib/my_extension.rb can actually be stored at any of the following three locations: my_extension/compass_init.rbmy_extension/lib/my_extension.rb (NOTE: You must use this one if you’re distributing as a rubygem.)my_extension/my_extension.rbThe first of those locations found (in the above order) will be loaded. The compass_init.rb file takes priority, so that extensions that want to work differently as compass extensions than they do as normal ruby libraries, have a way of targeting compass. Stylesheet and Template Locations If you’d like to store your stylesheets and/or templates in a non-standard location within your extension, you must provide a library file and register the extension explicitly like so: base_directory = File.join(File.dirname(FILE), ‘..’)stylesheets_dir = File.join(base_directory, ‘my’, ‘stylesheets’)templates_dir = File.join(base_directory, ‘my’, ‘templates’)Compass::Frameworks.register(‘my_extension’, :stylesheets_directory =&gt; stylesheets_dir, :templates_directory =&gt; templates_dir)If you’re following the standard naming convention, but the stylesheet and template directories are not at the top level, you can just do this instead: path from the library file to where you’re keeping your compass stuff.base_directory = File.join(File.dirname(FILE), ‘..’, ‘compass’)Compass::Frameworks.register(‘my_extension’, :path =&gt; base_directory)Adding Configuration Options to Compass For details on how to add new configuration options to compass read this. Conventions to Follow The following are not required, but are standards that your framework should attempt to adhere to unless there’s a good reason not to do so. Have a single import for your framework.Break up your framework into modules so that people can import just smaller pieces for faster load times when they’re not using everything.Use partials (files starting with an underscore) for stylesheets that are meant to be imported. If you do not Sass will generate css files for your libraries in some configurations.Provide a project template. If you do not, your project should only be providing widgets or page designs, etc.Building a Template (a.k.a. Pattern)Manifest Files The manifest file declares the template contents and tells compass information about the files in the template. An Example Manifest File description “My awesome compass plugin.” stylesheet ‘screen.sass’, :media =&gt; ‘screen, projection’stylesheet ‘partials/_base.sass’stylesheet ‘print.sass’, :media =&gt; ‘print’stylesheet ‘ie.sass’, :media =&gt; ‘screen, projection’, :condition =&gt; “lt IE 8” image ‘grid.png’javascript ‘script.js’ html ‘welcome.html.haml’, :erb =&gt; truefile ‘README’ help %Q{This is a message that users will see if they type compass help my_extension You can use it to help them learn how to use your extension.} welcome_message %Q{This is a message that users will see after they install this pattern.Use this to tell users what to do next.}You may also see some real manifest files here: blueprintcompass-css-lightboxManifest Declarations Easy Mode: If you just have some basic files and nothing fancy going on, simply place this line in your manifest: discover :allIf the file is missing discover :all is the default This will cause compass to find all the files in your template and use the files’ extension to determine where they should go. Alternatively, you can request that compass only discover files of a certain type. For example, the following will only discover javascript and image assets, you could then declare other file types on your own. discover :javascriptsdiscover :imagesThe following types may be discovered: :stylesheets, :images, :javascripts, :fonts, :html, :files, and :directories Normal Mode: There are seven kinds of manifest declarations: stylesheet - Declares a sass file.image - Declares an image.javascript - Declares a javascript file.font - Declares a font file.html - Declares an html file.file - Declares a random file.directory - Declares a directory should be created.All declarations take the path to the file as their first argument. Note that the normal slash / can and should be used in a manifest. Compass will take care of the cross platform issues. The path to the file will be reproduced in the user’s project, so please keep that in mind when creating folders. The location where files are going to be installed is dictated by the user’s project configuration, however, a template can place things into subdirectories relative to those locations. Common options: :erb - When set to true, the file will be processed via the ERB templating language. See the “Advanced Manifests” section below for more details.:to - The location where the file should be installed relative to the type-specific location.:like - Most often used with a file declaration, this option allows you to install into the location of another manifest type (and also :css). E.g. :like =&gt; :cssStylesheet options: :media - this is used as a hint to the user about the media attribute of the stylesheet link tag.:condition - this is used to hint the user that a conditional comment should be used to import the stylesheet with the given condition.Directory options: :within - where the directory should be created. If omitted, the directory will be relative to the project directory. Can be one of: the followingsass_dirjavascripts_dirfonts_dirimages_dirHTML files: You can provide html as haml or as plain html. If you provide haml, the haml will be converted to html when it is installed, unless the project allows haml files. Providing html files is usually done to demonstrate how to use a more complicated design and to get the user started off with working product. Advanced Manifests and Templates ERB Processing - This can be used to customize the contents of the file in an extension template. The template will be processed in the context of a TemplateContext instance, which gives you access to the full project configuration information as well as the command line options. Since it’s unlikely many templates will need this functionality, I leave it as an exercise of the user to figure it out and if they can’t to contact the compass-devs mailing list for assistance.no_configuration_file! - calling this method within the manifest will tell the installer to skip the creation of a configuration file.skip_compilation! - calling this method within the manifest will tell the installer to skip compilation of sass files to css.Distributing Extensions as Ruby Gems Rubygems is a flexible, easy-to-use system for distributing ruby software. If you have any questions about rubygems, I suggest that you start looking for help here. The big advantages of using rubygems to distribute your extension is that it allows your extension to be a dependency for other projects and that each install is versioned, which makes supporting your extension easier. If distributing as a rubygem, it is a good idea to have a file compass-.rb in your lib directory that registers the compass framework. This will allow compass to automatically require the framework from within rubygems. Tips for Developing Extensions If you’re developing a simple extension, you may find it convenient to place your extension within an existing compass project in the extension folder.Never specify an extension in your imports as this can cause issue when the syntax of a file changes.Packaging an Extension as a RubyGem You do not have to make your extension a ruby gem. But if you do, you get some benefits you would not have otherwise: ReleasesVersionsA standard way of asking your users what release they are using.Better integration with ruby-based projects via tools like Bundler.Creating a Gem Before you begin, please ensure you have gem version 1.3.6 or greater. gem -v will tell you the currently installed version. Define your gemspec file at the top of your extension. Here’s an example of one. The gemspec should have the same name as your gem.Register your framework by adding lib/my_extension.rb and registering it: require ‘compass’extension_path = File.expand_path(File.join(File.dirname(FILE), “..”))Compass::Frameworks.register(‘my_extension’, :path =&gt; extension_path)This is how compass knows where to find your extension’s files when a user requires it. For more options, go back up and read about Stylesheet and Template Locations. Build a gem: gem build my_extension.gemspec. This will build your gem file and add the current version to the name. E.g. my_extension-0.0.1.gemTest your gem by installing it locally: gem install my_extension-0.0.1.gemReleasing a Gem The ruby community is nice and will host your gem files for free. To release your gem: gem push my_extension-0.0.1.gemYour ruby gem will be hosted on rubygems.org. Please familiarize yourself with their documentation. Installing ExtensionsHow extensions are installed varies according to the decisions you make about how you are packaging and releasing your gem. There will be a standard approach in a future release, but until then, it is suggested that you provide your users with succinct installation instructions. Installing Extensions Released as RubyGems When creating a new project: sudo gem install my_extensioncompass create my_project -r my_extension –using my_extensionThe -r option is annoying and will not be needed in a future version of compass. But for now, it tells compass to find and load the extension from the local rubygems repository. To install via rubygems into an existing project: gem install my_extension edit the project configuration file and add:require ‘my_extension’compass install my_extensionOr if you have other patterns besides the project pattern: compass install my_extension/patternInstalling Ad-hoc Extensions Ad-hoc extensions are any set of files and folders following the basic conventions described above. They could be installed via a zip file or by checking the code out from source control. Ad-hoc extensions will be automatically found in the extensions directory of a project and registered for import without needing a require statement in the compass configuration file. Currently, ad-hoc extensions can only be installed into the extensions directory of an existing compass project. This will be fixed in a future release of compass. Until then, you may need to instruct your users to create a bare project to get started: compass create my_project –bareThis will create a project directory, a sass directory (with no sass files) and a configuration file. The standard location for extensions is project_root/extensions for stand-alone projects and project_root/vendor/plugins/compass_extensions for rails projects. Additionally, the user may customize their extensions directory by setting extensions_dir in their compass configuration file. To install into an existing project, simply place the extension into a project’s extension directory. This could be done via a git clone or by extracting an archive. The name of the directory it creates should be the name of the extension. The project will now have access to the extension. Verifying that an Extension is Installed Correctly The user can verify that they have access to your extension by typing: compass helpAnd they should see the framework in the list of available frameworks. Alternatively, if you’ve provided a help message in the manifest, then the user can type: compass help my_extension or -compass help my_extension/pattern_nameNote: The user might need to provide the -r option to help in order for compass to find a gem-based extension before a project exists. This is not needed for extensions installed into the extensions directory, or if the project is already required in the current directory’s project configuration.Extending CompassProduction StylesheetsSpritingCustomizationMagic SelectorsSprite layoutsTestingUpgradingLemonade UpgradeScared to Upgrade?Upgrading to v0.11Working with Configurable VariablesExamplesDocumentationSupportBugs]]></content>
    </entry>

    
  
  
</search>
